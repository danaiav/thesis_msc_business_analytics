#for posts_no a first approach (we remove LDA04 since it gives us NA)
full <- lm(Ranking~.,data=total_500_final)
anova(full)
x <- model.matrix(full) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final$Ranking)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final$Ranking)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#coefiecinets for lammda min with the min CV - MSE for posts3
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
#since the sum is NA that means we have to substract some variables
# in order to find which variables to substract we run the coefficients and we see which of them has NA as result
coef(full)
total_500_final_r <- total_500_final[,-c(5,11)]
full_2 <- lm(Ranking~.,data=total_500_final_r)
anova(full_2)
x <- model.matrix(full_2) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final_r$Ranking)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final_r$Ranking)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#coefiecinets for lammda min with the min CV - MSE for posts3
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full_2) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
s <- sum(abs(zblasso))/sum(abs(azbolt))
s
blassob <- coef(lassob, s="lambda.1se")
blassob
zblassob <- blassob[-1] * apply(x,2,sd)
zboltb <- coef (full_2) [-1] * apply (x,2,sd)
s <- sum(abs(zblassob))/sum(abs(zboltb))
s
model_a <- step(model_null, scope = list(lower = model_null, upper=full), direction = "forward")
summary(model_a)
ad_r_sq_ma <- summary(model_a)$adj.r.squared
ad_r_sq_ma
aic_ma <- AIC(model_a)
aic_ma
par(mfrow=c(3,1))
plot(model_a,which=1:3)
1
2
3
par(mfrow=c(1,1))
plot(model_a,which=1:3)
model_b <- step(model_null, scope = list(lower = model_null, upper=full), direction = "backward")
summary(model_b)
ad_r_sq_mb <- summary(model_b)$adj.r.squared
ad_r_sq_mb
aic_mb <- AIC(model_b)
aic_mb
par(mfrow=c(1,1))
plot(model_b,which=1:3)
#We use the backward method to compare the full model woth the null model to see how many variables are indeed important
model_b <- step(model_null, scope = list(lower = model_null, upper=full), direction = "both")
summary(model_b)
ad_r_sq_mb <- summary(model_b)$adj.r.squared
ad_r_sq_mb
aic_mb <- AIC(model_b)
aic_mb
par(mfrow=c(1,1))
plot(model_b,which=1:3)
names(total_500_final)
total_500_final_reg <- total_500_final[,c(1,8,9,15,24,28,29)]
set.seed(20)
set.seed(20)
fortuneCluster <- kmeans(total_500_final_reg[, 2:7], 5, nstart = 20)
fortuneCluster
set.seed(20)
fortuneCluster <- kmeans(total_500_final_reg[, 2:7], 2, nstart = 20)
fortuneCluster
table(fortuneCluster$cluster, total_500_final_reg$Ranking)
set.seed(20)
fortuneCluster <- kmeans(total_500_final_reg[, 2:7], 5, nstart = 20)
fortuneCluster
table(fortuneCluster$cluster, total_500_final_reg$Ranking)
fortuneCluster$cluster <- as.factor(fortuneCluster$cluster)
ggplot(total_500_final_reg, aes(number_of_warning, external, color = fortuneCluster$cluster)) + geom_point()
set.seed(20)
fortuneCluster <- kmeans(total_500_final_reg[, 2:7], 4, nstart = 20)
fortuneCluster
table(fortuneCluster$cluster, total_500_final_reg$Ranking)
fortuneCluster$cluster <- as.factor(fortuneCluster$cluster)
ggplot(total_500_final_reg, aes(number_of_warning, external, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, pinterest, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(total.images, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(total.images, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(im_s_small, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
total_500_final_reg <- total_500_final[,c(1,8,9,15,24,28,29)]
set.seed(20)
fortuneCluster <- kmeans(total_500_final_reg[, 2:7], 3, nstart = 20)
fortuneCluster
table(fortuneCluster$cluster, total_500_final_reg$Ranking)
fortuneCluster$cluster <- as.factor(fortuneCluster$cluster)
ggplot(total_500_final_reg, aes(number_of_warning, external, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, pinterest, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, pinterest, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(total.images, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(total.images, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(im_s_small, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
#we upload the dataset
total_500 <- read.csv("~/GitHub/thesis_msc_business_analytics/total_500.csv", sep=";", na.strings="n/a")
#we see how many observations and how many variables we have
dim(total_500)
names(total_500)
coef(full)
```{r}
#we upload the dataset
total_500 <- read.csv("~/GitHub/thesis_msc_business_analytics/total_500.csv", sep=";", na.strings="n/a")
#we see how many observations and how many variables we have
dim(total_500)
#We create a subset to make some changes to the data
total_500_sub <- total_500
#Change the decimal point for the 4 variables
total_500_sub$Assets.. <- gsub(",", ".", total_500_sub$Assets.. )
total_500_sub$Market.value.. <- gsub(",", ".", total_500_sub$Market.value.. )
total_500_sub$Revenues.. <- gsub(",", ".", total_500_sub$Revenues.. )
total_500_sub$Total.Stockholder.Equity.. <- gsub(",", ".", total_500_sub$Total.Stockholder.Equity.. )
#Make the variables numeric
for(i in 1:741){
total_500_sub[,i] <- as.numeric(total_500_sub[,i])}
#We omit the nas from the analysis
total_500_final <- na.omit(total_500_sub)
#We rename variable X as Ranking
colnames(total_500_final)[1] <- "Ranking"
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
#We make plots to see how the variables we got from Fortune 500 are related with each other
ggplot(total_500_final, aes(Assets..,Market.value.. , color = Ranking)) + geom_point()
ggplot(total_500_final, aes(Assets.., Revenues.., color = Ranking)) + geom_point()
ggplot(total_500_final, aes(Assets.., Total.Stockholder.Equity.., color = Ranking)) + geom_point()
ggplot(total_500_final, aes(Market.value.., Revenues.. , color = Ranking)) + geom_point()
ggplot(total_500_final, aes(Market.value.., Total.Stockholder.Equity.. , color = Ranking)) + geom_point()
ggplot(total_500_final, aes(Total.Stockholder.Equity.., Revenues.. , color = Ranking)) + geom_point()
#In order to have a more clear look we also create a correlation diagram
total_500_fortune <- total_500_final[,c(1:6)]
library(corrplot)
library(caret)
sm <- cor(total_500_fortune)
sm
corrplot(cor(total_500_fortune),method="number")
#From this plot we understand that the Ranking and teh Revenues have very high correlation.
#This means that since we will examine the Ranking as a variable we can exclude the Revenue and the Revenue..1 from the final model before the regression
#######################################################################################################
#We make the variables from fortune binomial so as to be more easily examined
#In order to achieve that we first see their summary and then we create their histogram so as to have a
#good grasp of how they are distributed
summary(total_500_final$Revenues..)
ggplot(data=total_500_final,aes(x=Revenues..))+geom_histogram(binwidth=50, colour = "green", fill ="darkgreen")
total_500_final$Revenues.. <- cut(total_500_final$Revenues..,c(-1,50,483))
summary(total_500_final$Assets..)
ggplot(data=total_500_final,aes(x=Assets..))+geom_histogram(binwidth=100, colour = "red", fill ="darkred")
total_500_final$Assets.. <- cut(total_500_final$Assets..,c(-1,500,1000))
summary(total_500_final$Market.value..)
ggplot(data=total_500_final,aes(x=Market.value..))+geom_histogram(binwidth=100, colour = "blue", fill ="darkblue")
total_500_final$Market.value.. <- cut(total_500_final$Market.value..,c(-1,400,1000))
summary(total_500_final$Total.Stockholder.Equity..)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=100, colour = "purple", fill ="pink")
total_500_final$Total.Stockholder.Equity.. <- cut(total_500_final$Total.Stockholder.Equity..,c(-1000,250,1000))
#######################################################################################################
#Change the names of some variables to be more easily readable
colnames(total_500_final)[2] <- "Assets"
colnames(total_500_final)[3] <- "Market_Value"
colnames(total_500_final)[4] <- "Revenues"
colnames(total_500_final)[6] <- "Total_SH_Equity"
#We make the Ranking variable binomial dividing the observations to the top 10 and the rest until the top 500
total_500_final$Ranking <- cut(total_500_final$Ranking,c(-1,9,500)) #we start from -1 so as to take 0 also
total_500_final$Ranking <- as.numeric(total_500_final$Ranking)
#Delete the variables we will not need
total_500_final[5] <- NULL #Revenues %
total_500_final[6] <- NULL #company name
total_500_final[21] <- NULL # company url
total_500_final[20] <- NULL # readability index
##########################################################################################################
```
```{r}
#Firstly we will analyze the social media relevance with the sites.
#We will see how many of the sites have social media and what type of social media
par(mfrow=c(1,2))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/439,3)
social_media_facebook
slicelable <- c(paste(38.8,"% no"),paste(61.2,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/439,3)
social_media_twitter
slicelable <- c(paste(33.7,"% no"),paste(66.3,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/439,3)
social_media_instagram
slicelable <- c(paste(79.1,"% no"),paste(20.9,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/439,3)
social_media_pinterest
slicelable <- c(paste(90.4,"% no"),paste(9.6,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/439,3)
social_media_youtube
slicelable <- c(paste(44.3,"% no"),paste(55.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/439,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#And we can also see for correlations
total_500_social_media <- total_500_final[,c(1,13:18)]
par(mfrow=c(1,1))
library(corrplot)
library(caret)
sm <- cor(total_500_social_media)
sm
corrplot(cor(total_500_social_media),method="number")
#The most high correlation is between facebook and twitter 69%
#While the second highest is between twitter and linkedIn 59%
#########################################################################################################
```
```{r}
#We will now check the links by creating an histogram
#Then we create ggplots in order to see in what frequency the links appear
par(mfrow=c(1,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
#And we can also see for correlations
total_500_links <- total_500_final[,c(1,10:12)]
library(corrplot)
library(caret)
tl <- cor(total_500_links)
tl
corrplot(cor(total_500_links),method="number")
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
#########################################################################################################
#Now we will see the words in total and in unique count in relation with the readability index
ggplot(data=total_500_final,aes(x=total_words,fill=Readability))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=unique_words, fill=Readability))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
#########################################################################################################
```
```{r}
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram(binwidth=100, colour = "darkred", fill ="red")
#########################################################################################################
#We will see now the frequency of image types that is being used
dev.off()
par(mfrow=c(3,3))
k = c(727:735)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/439,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
#It is obvious that the most common images type are .jpg,.png and .gif
#So they will be the ones that we will keep
#Delete the variables we will not need
total_500_final[727] <- NULL #.bmp
total_500_final[727] <- NULL #.dib
total_500_final[728] <- NULL # .jpe
total_500_final[728] <- NULL # .jpeg
total_500_final[730] <- NULL # .tif
total_500_final[730] <- NULL # .tiff
##########################################################################################################
#Now we will check the sizes of the images used
#2 means YES and 1 means NO
dev.off()
par(mfrow=c(3,3))
ks = c(22:726)
for(i in 1:705){
a <- ks[i]
image_type<- round(table(total_500_final[,a])/439,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark red")}
#Firstly we will keep the image sizes that exist in more than the half od the sites that we are examining
#So we will keep until the size x210x420 [304]
total_500_final <- total_500_final[,-c(305:726)]
#We will also subtrack the sizes that are not clear
#x1x1 [24], x11x8 [42], x [44], x1x700 [50], X1x10 [53], "X10x1" [54],"X1x660" [56],"X19x1"[57], 2x2 [60],  x0x0 [74],"X1x110"[208], "autox100." [249],"autox200" [250], "X2x213" [255],
total_500_final <- total_500_final[,-c(24,42,44,50,53,54,56,57,60,74,208,249,250,255)]
#names(total_500_final)
#We still have many bariables in order to make a regression model
#So we will group the sizes based  on the following 5 categories so as to have a more calable information
#If at least one of the dimensions belongs to a category we choose the higher category that a dimension belongs
#Very large size: more than 800pixels
#Large: 500 - 799 pixels
#Medium: 300 - 499 pixels
#Small: 100 - 299 pixels
#Thumbnail: less than 100 pixels
############################################################################################################
verylarge <- c(24,34,53,54,61,62,69,70,74,75,76,80,81,83,97,98,99,114,122,123,131,138,140,141,145,153,157,182,209,210,212,213,214,215,216,217,219,220,221,222,228,234,258,274,277,280,285,286,287)
total_500_final$im_s_verylarge <- 0
k<-0
for(i in 1:49){
k <- verylarge[i]
for(i in 1:439){
total_500_final$im_s_verylarge[i] <- total_500_final$im_s_verylarge[i] + total_500_final[i,k]
}}
total_500_final$im_s_verylarge <- total_500_final$im_s_verylarge/length(verylarge)
for(i in 1:439){
if (total_500_final$im_s_verylarge[i] >1){
total_500_final$im_s_verylarge[i] <- 2 #they have images of this size
}else{
total_500_final$im_s_verylarge[i] <- 1 #they do not have images of this size
}
}
par(mfrow=c(1,1))
barplot(table(total_500_final$im_s_verylarge),col = "darkred", main="Very Large images 1:NO, 2:YES")
###########################################################################################################
large <- c(23,45,52,65,100,113,118,119,129,137,139,150,159,211,218,232,235,249,265)
total_500_final$im_s_large <- 0
for(i in 1:19){
l <- large[i]
total_500_final$im_s_large <- total_500_final$im_s_large + total_500_final[,l]}
total_500_final$im_s_large <- total_500_final$im_s_large/length(large)
for(i in 1:439){
if (total_500_final$im_s_large[i] >1){
total_500_final$im_s_large[i] <- 2
}
}
par(mfrow=c(1,1))
barplot(table(total_500_final$im_s_large),col = "darkblue", main="Large images 1:NO, 2:YES")
###########################################################################################################
medium <- c(37,67,68,71,85,87,94,96,121,124,154,180,183,198,207,227,238,269,281,288,290)
total_500_final$im_s_medium <- 0
for(i in 1:21){
m <- medium[i]
total_500_final$im_s_medium <- total_500_final$im_s_medium + total_500_final[,m]}
total_500_final$im_s_medium <- total_500_final$im_s_medium/length(medium)
for(i in 1:439){
if (total_500_final$im_s_medium[i] >1){
total_500_final$im_s_medium[i] <- 2
}
}
par(mfrow=c(1,1))
barplot(table(total_500_final$im_s_medium),col = "darkgreen", main="Medium images 1:NO, 2:YES")
###########################################################################################################
small <- c(25,26,30,31,32,33,38,39,40,43,44,46,47,51,55,57,60,63,72,73,78,79,88,89,90,95,101,102,103,106,107,109,112,117,120,128,135,143,146,147,148,149,151,152,156,160,161,162,163,164,165,166,167,168,170,171,174,189,190,192,194,196,197,199,201,203,204,206,208,225,226,230,231,233,236,236,237,242,244,246,247,248,252,257,263,264,266,268,271,272,273,275,278,279,282,283,284,289)
total_500_final$im_s_small <- 0
for(i in 1:98){
sl <- small[i]
total_500_final$im_s_small <- total_500_final$im_s_small + total_500_final[,sl]}
total_500_final$im_s_small <- total_500_final$im_s_small/length(small)
for(i in 1:439){
if (total_500_final$im_s_small[i] >1){
total_500_final$im_s_small[i] <- 2
}
}
par(mfrow=c(1,1))
barplot(table(total_500_final$im_s_small),col = "red", main="Small images 1:NO, 2:YES")
###########################################################################################################
thumbnail<- c(22,41,64,84,91,92,93,108,126,127,169,224,240,245,250,27,142,28,144,29,155,35,158,36,172,42,173,175,48,176,49,177,50,178,56,179,58,181,184,59,185,66,186,187,188,77,82,191,86,193,195,104,200,105,202,110,111,205,115,116,223,229,125,239,241,130,132,243,133,134,136,251,253,254,255,256,259,260,261,262,267,270,276)
total_500_final$im_s_thumbnail <- 0
for(i in 1:83){
tl <- thumbnail[i]
total_500_final$im_s_thumbnail <- total_500_final$im_s_thumbnail + total_500_final[,tl]}
total_500_final$im_s_thumbnail <- total_500_final$im_s_thumbnail/length(thumbnail)
for(i in 1:439){
if (total_500_final$im_s_thumbnail[i] >1){
total_500_final$im_s_thumbnail[i] <- 2
}
}
par(mfrow=c(1,1))
barplot(table(total_500_final$im_s_thumbnail),col = "blue", main="Thumbnail images 1:NO, 2:YES")
###########################################################################################################
```
```{r}
#Now we will substract the sizes variables an keep only the new ones we created
total_500_final <- total_500_final[,-c(22:290)]
#str(total_500_final)
total_500_final$Market_Value <- as.numeric(total_500_final$Market_Value)
total_500_final$Assets <- as.numeric(total_500_final$Assets)
total_500_final$Revenues <- NULL #we also remove the variable Revenues as we said in the beggining
total_500_final$total.links <- NULL
total_500_final$twitter <- NULL
total_500_final$Total_SH_Equity <- as.numeric(total_500_final$Total_SH_Equity)
#We will try to create a regression model to see which of the variables of the websites play the most important part regarding the Ranking of the company.
#We create the empty lm model
model_null = lm(Ranking~1,data=total_500_final)
summary(model_null)
#And we create a full model to check which variables influence the ranking
full_model <- lm(Ranking~.,data=total_500_final)
anova(full_model)
#####################################################################################################
#Use of LASSO
library(glmnet)
#We create a full model for the variable Ranking
full <- lm(Ranking~.,data=total_500_final)
anova(full)
x <- model.matrix(full) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final$Ranking)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final$Ranking)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#We see the coefficients for lamda min
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
#since the sum is NA that means we have to substract some variables
# in order to find which variables to substract we run the coefficients and we see which of them has NA as result
coef(full)
#Now we create a new model with only the variables with coef different from NA
total_500_final_r <- total_500_final[,-c(5)]
full_2 <- lm(Ranking~.,data=total_500_final_r)
anova(full_2)
x <- model.matrix(full_2) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final_r$Ranking)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final_r$Ranking)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#coefiecinets for lammda min
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full_2) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
s <- sum(abs(zblasso))/sum(abs(azbolt))
s
blassob <- coef(lassob, s="lambda.1se")
blassob
zblassob <- blassob[-1] * apply(x,2,sd)
zboltb <- coef (full_2) [-1] * apply (x,2,sd)
s <- sum(abs(zblassob))/sum(abs(zboltb))
s
#We use the "both" method to compare the full model woth the null model to see how many variables are indeed important
model_a <- step(model_null, scope = list(lower = model_null, upper=full_2), direction = "both")
summary(model_a)
ad_r_sq_ma <- summary(model_a)$adj.r.squared
ad_r_sq_ma
aic_ma <- AIC(model_a)
aic_ma
par(mfrow=c(1,1))
#We create the 2 basic plots so as to be able to explain the regression model
plot(model_a,which=1:3)
names(total_500_final)
summary(model_a)
#Based on those results we will try to cluster the companies based on the results of the regression
total_500_final_reg <- total_500_final[,c(1,8,9,14,22,26,27)]
set.seed(20)
fortuneCluster <- kmeans(total_500_final_reg[, 2:7], 3, nstart = 20)
fortuneCluster
table(fortuneCluster$cluster, total_500_final_reg$Ranking)
fortuneCluster$cluster <- as.factor(fortuneCluster$cluster)
ggplot(total_500_final_reg, aes(number_of_warning, external, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, pinterest, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(number_of_warning, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, pinterest, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(external, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, total.images, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(pinterest, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(total.images, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(total.images, im_s_small, color = fortuneCluster$cluster)) + geom_point()
ggplot(total_500_final_reg, aes(im_s_small, im_s_medium, color = fortuneCluster$cluster)) + geom_point()
