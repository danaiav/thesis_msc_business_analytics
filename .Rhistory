social_media_linkedin <- round(table(total_500_final$linkedin)/436,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#And we can also see for correlations
total_500_social_media <- total_500_final[,c(15:20)]
par(mfrow=c(1,1))
library(corrplot)
library(caret)
sm <- cor(total_500_social_media)
corrplot(cor(total_500_social_media),method="number")
#The most high correlation is between facebook and twitter 68%
#While the second highest is between twitter and linkedIn
#########################################################################################################
#We will now check the links by creating an histogram
#Then we create ggplots in order to see in what frequency the links appear
par(mfrow=c(3,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
#########################################################################################################
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
#########################################################################################################
#Now we will see the words in total and in unique count in relation with the readability index
ggplot(data=total_500_final,aes(x=total_words,fill=Readability))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=unique_words, fill=Readability))+geom_histogram(binwidth=50)
#########################################################################################################
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram(binwidth=100)
table(total_500_final$total.images)
#########################################################################################################
#We will see now the frequency of image types that is being used
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
#It is obvious that the most common images type are .jpg,.png and .gif
##########################################################################################################
total_500_final$num_companies <- c(1:436)
par(mfrow=c(3,3))
ks = c(25:730)
for(i in 1:706){
a <- ks[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark red")}
###########################################################################################################
#we make a sub data frame without the image sizes for the time being
ggplot(data=total_500_final,aes(x=Revenues..))+geom_histogram(binwidth=50)
rev <- cut(total_500_final$Revenues..,c(-1,50,483))
round(table(rev)/436,3)
ggplot(data=total_500_final,aes(x=Assets..))+geom_histogram(binwidth=100)
as <- cut(total_500_final$Assets..,c(-1,300,1000))
round(table(as)/436,3)
ggplot(data=total_500_final,aes(x=Market.value..))+geom_histogram(binwidth=100)
mv <- cut(total_500_final$Market.value..,c(-1,400,1000))
round(table(mv)/436,3)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=100)
stock <- cut(total_500_final$Total.Stockholder.Equity..,c(-1000,250,1000))
round(table(stock)/436,3)
#we create a binomial variable as the one to see how the other variables are related to the revenue of the companies
total_500_final$rev <- cut(total_500_final$Revenues..,c(-1,50,483))
total_500 <- read.csv("~/GitHub/thesis_msc_business_analytics/total_500.csv", sep=";", na.strings="n/a")
#total_500 <- read.csv("F:/Dropbox/Dani/Spinellis - Diplwmatiki/Jupyter markdown/total_500.csv", sep=";")
#we see how many observations and how many variables we have and then the names of the variables we have
dim(total_500)
names(total_500)
str(total_500)
total_500.sub <- total_500
#We make the factors numbers where it is possible
total_500.sub$Assets.. <- gsub(",", ".", total_500.sub$Assets.. )
total_500.sub$Market.value.. <- gsub(",", ".", total_500.sub$Market.value.. )
total_500.sub$Revenues.. <- gsub(",", ".", total_500.sub$Revenues.. )
total_500.sub$Total.Stockholder.Equity.. <- gsub(",", ".", total_500.sub$Total.Stockholder.Equity.. )
num <- c(2,3,4,5,6,9,10,11,13,14,12,24,25,757,758,759,760,761,762,763,764,765,766,767)
for(i in 1:24){
k <- num[i]
total_500.sub[,k] <- as.numeric(as.character(total_500.sub[,k]))}
str(total_500.sub[757:767])
#We omit the nas from the analysis
total_500_final <- na.omit(total_500.sub)
#we remove the extra value X since it is not necessary for the analysis
#total_500_final$X <- NULL
str(total_500_final)
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
##########################################################################################################
#Firstly we will analyze the social media relevance with the sites.
#We will see how many of the sites have social media and what type of social media
par(mfrow=c(2,3))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/436,3)
social_media_facebook
slicelable <- c(paste(38.8,"% no"),paste(61.2,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/436,3)
social_media_twitter
slicelable <- c(paste(33.7,"% no"),paste(66.3,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/436,3)
social_media_instagram
slicelable <- c(paste(79.1,"% no"),paste(20.9,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/436,3)
social_media_pinterest
slicelable <- c(paste(90.4,"% no"),paste(9.6,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/436,3)
social_media_youtube
slicelable <- c(paste(44.3,"% no"),paste(55.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/436,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#And we can also see for correlations
total_500_social_media <- total_500_final[,c(15:20)]
par(mfrow=c(1,1))
library(corrplot)
library(caret)
sm <- cor(total_500_social_media)
corrplot(cor(total_500_social_media),method="number")
#The most high correlation is between facebook and twitter 68%
#While the second highest is between twitter and linkedIn
#########################################################################################################
#We will now check the links by creating an histogram
#Then we create ggplots in order to see in what frequency the links appear
par(mfrow=c(3,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
par(mfrow=c(1,1))
#########################################################################################################
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
#########################################################################################################
#Now we will see the words in total and in unique count in relation with the readability index
ggplot(data=total_500_final,aes(x=total_words,fill=Readability))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=unique_words, fill=Readability))+geom_histogram(binwidth=50)
#########################################################################################################
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram(binwidth=100)
table(total_500_final$total.images)
#########################################################################################################
#We will see now the frequency of image types that is being used
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
#It is obvious that the most common images type are .jpg,.png and .gif
par(mfrow=c(1,1))
##########################################################################################################
total_500_final$num_companies <- c(1:436)
par(mfrow=c(3,3))
ks = c(25:730)
for(i in 1:706){
a <- ks[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark red")}
###########################################################################################################
#we make a sub data frame without the image sizes for the time being
ggplot(data=total_500_final,aes(x=Revenues..))+geom_histogram(binwidth=50)
rev <- cut(total_500_final$Revenues..,c(-1,50,483))
round(table(rev)/436,3)
ggplot(data=total_500_final,aes(x=Assets..))+geom_histogram(binwidth=100)
as <- cut(total_500_final$Assets..,c(-1,300,1000))
round(table(as)/436,3)
ggplot(data=total_500_final,aes(x=Market.value..))+geom_histogram(binwidth=100)
mv <- cut(total_500_final$Market.value..,c(-1,400,1000))
round(table(mv)/436,3)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=100)
stock <- cut(total_500_final$Total.Stockholder.Equity..,c(-1000,250,1000))
round(table(stock)/436,3)
#we create a binomial variable as the one to see how the other variables are related to the revenue of the companies
total_500_final$rev <- cut(total_500_final$Revenues..,c(-1,50,483))
str(total_500_final)
names(total_500_final)
str(total_500_final[1,350])
str(total_500_final[1:350])
str(total_500_final[1:300])
str(total_500_final[1:250])
str(total_500_final[1:200])
str(total_500_final[1:150])
names(total_500_final)
str(total_500_final[1:25])
str(total_500_final[731:743])
table(total_500_final$rev)
model_null = lm(rev~1,data=total_500_final)
summary(model_null)
posts <- read.csv(choose.files(),sep=";")
dim(posts)
names(posts)
str(posts_test)
str(posts)
model_null = lm(Revenues..~1,data=total_500_final)
summary(model_null)
full_model <- lm(Revenues..~.,data=total_500_final)
anova(full)
anova(full_model)
str(total_500_final[1:25])
full_model <- lm(Revenues..~. -non.document.error,data=total_500_final)
total_500_final$Rank <- total_500_final$X +1
str(total_500_final[731:744])
full_model <- lm(Revenues..~.,data=total_500_final)
str(posts)
total_500_final$X <- NULL
str(total_500_final[1:25])
full_model <- lm(Revenues..~. -The_page_opened,data=total_500_final)
total_500_final$The_page_opened <- NULL
full_model <- lm(Revenues..~.,data=total_500_final)
anova(full_model)
model_a <- step(model_null, scope = list(lower = model_null, upper=full_model), direction = "forward")
summary(model_a)
#Use of LASSO
library(glmnet)
#for posts_no a first approach (we remove LDA04 since it gives us NA)
full <- lm(Revenues..~.,data=total_500_final)
anova(full)
x <- model.matrix(full) [,-1]
dim(x)
lasso <- glmnet (x, posts_no$shares)
lasso <- glmnet (x, total_500_final$Revenues..)
plot(lasso,label=T)
plot(lasso,label=T)
par(mfrow=c(1,1))
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
par(mfrow=c(1,1))
plot(lasso,label=T)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final$Revenues..)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
blasso <- coef(lassob, s="lambda.min")
blasso
total_500_final_for_regression <- total_500_final
total_500_final_for_regression$X <- NULL
total_500_final_for_regression$The_page_opened <- NULL
total_500_final_for_regression$company <- NULL
total_500_final_for_regression$url <- NULL
full_model <- lm(Revenues..~.,data=total_500_final_for_regression)
anova(full_model)
total_500_final_for_regression$num_companies <- NULL
full_model <- lm(Revenues..~.,data=total_500_final_for_regression)
anova(full_model)
total_500_final_for_regression$Assets.. <- NULL
total_500_final_for_regression$Market.value.. <- NULL
total_500_final_for_regression$Total.Stockholder.Equity.. <- NULL
total_500_final_for_regression$Revenues...1 <- NULL
full_model <- lm(Revenues..~.,data=total_500_final_for_regression)
anova(full_model)
model_a <- step(model_null, scope = list(lower = model_null, upper=full_model), direction = "forward")
summary(model_a)
ad_r_sq_ma <- summary(model_a)$adj.r.squared
ad_r_sq_ma
# with the forward method we had a cut off to 8 variables but with worst adjusted R2
ma_residuals <- model_a$residuals
ma_fitted_values <- model_a$fitted.values
pa <- qplot(ma_fitted_values,ma_residuals)
pa <- pa + ggtitle("Residual Plot model a")
pa <- pa + theme(plot.title = element_text(lineheight=.8, face="bold"))
pa <- pa + xlab("Fitted Values")
pa <- pa + ylab("Residuals")
pa
par(mfrow=c(1,1))
qqnorm(ma_residuals, main = "Normal Q-Q Plot for Revenues")
qqline(ma_residuals)
aic_ma <- AIC(model_a)
aic_ma
par(mfrow=c(3,2))
plot(model_a,which=1:6)
#dhmiourgoume ta diastimata empistosunis twn syntelestwn tou modelou
confint(model_a)
full <- lm(Revenues..~.,data=total_500_final_for_regression)
anova(full)
x <- model.matrix(full) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final_for_regression$Revenues..)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final_for_regression$Revenues..)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#coefiecinets for lammda min with the min CV - MSE for posts3
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
s <- sum(abs(zblasso))/sum(abs(zbolt))
s
coef (full)
str(total_500_final[1:25])
cf <- coef (full)
cf <- na.omit(cf)
cf <- coef (full)
cf <- na.omit(cf)
cf <- coef (full) [-1]
cf <- na.omit(cf)
zbolt <- cf * apply (x,2,sd)
zbolt <- coef (full) [-1] * apply (x,2,sd)
coef (full)
azbolt <- abs(zbolt)
sum(azbolt)
names(total_500_final_for_regression)
total_500_final_for_regression[,-c(7,15,20,23,28:31,34,37:41,44:47,50:53,58,60,62,65,66,68,74:76,78:81,83,86,87,89,90,95:100,103:107,109,112:119,121,122,124,125,126,128,129,130,133,137:142,144,147:149,152,156:168,170:177,179,180,182:185,187,189,190,192:204,206,208,209,211,212,215:218,220:230,232,2326,237,240:242,244,247,248,250,252:268,270:272,276:280,282,283,286:290,292,295,297,298,300,302,304,306:308,310:316,318,319,322,324,326,328:333,335,337:339,341,343:345,347:349,351,354,356:364,366:368,370:383,385:388,391,392,394:398,400:414,416:420,422:424,426,427,430,431,433:440,442:445,447,449:452,456:472,474,476:478,480,481,485,487:494,496,497,499,501:505,507,509:516,519,522:524,526,527,532,533,535:592,594:606,609:612,614:616,620:626,628:630,632:641,644,645,646,648,649,651,653,654,656,659,661:664,667,668,670:674,676,678:683,688,689,691:694,696,698:700,702,703,705:713,718:722,724,734,736)]
total_500_final_for_regression_sub <- total_500_final_for_regression[,-c(7,15,20,23,28:31,34,37:41,44:47,50:53,58,60,62,65,66,68,74:76,78:81,83,86,87,89,90,95:100,103:107,109,112:119,121,122,124,125,126,128,129,130,133,137:142,144,147:149,152,156:168,170:177,179,180,182:185,187,189,190,192:204,206,208,209,211,212,215:218,220:230,232,2326,237,240:242,244,247,248,250,252:268,270:272,276:280,282,283,286:290,292,295,297,298,300,302,304,306:308,310:316,318,319,322,324,326,328:333,335,337:339,341,343:345,347:349,351,354,356:364,366:368,370:383,385:388,391,392,394:398,400:414,416:420,422:424,426,427,430,431,433:440,442:445,447,449:452,456:472,474,476:478,480,481,485,487:494,496,497,499,501:505,507,509:516,519,522:524,526,527,532,533,535:592,594:606,609:612,614:616,620:626,628:630,632:641,644,645,646,648,649,651,653,654,656,659,661:664,667,668,670:674,676,678:683,688,689,691:694,696,698:700,702,703,705:713,718:722,724,734,736)]
full_2 <- lm(Revenues..~.,data=total_500_final_for_regression_sub)
full_2 <- lm(Revenues..~.,data=total_500_final_for_regression_sub)
anova(full_2)
x <- model.matrix(full_2) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final_for_regression_sub$Revenues..)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final_for_regression_sub$Revenues..)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#coefiecinets for lammda min with the min CV - MSE for posts3
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full_2) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
s <- sum(abs(zblasso))/sum(abs(zbolt))
s
coef (full_2)
names(total_500_final_for_regression_sub)
coef (full_2)
total_500_final_for_regression_sub_2 <- total_500_final_for_regression_sub[,-c(86,91,92,94,97,103,106,108,118,129,135,142,149,155,165,169,170,174,177,178,182,185,189,191,194,197,198,201,206,207)]
full_3 <- lm(Revenues..~.,data=total_500_final_for_regression_sub_2)
anova(full_3)
x <- model.matrix(full_3) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final_for_regression_sub_2$Revenues..)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso,label=T)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final_for_regression_sub_2$Revenues..)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#coefiecinets for lammda min with the min CV - MSE for posts3
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full_3) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
s <- sum(abs(zblasso))/sum(abs(zbolt))
s
blassob <- coef(lassob, s="lambda.1se")
blassob
zblassob <- blassob[-1] * apply(x,2,sd)
zboltb <- coef (full) [-1] * apply (x,2,sd)
s <- sum(abs(zblassob))/sum(abs(zboltb))
s
blassob <- coef(lassob, s="lambda.1se")
blassob
zblassob <- blassob[-1] * apply(x,2,sd)
zboltb <- coef (full_3) [-1] * apply (x,2,sd)
s <- sum(abs(zblassob))/sum(abs(zboltb))
s
model_a <- step(model_null, scope = list(lower = model_null, upper=full_3), direction = "forward")
summary(model_a)
ad_r_sq_ma <- summary(model_a)$adj.r.squared
ad_r_sq_ma
ma_residuals <- model_a$residuals
ma_fitted_values <- model_a$fitted.values
pa <- qplot(ma_fitted_values,ma_residuals)
pa <- pa + ggtitle("Residual Plot model a")
pa <- pa + theme(plot.title = element_text(lineheight=.8, face="bold"))
pa <- pa + xlab("Fitted Values")
pa <- pa + ylab("Residuals")
pa
par(mfrow=c(1,1))
qqnorm(ma_residuals, main = "Normal Q-Q Plot for Revenues")
qqline(ma_residuals)
aic_ma <- AIC(model_a)
aic_ma
par(mfrow=c(3,2))
plot(model_a,which=1:6)
#dhmiourgoume ta diastimata empistosunis twn syntelestwn tou modelou
confint(model_a)
summary(model_a)
library(psych)
fit <- principal(total_500_final, nfactors=5, rotate="varimax")
fit
library(psych)
total_500_final[,436] <- as.numeric(total_500_final[,436])
fit <- principal(total_500_final, nfactors=5, rotate="varimax")
fit
str(total_500_final)
as.numeric(total_500_final[,436])
library(psych)
for(i in 1:436){
total_500_final[,i] <- as.numeric(total_500_final[,i])}
str(total_500_final)
fit <- principal(total_500_final, nfactors=5, rotate="varimax")
fit
library(psych)
fit <- principal(total_500_final, nfactors=5, rotate="varimax")
fit
fit <- principal(total_500_final, nfactors=5, rotate="pairwise")
fit <- principal(total_500_final, nfactors=15)
?principal
?pairwise.table
confint(model_a)
summary(model_a)
fit <- principal(total_500_final, nfactors=50)
fit
library(psych)
fit <- principal(total_500_final, nfactors=50)
fit
str(total_500_final)
names(total_500_final)
total_500_final_images <- total_500_final[,-c(1,2,4:23,729:742)]
names(total_500_final_images)
fit <- principal(total_500_final_images, nfactors=5)
fit
View(total_500_final_for_regression_sub)
View(total_500_final_for_regression_sub_2)
total_500_final_without_images <- total_500_final[,c(3:23,729:742)]
library(psych)
fit <- principal(total_500_final_without_images, nfactors=5)
names(total_500_final_without_images)
total_500_final_without_images <- total_500_final[,c(3,6:23,729:742)]
names(total_500_final_without_images)
str(total_500_final_without_images)
for(i in 1:742){
total_500_final[,i] <- as.numeric(total_500_final[,i])}
total_500_final_images <- total_500_final[,-c(1,2,4:23,729:742)]
total_500_final_without_images <- total_500_final[,c(3,6:23,729:742)]
str(total_500_final_without_images)
fit <- principal(total_500_final_without_images, nfactors=5)
fit
fit <- principal(total_500_final, nfactors=5)
fit
install.packages("FactoMineR", lib="F:/programmes/R/R-3.2.3/library")
install.packages("factorplot", lib="F:/programmes/R/R-3.2.3/library")
fit <- principal(total_500_final, nfactors=2)
fit
plot(fit)
fit <- principal(total_500_final, nfactors=3)
plot(fit)
fit <- principal(total_500_final, nfactors=5)
plot(fit)
str(total_500_final_without_images)
autoplot(prcomp(total_500_final), data = total_500_final, colour = 'rev')
install.packages("ggfortify", lib="F:/programmes/R/R-3.2.3/library")
library(ggfortify)
autoplot(prcomp(total_500_final), data = total_500_final, colour = 'rev')
install.packages("lazyeval", lib="F:/programmes/R/R-3.2.3/library")
library(ggfortify)
autoplot(prcomp(total_500_final), data = total_500_final, colour = 'rev')
autoplot(prcomp(total_500_final), data = total_500_final, colour = 'Revenue')
autoplot(prcomp(total_500_final), data = total_500_final, colour = 'Facebook')
autoplot(prcomp(total_500_final), data = total_500_final, colour = 'facebook')
autoplot(prcomp(total_500_final), data = total_500_final, colour = 'rev')
summary(total_500_final$Market.value..)
ggplot(data=total_500_final,aes(x=Revenues..))+geom_histogram(binwidth=50)
rev <- cut(total_500_final$Revenues..,c(-1,50,483))
round(table(rev)/436,3)
ggplot(data=total_500_final,aes(x=Assets..))+geom_histogram(binwidth=100)
as <- cut(total_500_final$Assets..,c(-1,300,1000))
round(table(as)/436,3)
ggplot(data=total_500_final,aes(x=Market.value..))+geom_histogram(binwidth=100)
mv <- cut(total_500_final$Market.value..,c(-1,400,1000))
round(table(mv)/436,3)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=100)
stock <- cut(total_500_final$Total.Stockholder.Equity..,c(-1000,250,1000))
round(table(stock)/436,3)
names(total_500_final)
str(total_500_final[1:25])
library(shiny)
library(highcharter)
install.packages("highcharter", lib="F:/programmes/R/R-3.2.3/library")
library(highcharter)
library(dplyr)
library(tidyr)
