total_500.sub$Assets.. <- gsub(",", ".", total_500.sub$Assets.. )
total_500.sub$Market.value.. <- gsub(",", ".", total_500.sub$Market.value.. )
total_500.sub$Revenues.. <- gsub(",", ".", total_500.sub$Revenues.. )
total_500.sub$Total.Stockholder.Equity.. <- gsub(",", ".", total_500.sub$Total.Stockholder.Equity.. )
num <- c(2,3,4,5,6,9,10,11,13,14,12,24,25,757,758,759,760,761,762,763,764,765,766,767)
for(i in 1:24){
k <- num[i]
total_500.sub[,k] <- as.numeric(as.character(total_500.sub[,k]))}
str(total_500.sub[757:767])
#We omit the nas from the analysis
total_500_final <- na.omit(total_500.sub)
#we remove the extra value X since it is not necessary for the analysis
#total_500_final$X <- NULL
str(total_500_final)
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
##########################################################################################################
#Firstly we will analyze the social media relevance with the sites.
#We will see how many of the sites have social media and what type of social media
par(mfrow=c(2,3))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/439,3)
slicelable <- c(paste(39.86,"% no"),paste(60.13,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/439,3)
social_media_twitter
slicelable <- c(paste(35.30,"% no"),paste(64.7,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/439,3)
social_media_instagram
slicelable <- c(paste(80,"% no"),paste(20,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/439,3)
social_media_pinterest
slicelable <- c(paste(90,"% no"),paste(10,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/439,3)
social_media_youtube
slicelable <- c(paste(45.3,"% no"),paste(54.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/439,3)
social_media_linkedin
slicelable <- c(paste(47.6,"% no"),paste(52.4,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#########################################################################################################
#We will now check the links by creating an histogram
#Then we create ggplots in order to see in what frequency the links appear
par(mfrow=c(3,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
#########################################################################################################
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
#########################################################################################################
#Now we will see the words in total and in unique count in relation with the readability index
ggplot(data=total_500_final,aes(x=total_words,fill=Readability))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=unique_words, fill=Readability))+geom_histogram(binwidth=50)
#########################################################################################################
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram()
social_media_facebook
social_media_twitter
social_media_instagram
social_media_pinterest
social_media_youtube
social_media_linkedin
par(mfrow=c(2,3))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/436,3)
social_media_facebook
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/436,3)
social_media_twitter
slicelable <- c(paste(38.8,"% no"),paste(61.2,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/436,3)
social_media_twitter
slicelable <- c(paste(33.7,"% no"),paste(66.3,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/436,3)
social_media_instagram
slicelable <- c(paste(79.1,"% no"),paste(20.9,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/436,3)
social_media_pinterest
slicelable <- c(paste(90.4,"% no"),paste(9.6,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/436,3)
social_media_youtube
slicelable <- c(paste(44.3,"% no"),paste(55.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/436,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#we upload the dataset
total_500 <- read.csv("~/GitHub/thesis_msc_business_analytics/total_500.csv", sep=";", na.strings="n/a"
#total_500 <- read.csv("F:/Dropbox/Dani/Spinellis - Diplwmatiki/Jupyter markdown/total_500.csv", sep=";")
#we see how many observations and how many variables we have and then the names of the variables we have
dim(total_500)
names(total_500)
str(total_500)
total_500.sub <- total_500
#We make the factors numbers where it is possible
total_500.sub$Assets.. <- gsub(",", ".", total_500.sub$Assets.. )
total_500.sub$Market.value.. <- gsub(",", ".", total_500.sub$Market.value.. )
total_500.sub$Revenues.. <- gsub(",", ".", total_500.sub$Revenues.. )
total_500.sub$Total.Stockholder.Equity.. <- gsub(",", ".", total_500.sub$Total.Stockholder.Equity.. )
num <- c(2,3,4,5,6,9,10,11,13,14,12,24,25,757,758,759,760,761,762,763,764,765,766,767)
for(i in 1:24){
k <- num[i]
total_500.sub[,k] <- as.numeric(as.character(total_500.sub[,k]))}
str(total_500.sub[757:767])
#We omit the nas from the analysis
total_500_final <- na.omit(total_500.sub)
#we remove the extra value X since it is not necessary for the analysis
#total_500_final$X <- NULL
str(total_500_final)
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
##########################################################################################################
#Firstly we will analyze the social media relevance with the sites.
#We will see how many of the sites have social media and what type of social media
par(mfrow=c(2,3))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/436,3)
social_media_facebook
slicelable <- c(paste(38.8,"% no"),paste(61.2,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/436,3)
social_media_twitter
slicelable <- c(paste(33.7,"% no"),paste(66.3,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/436,3)
social_media_instagram
slicelable <- c(paste(79.1,"% no"),paste(20.9,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/436,3)
social_media_pinterest
slicelable <- c(paste(90.4,"% no"),paste(9.6,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/436,3)
social_media_youtube
slicelable <- c(paste(44.3,"% no"),paste(55.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/436,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#########################################################################################################
#We will now check the links by creating an histogram
#Then we create ggplots in order to see in what frequency the links appear
par(mfrow=c(3,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
#########################################################################################################
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
#########################################################################################################
#Now we will see the words in total and in unique count in relation with the readability index
ggplot(data=total_500_final,aes(x=total_words,fill=Readability))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=unique_words, fill=Readability))+geom_histogram(binwidth=50)
#########################################################################################################
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram()
names(total_500_final)
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/439,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
#It is obvious that the most common images type are .jpg,.png and .gif
ggplot(data=total_500_final,aes(X,fill=facebook))+geom_histogram()
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
total_500_final$num_companies <- c(1:436)
total_500_final$num_companies
ggplot(data=total_500_final,aes(X,fill=num_companies))+geom_histogram()
ggplot(data=total_500_final,aes(num_companies,fill=facebook))+geom_histogram()
ggplot(data=total_500_final,aes(num_companies,fill=facebook))+geom_histogram(binwidth = 1)
ggplot(data=total_500_final,aes(num_companies,fill=facebook))+geom_histogram(binwidth = 15)
ggplot(data=total_500_final,aes(num_companies,fill=facebook))+geom_histogram()
names(total_500_final)
ks = c(25:730)
par(mfrow=c(3,3))
ks = c(25:730)
for(i in 1:706){
a <- ks[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
total_500_final_sub <- total_500_final[,c(-307:706)]
total_500_final_sub <- total_500_final[,-c(307:706)]
names(total_500_final_sub)
total_500_final_sub$X1x1 <- NULL
total_500_final_sub <- total_500_final[,-c(25:730)]
names(total_500_final_sub)
total_500_final_sub$X
for(i in 1:433){
total_500_final_sub$X[i] <- total_500_final_sub$X[i]+1}
total_500_final_sub$X
total_500_final_sub <- total_500_final[,-c(25:730)]
names(total_500_final_sub)
for(i in 1:436){
total_500_final_sub$X[i] <- total_500_final_sub$X[i]+1}
total_500_final_sub$X
total_500_final_sub <- total_500_final[,-c(25:730)]
names(total_500_final_sub)
for(i in 1:436){
total_500_final_sub$Rank[i] <- total_500_final_sub$X[i]+1}
total_500_final_sub$X <- NULL
total_500_final_sub$num_companies <- NULL
names(total_500_final_sub)
total_500_final_sub$URL <- NULL
total_500_final_sub$Readability <- NULL
names(total_500_final_sub)
total_500_final_sub$url <- NULL
names(total_500_final_sub)
pairs(total_500_final_sub)
total_500_social_media <- total_500_final_sub[,c(8:21)]
pairs(total_500_final_sub)
total_500_social_media <- total_500_final_sub[,c(14:19)]
pairs(total_500_final_sub)
total_500_social_media <- as.numeric(as.character(total_500_social_media)
pairs(total_500_final_sub)
pairs(total_500_social_media)
total_500_social_media <- total_500_final_sub[,c(14:21)]
total_500_social_media <- as.numeric(as.character(total_500_social_media)
pairs(total_500_social_media)
pairs(total_500_social_media)
total_500_social_media <- total_500_final_sub[,c(31:32)]
total_500_social_media <- as.numeric(as.character(total_500_social_media)
)
pairs(total_500_social_media)
total_500_social_media <- total_500_final_sub[,c(31:32)]
pairs(total_500_social_media)
total_500_social_media <- total_500_final_sub[,c(11:13)]
pairs(total_500_social_media)
total_500_social_media <- total_500_final_sub[,c(14:19)]
pairs(total_500_social_media)
cor(total_500_social_media)
social <- cor(total_500_social_media)
plot(social)
pairs(social)
cor(total_500_social_media)
#we upload the dataset
total_500 <- read.csv("~/GitHub/thesis_msc_business_analytics/total_500.csv", sep=";", na.strings="n/a"
#total_500 <- read.csv("F:/Dropbox/Dani/Spinellis - Diplwmatiki/Jupyter markdown/total_500.csv", sep=";")
#we see how many observations and how many variables we have and then the names of the variables we have
dim(total_500)
names(total_500)
str(total_500)
total_500.sub <- total_500
#We make the factors numbers where it is possible
total_500.sub$Assets.. <- gsub(",", ".", total_500.sub$Assets.. )
total_500.sub$Market.value.. <- gsub(",", ".", total_500.sub$Market.value.. )
total_500.sub$Revenues.. <- gsub(",", ".", total_500.sub$Revenues.. )
total_500.sub$Total.Stockholder.Equity.. <- gsub(",", ".", total_500.sub$Total.Stockholder.Equity.. )
num <- c(2,3,4,5,6,9,10,11,13,14,12,24,25,757,758,759,760,761,762,763,764,765,766,767)
for(i in 1:24){
k <- num[i]
total_500.sub[,k] <- as.numeric(as.character(total_500.sub[,k]))}
str(total_500.sub[757:767])
#We omit the nas from the analysis
total_500_final <- na.omit(total_500.sub)
#we remove the extra value X since it is not necessary for the analysis
#total_500_final$X <- NULL
str(total_500_final)
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
##########################################################################################################
#Firstly we will analyze the social media relevance with the sites.
#We will see how many of the sites have social media and what type of social media
par(mfrow=c(2,3))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/436,3)
social_media_facebook
slicelable <- c(paste(38.8,"% no"),paste(61.2,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/436,3)
social_media_twitter
slicelable <- c(paste(33.7,"% no"),paste(66.3,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/436,3)
social_media_instagram
slicelable <- c(paste(79.1,"% no"),paste(20.9,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/436,3)
social_media_pinterest
slicelable <- c(paste(90.4,"% no"),paste(9.6,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/436,3)
social_media_youtube
slicelable <- c(paste(44.3,"% no"),paste(55.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/436,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#And we can also see for correlations
cor(total_500_social_media)
total_500_social_media <- total_500_final[,c(14:19)]
cor(total_500_social_media)
total_500 <- read.csv("~/GitHub/thesis_msc_business_analytics/total_500.csv", sep=";", na.strings="n/a"
)
dim(total_500)
names(total_500)
str(total_500)
total_500.sub <- total_500
#We make the factors numbers where it is possible
total_500.sub$Assets.. <- gsub(",", ".", total_500.sub$Assets.. )
total_500.sub$Market.value.. <- gsub(",", ".", total_500.sub$Market.value.. )
total_500.sub$Revenues.. <- gsub(",", ".", total_500.sub$Revenues.. )
total_500.sub$Total.Stockholder.Equity.. <- gsub(",", ".", total_500.sub$Total.Stockholder.Equity.. )
num <- c(2,3,4,5,6,9,10,11,13,14,12,24,25,757,758,759,760,761,762,763,764,765,766,767)
for(i in 1:24){
k <- num[i]
total_500.sub[,k] <- as.numeric(as.character(total_500.sub[,k]))}
str(total_500.sub[757:767])
#We omit the nas from the analysis
total_500_final <- na.omit(total_500.sub)
#we remove the extra value X since it is not necessary for the analysis
#total_500_final$X <- NULL
str(total_500_final)
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
##########################################################################################################
#Firstly we will analyze the social media relevance with the sites.
#We will see how many of the sites have social media and what type of social media
par(mfrow=c(2,3))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/436,3)
social_media_facebook
slicelable <- c(paste(38.8,"% no"),paste(61.2,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/436,3)
social_media_twitter
slicelable <- c(paste(33.7,"% no"),paste(66.3,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/436,3)
social_media_instagram
slicelable <- c(paste(79.1,"% no"),paste(20.9,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/436,3)
social_media_pinterest
slicelable <- c(paste(90.4,"% no"),paste(9.6,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/436,3)
social_media_youtube
slicelable <- c(paste(44.3,"% no"),paste(55.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/436,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#And we can also see for correlations
total_500_social_media <- total_500_final[,c(14:19)]
cor(total_500_social_media)
corrplot(cor(total_500_social_media),method="square")
library(corrplot)
cor(total_500_social_media)
corrplot(cor(total_500_social_media),method="square")
total_500_social_media <- total_500_final[,c(15:20)]
par(mfrow=c(1,1))
library(corrplot)
cor(total_500_social_media)
corrplot(cor(total_500_social_media),method="square")
corrplot(cor(total_500_social_media),method="number")
par(mfrow=c(3,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
#Now we will see the words in total and in unique count in relation with the readability index
ggplot(data=total_500_final,aes(x=total_words,fill=Readability))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=unique_words, fill=Readability))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram()
#We will see now the frequency of image types that is being used
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
#It is obvious that the most common images type are .jpg,.png and .gif
total_500_final$num_companies <- c(1:436)
par(mfrow=c(3,3))
ks = c(25:730)
for(i in 1:706){
a <- ks[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark red")}
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
total_500_final$num_companies <- c(1:436)
par(mfrow=c(3,3))
ks = c(25:730)
for(i in 1:706){
a <- ks[i]
image_type<- round(table(total_500_final[,a])/436,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark red")}
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram()
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram(binwidth=100)
table(total_500_final$total.images)
library(corrplot)
sm <- cor(total_500_social_media)
findCorrelation(sm)
corrplot(cor(total_500_social_media),method="number")
findCorrelation(sm)
library(corrplot)
library(caret)
sm <- cor(total_500_social_media)
findCorrelation(sm)
corrplot(cor(total_500_social_media),method="number")
par(mfrow=c(1,1))
library(corrplot)
library(caret)
sm <- cor(total_500_social_media)
corrplot(cor(total_500_social_media),method="number")
revenue <- total_500_final$Revenues..
revenue <- table(total_500_final$Revenues..)
revenue
ggplot(data=total_500_final,aes(x=Revenues..))+geom_histogram(binwidth=100)
ggplot(data=total_500_final,aes(x=Revenues..))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=Assets..))+geom_histogram(binwidth=100)
ggplot(data=total_500_final,aes(x=Market.value..))+geom_histogram(binwidth=100)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=100)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=20)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=10)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=1)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=100)
ggplot(data=total_500_final,aes(x=Revenues..))+geom_histogram(binwidth=50)
rev <- cut(total_500_final$Revenues..,c(-1,200,483))
table(rev)
rev <- cut(total_500_final$Revenues..,c(-1,150,483))
table(rev)
rev <- cut(total_500_final$Revenues..,c(-1,100,483))
table(rev)
rev <- cut(total_500_final$Revenues..,c(-1,50,483))
table(rev)
ggplot(data=total_500_final,aes(x=Assets..))+geom_histogram(binwidth=100)
as <- cut(total_500_final$Assets..,c(-1,450,1000))
table(as)
as <- cut(total_500_final$Assets..,c(-1,300,1000))
table(as)
ggplot(data=total_500_final,aes(x=Market.value..))+geom_histogram(binwidth=100)
mv <- cut(total_500_final$Market.value..,c(-1,400,1000))
table(mv)
ggplot(data=total_500_final,aes(x=Total.Stockholder.Equity..))+geom_histogram(binwidth=100)
stock <- cut(total_500_final$Total.Stockholder.Equity..,c(-1000,0,1000))
table(stock)
stock <- cut(total_500_final$Total.Stockholder.Equity..,c(-1000,250,1000))
table(stock)
table(rev/436)
table(rev)/436
round(table(rev)/436)
round(table(rev)/436,3)
round(table(as)/436,3)
round(table(mv)/436,3)
round(table(stock)/436,3)
total_500_final$rev <- cut(total_500_final$Revenues..,c(-1,50,483))
total_500_final$rev
