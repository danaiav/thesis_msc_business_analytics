---
title: "Spinellis"
author: "Danai Avratoglou"
date: "31 Οκτωβρίου 2016"
output: html_document
---

```{r}
#we upload the dataset
total_500 <- read.csv("~/GitHub/thesis_msc_business_analytics/total_500.csv", sep=";", na.strings="n/a")
#total_500 <- read.csv("F:/Dropbox/Dani/Spinellis - Diplwmatiki/Jupyter markdown/total_500.csv", sep=";")
#we see how many observations and how many variables we have and then the names of the variables we have
dim(total_500)
names(total_500)
str(total_500)
total_500.sub <- total_500
#We make the factors numbers where it is possible
total_500.sub$Assets.. <- gsub(",", ".", total_500.sub$Assets.. )
total_500.sub$Market.value.. <- gsub(",", ".", total_500.sub$Market.value.. )
total_500.sub$Revenues.. <- gsub(",", ".", total_500.sub$Revenues.. )
total_500.sub$Total.Stockholder.Equity.. <- gsub(",", ".", total_500.sub$Total.Stockholder.Equity.. )
num <- c(2,3,4,5,6,9,10,11,13,14,12,24,25,757,758,759,760,761,762,763,764,765,766,767)
for(i in 1:24){
  k <- num[i]
  total_500.sub[,k] <- as.numeric(as.character(total_500.sub[,k]))}  
str(total_500.sub[757:767])
#We omit the nas from the analysis
total_500_final <- na.omit(total_500.sub)
#we remove the extra value X since it is not necessary for the analysis
#total_500_final$X <- NULL
str(total_500_final)
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
##########################################################################################################
#Firstly we will analyze the social media relevance with the sites.
#We will see how many of the sites have social media and what type of social media
par(mfrow=c(2,3))
#Facebook
social_media_facebook <- round(table(total_500_final$facebook)/436,3)
social_media_facebook
slicelable <- c(paste(38.8,"% no"),paste(61.2,"% yes"))
pie(social_media_facebook,label = slicelable,main="Share of companies with Facebook",col=rainbow(length(social_media_facebook)))
#Twitter
social_media_twitter <- round(table(total_500_final$twitter)/436,3)
social_media_twitter
slicelable <- c(paste(33.7,"% no"),paste(66.3,"% yes"))
pie(social_media_twitter,label = slicelable,main="Share of companies with Twitter",col=rainbow(length(social_media_twitter)))
#Instagram
social_media_instagram <- round(table(total_500_final$instagram)/436,3)
social_media_instagram
slicelable <- c(paste(79.1,"% no"),paste(20.9,"% yes"))
pie(social_media_instagram,label = slicelable,main="Share of companies with Instagram",col=rainbow(length(social_media_instagram)))
#Pinterest
social_media_pinterest <- round(table(total_500_final$pinterest)/436,3)
social_media_pinterest
slicelable <- c(paste(90.4,"% no"),paste(9.6,"% yes"))
pie(social_media_pinterest,label = slicelable,main="Share of companies with Pinterest",col=rainbow(length(social_media_pinterest)))
#Youtube
social_media_youtube <- round(table(total_500_final$youtube)/436,3)
social_media_youtube
slicelable <- c(paste(44.3,"% no"),paste(55.7,"% yes"))
pie(social_media_youtube,label = slicelable,main="Share of companies with Youtube",col=rainbow(length(social_media_youtube)))
#LinkedIn
social_media_linkedin <- round(table(total_500_final$linkedin)/436,3)
social_media_linkedin
slicelable <- c(paste(45.4,"% no"),paste(54.6,"% yes"))
pie(social_media_linkedin,label = slicelable,main="Share of companies with Linkedin",col=rainbow(length(social_media_linkedin)))
#And we can also see for correlations
total_500_social_media <- total_500_final[,c(15:20)]
par(mfrow=c(1,1))
library(corrplot)
cor(total_500_social_media)
corrplot(cor(total_500_social_media),method="number")
#The most high correlation is between facebook and twitter 68%
#While the second highest is between twitter and linkedIn
#########################################################################################################
#We will now check the links by creating an histogram
#Then we create ggplots in order to see in what frequency the links appear
par(mfrow=c(3,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
#########################################################################################################
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
#########################################################################################################
#Now we will see the words in total and in unique count in relation with the readability index
ggplot(data=total_500_final,aes(x=total_words,fill=Readability))+geom_histogram(binwidth=50)
ggplot(data=total_500_final,aes(x=unique_words, fill=Readability))+geom_histogram(binwidth=50)
#########################################################################################################
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram()
#########################################################################################################
#We will see now the frequency of image types that is being used
par(mfrow=c(3,3))
k = c(731,732,733,734,735,736,737,738,739)
for(i in 1:9){
  a <- k[i]
  image_type<- round(table(total_500_final[,a])/436,3)
  barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
#It is obvious that the most common images type are .jpg,.png and .gif
##########################################################################################################
total_500_final$num_companies <- c(1:436)
par(mfrow=c(3,3))
ks = c(25:730)
for(i in 1:706){
  a <- ks[i]
  image_type<- round(table(total_500_final[,a])/436,3)
  barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark red")}
###########################################################################################################
#we make a sub data frame without the image sizes for the time being
#total_500_final_sub <- total_500_final[,-c(25:730)]
#names(total_500_final_sub)
#for(i in 1:436){
#total_500_final_sub$Rank[i] <- total_500_final_sub$X[i]+1}
#total_500_final_sub$X <- NULL
#total_500_final_sub$num_companies <- NULL
#total_500_final_sub$url <- NULL
#total_500_final_sub$Readability <- NULL
#
#pairs(total_500_social_media)
 

