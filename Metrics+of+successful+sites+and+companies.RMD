---
title: "Spinellis"
author: "Danai Avratoglou"
date: "31 Οκτωβρίου 2016"
output: html_document
---

```{r}
#we upload the dataset
total_500 <- read.csv("F:/Dropbox/Dani/Spinellis - Diplwmatiki/Jupyter markdown/total_500.csv", sep=";")
#we see how many observations and how many variables we have and then the names of the variables we have
dim(total_500)
names(total_500)
str(total_500)
#since we know that some pages where not downloaded we have to create a subset that we do not include those pages so as not to have n/a
total_500.sub <- total_500
not_downloadable_sites= c(15,64,86,90,97,118,131,135,141,161,164,216,239,242,275,306,326,363,397,414,416,441,455,464)
for (i in 1:24) {
  nds <- not_downloadable_sites[i]
  total_500.sub <- subset(total_500.sub, X != nds)
}
str(total_500.sub)
names(total_500.sub)
total_500.sub$X
#we remove the extra value X since it is not necessary for the analysis
total_500.sub$X <- NULL
#we upload the libraries beneath that we will use in the analysis
library(ggplot2)
library(reshape2)
library(DAAG)
#We make the variables numeric in order to test them
total_500.sub[,766] <- as.numeric(total_500.sub[,766])
#Firstly we will analyze the social media relevance with the sites.
total_500_social_media <- total_500.sub[,c(6,22,14,15,16,17,18,19)]
#We will see how many of the sites have social media and what type of social media
social_media_facebook <- table(total_500_social_media$facebook)
social_media_twitter <- table(total_500_social_media$twitter)
social_media_instagram <- table(total_500_social_media$instagram)
social_media_pinterest <- table(total_500_social_media$pinterest)
social_media_youtube <- table(total_500_social_media$youtube)
social_media_linkedin <- table(total_500_social_media$linkedin)
par(mfrow=c(2,3))
barplot(social_media_facebook,horiz = FALSE,col = "BLUE") + title ("Facebook link per company")
barplot(social_media_twitter,horiz = FALSE,col = "DARKGREEN") + title ("Twitter link per company")
barplot(social_media_instagram,horiz = FALSE,col = "PINK") + title ("Instagram link per company")
barplot(social_media_pinterest,horiz = FALSE,col = "RED") + title ("pinterest link per company")
barplot(social_media_youtube,horiz = FALSE,col = "DARKred") + title ("youtube link per company")
barplot(social_media_linkedin,horiz = FALSE,col = "DARKBLUE") + title ("linkedin link per company")
par(mfrow=c(1,1))
#We will now check the links by creating an histogram
social_media_external <- table(total_500.sub$external)
social_media_internal <- table(total_500.sub$internal)
social_media_total_links <- table(total_500.sub$total.links)
#In order to put the prices in an ascending order we will first have to change the names of some variables
#In order to achieve that we will create our own functions below
names(social_media_external)
split_str_by_index <- function(target, index) {
  index <- sort(index)
  substr(rep(target, length(index) + 1),
         start = c(1, index),
         stop = c(index -1, nchar(target)))
}
#Taken from https://stat.ethz.ch/pipermail/r-help/2006-March/101023.html
interleave <- function(v1,v2)
{
  ord1 <- 2*(1:length(v1))-1
  ord2 <- 2*(1:length(v2))
  c(v1,v2)[order(c(ord1,ord2))]
}

insert_str <- function(target, insert, index) {
  insert <- insert[order(index)]
  index <- sort(index)
  paste(interleave(split_str_by_index(target, index), insert), collapse="")
}
#Here we create a variable with the numbers of the names that needs changing
changes <- c(1,2,3,6,8,9,15,16,19,21,23,24,26,27,28,30,32:55,57:70)
for (i in 0:53) {
  c <- changes[i]
  names(social_media_external)[c] <- insert_str(names(social_media_external)[c], "0",0)
}
social_media_extrenal <- social_media_external[order(names(social_media_external))]
par(mfrow=c(1,1))
barplot(social_media_external,col = "DARKRED") + title ("External links frequency")
```
