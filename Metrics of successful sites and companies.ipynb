{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First we import the libraries we will need\n",
    "import urllib\n",
    "import urllib2\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First of all we need to find all the name of the sites that belong to fortune 500. This can happen if we seperate\n",
    "#The information needed from the below link\n",
    "url = \"http://www.zyxware.com/articles/4344/list-of-fortune-500-companies-and-their-websites\"\n",
    "list_company_number =[]\n",
    "list_company_name = []\n",
    "list_company_website = []\n",
    "list500_sites = []\n",
    "list500_names = []\n",
    "list500_num = []\n",
    "list500_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In order to extract the needed informations we will create 3 lists. The first one will contain the rank of each site, the\n",
    "#second one will contain the name of the company and the 3rd one will contain the actual link of the company's site.\n",
    "#For achieving this purpose we will create a funstion that will in its turn create those three list.\n",
    "#In order to know if the function worked we will ask it to return the first element of each list along with a sentence.\n",
    "def websites (url): \n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    browser = urllib2.build_opener() \n",
    "    browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    response = browser.open(url)# this might throw an exception if something goes wrong.\n",
    "    myHTML = response.read()\n",
    "    soup = BeautifulSoup(myHTML,\"lxml\")    \n",
    "    o = 0\n",
    "    td_list =[]\n",
    "    for row2 in soup.html.body.findAll('td'):\n",
    "        td_list.insert(o, row2)\n",
    "        o = o + 1\n",
    "    a = 0\n",
    "    b = 1\n",
    "    c = 2\n",
    "    list_numbering = 0\n",
    "    for i in range (0,500):        \n",
    "        num = str(td_list[a])\n",
    "        company = str(td_list[b])\n",
    "        site = str(td_list[c])\n",
    "        c_num = re.findall('>(.+?)</td>',num)  \n",
    "        c_num = str(c_num[0])\n",
    "        c_name = re.findall('>(.+?)</td>',company)\n",
    "        c_name = str(c_name[0])\n",
    "        c_site = re.findall('\">(.+?)</a>',site)\n",
    "        c_site = str(c_site[0])        \n",
    "        list_company_number.insert(list_numbering,c_num)\n",
    "        list_company_name.insert(list_numbering,c_name)\n",
    "        list_company_website.insert(list_numbering,c_site)\n",
    "        a = a + 3\n",
    "        b = b + 3\n",
    "        c = c + 3\n",
    "        list_numbering =  list_numbering + 1 \n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The three lists are ready in ', minutes, ' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three lists are ready in  0.0  minutes\n"
     ]
    }
   ],
   "source": [
    "# After creating the function we should now test that it actually works correctly\n",
    "websites (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The url is ok for : ', 'Walmart')\n",
      "('The url is ok for : ', 'Exxon Mobil')\n",
      "('The url is ok for : ', 'Apple')\n",
      "('The url is ok for : ', 'Berkshire Hathaway')\n",
      "('The url is ok for : ', 'McKesson')\n",
      "('The url is ok for : ', 'UnitedHealth Group')\n",
      "('The url is ok for : ', 'CVS Health')\n",
      "('The url is ok for : ', 'General Motors')\n",
      "('The url is ok for : ', 'Ford Motor')\n",
      "('The url is ok for : ', 'AT&amp;T')\n",
      "('The url is ok for : ', 'General Electric')\n",
      "('The url is ok for : ', 'AmerisourceBergen')\n",
      "('The url is ok for : ', 'Verizon')\n",
      "('The url is ok for : ', 'Chevron')\n",
      "('The url is ok for : ', 'Costco')\n",
      "('The url is ok for : ', 'Fannie Mae')\n",
      "('The url is ok for : ', 'Kroger')\n",
      "('The url is ok for : ', 'Amazon.com')\n",
      "('The url is ok for : ', 'Walgreens Boots Alliance')\n",
      "('The url is ok for : ', 'HP')\n",
      "('The url is ok for : ', 'Cardinal Health')\n",
      "('The url is ok for : ', 'Express Scripts Holding')\n",
      "('The url is ok for : ', 'J.P. Morgan Chase')\n",
      "('The url is ok for : ', 'Boeing')\n",
      "('The url is ok for : ', 'Microsoft')\n",
      "('The url is ok for : ', 'Bank of America Corp.')\n",
      "('The url is ok for : ', 'Wells Fargo')\n",
      "('The url is ok for : ', 'Home Depot')\n",
      "('The url is ok for : ', 'Citigroup')\n",
      "('The url is ok for : ', 'Phillips 66')\n",
      "('The url is ok for : ', 'IBM')\n",
      "('The url is ok for : ', 'Valero Energy')\n",
      "('The url is ok for : ', 'Anthem')\n",
      "('The url is ok for : ', 'Procter &amp; Gamble')\n",
      "('The url is ok for : ', 'State Farm Insurance Cos.')\n",
      "('The url is ok for : ', 'Alphabet')\n",
      "('The url is ok for : ', 'Comcast')\n",
      "('The url is ok for : ', 'Target')\n",
      "('The url is ok for : ', 'Johnson &amp; Johnson')\n",
      "('The url is ok for : ', 'MetLife')\n",
      "('The url is ok for : ', 'Archer Daniels Midland')\n",
      "('The url is ok for : ', 'Marathon Petroleum')\n",
      "('The url is ok for : ', 'Freddie Mac')\n",
      "('The url is ok for : ', 'PepsiCo')\n",
      "('The url is ok for : ', 'United Technologies')\n",
      "('The url is ok for : ', 'Aetna')\n",
      "('The url is ok for : ', 'Lowe\\xe2\\x80\\x99s')\n",
      "('The url is ok for : ', 'UPS')\n",
      "('The url is ok for : ', 'AIG')\n",
      "('The url is ok for : ', 'Prudential Financial')\n",
      "('The url is ok for : ', 'Intel')\n",
      "('The url is ok for : ', 'Humana')\n",
      "('The url is ok for : ', 'Disney')\n",
      "('The url is ok for : ', 'Cisco Systems')\n",
      "('The url is ok for : ', 'Pfizer')\n",
      "('The url is ok for : ', 'Dow Chemical')\n",
      "('The url is ok for : ', 'Sysco')\n",
      "('The url is ok for : ', 'FedEx')\n",
      "('The url is ok for : ', 'Caterpillar')\n",
      "('The url is ok for : ', 'Lockheed Martin')\n",
      "('The url is ok for : ', 'New York Life Insurance')\n",
      "('The url is ok for : ', 'Coca-Cola')\n",
      "('The url is ok for : ', 'HCA Holdings')\n",
      "('The url is ok for : ', 'Ingram Micro')\n",
      "('The url is ok for : ', 'Energy Transfer Equity')\n",
      "('The url is ok for : ', 'Tyson Foods')\n",
      "('The url is ok for : ', 'American Airlines Group')\n",
      "('The url is ok for : ', 'Delta Air Lines')\n",
      "('The url is ok for : ', 'Nationwide')\n",
      "('The url is ok for : ', 'Johnson Controls')\n",
      "('The url is ok for : ', 'Best Buy')\n",
      "('The url is ok for : ', 'Merck')\n",
      "('The url is ok for : ', 'Liberty Mutual Insurance Group')\n",
      "('The url is ok for : ', 'Goldman Sachs Group')\n",
      "('The url is ok for : ', 'Honeywell International')\n",
      "('The url is ok for : ', 'Massachusetts Mutual Life Insurance')\n",
      "('The url is ok for : ', 'Oracle')\n",
      "('The url is ok for : ', 'Morgan Stanley')\n",
      "('The url is ok for : ', 'Cigna')\n",
      "('The url is ok for : ', 'United Continental Holdings')\n",
      "('The url is ok for : ', 'Allstate')\n",
      "('The url is ok for : ', 'TIAA')\n",
      "('The url is ok for : ', 'INTL FCStone')\n",
      "('The url is ok for : ', 'CHS')\n",
      "('The url is ok for : ', 'American Express')\n",
      "('The url is ok for : ', 'Gilead Sciences')\n",
      "('The url is ok for : ', 'Publix Super Markets')\n",
      "('The url is ok for : ', 'General Dynamics')\n",
      "('The url is ok for : ', 'TJX')\n",
      "('The url is ok for : ', 'ConocoPhillips')\n",
      "('The url is ok for : ', 'Nike')\n",
      "('The url is ok for : ', 'World Fuel Services')\n",
      "('The url is ok for : ', '3M')\n",
      "('The url is ok for : ', 'Mondelez International')\n",
      "('The url is ok for : ', 'Exelon')\n",
      "('The url is ok for : ', 'Twenty-First Century Fox')\n",
      "('The url is ok for : ', 'Deere')\n",
      "('The url is ok for : ', 'Tesoro')\n",
      "('The url is ok for : ', 'Time Warner')\n",
      "('The url is ok for : ', 'Northwestern Mutual')\n",
      "('The url is ok for : ', 'DuPont')\n",
      "('The url is ok for : ', 'Avnet')\n",
      "('The url is ok for : ', 'Macy\\xe2\\x80\\x99s')\n",
      "('The url is ok for : ', 'Enterprise Products Partners')\n",
      "('The url is ok for : ', 'Travelers Cos.')\n",
      "('The url is ok for : ', 'Philip Morris International')\n",
      "('The url is ok for : ', 'Rite Aid')\n",
      "('The url is ok for : ', 'Tech Data')\n",
      "('The url is ok for : ', 'McDonald\\xe2\\x80\\x99s')\n",
      "('The url is ok for : ', 'Qualcomm')\n",
      "('The url is ok for : ', 'Sears Holdings')\n",
      "('The url is ok for : ', 'Capital One Financial')\n",
      "('The url is ok for : ', 'EMC')\n",
      "('The url is ok for : ', 'USAA')\n",
      "('The url is ok for : ', 'Duke Energy')\n",
      "('The url is ok for : ', 'Time Warner Cable')\n",
      "('The url is ok for : ', 'Halliburton')\n",
      "('The url is ok for : ', 'Northrop Grumman')\n",
      "('The url is ok for : ', 'Arrow Electronics')\n",
      "('The url is ok for : ', 'Raytheon')\n",
      "('The url is ok for : ', 'Plains GP Holdings')\n",
      "('The url is ok for : ', 'US Foods Holding')\n",
      "('The url is ok for : ', 'AbbVie')\n",
      "('The url is ok for : ', 'Centene')\n",
      "('The url is ok for : ', 'Community Health Systems')\n",
      "('The url is ok for : ', 'Alcoa')\n",
      "('The url is ok for : ', 'International Paper')\n",
      "('The url is ok for : ', 'Emerson Electric')\n",
      "('The url is ok for : ', 'Union Pacific')\n",
      "('The url is ok for : ', 'Amgen')\n",
      "('The url is ok for : ', 'U.S. Bancorp')\n",
      "('The url is ok for : ', 'Staples')\n",
      "('The url is ok for : ', 'Danaher')\n",
      "('The url is ok for : ', 'Whirlpool')\n",
      "('The url is ok for : ', 'Aflac')\n",
      "('The url is ok for : ', 'AutoNation')\n",
      "('The url is ok for : ', 'Progressive')\n",
      "('The url is ok for : ', 'Abbott Laboratories')\n",
      "('The url is ok for : ', 'Dollar General')\n",
      "('The url is ok for : ', 'Tenet Healthcare')\n",
      "('The url is ok for : ', 'Eli Lilly')\n",
      "('The url is ok for : ', 'Southwest Airlines')\n",
      "('The url is ok for : ', 'Penske Automotive Group')\n",
      "('The url is ok for : ', 'ManpowerGroup')\n",
      "('The url is ok for : ', 'Kohl\\xe2\\x80\\x99s')\n",
      "('The url is ok for : ', 'Starbucks')\n",
      "('The url is ok for : ', 'Paccar')\n",
      "('The url is ok for : ', 'Cummins')\n",
      "('The url is ok for : ', 'Altria Group')\n",
      "('The url is ok for : ', 'Xerox')\n",
      "('The url is ok for : ', 'Kimberly-Clark')\n",
      "('The url is ok for : ', 'Hartford Financial Services Group')\n",
      "('The url is ok for : ', 'Kraft Heinz')\n",
      "('The url is ok for : ', 'Lear')\n",
      "('The url is ok for : ', 'Fluor')\n",
      "('The url is ok for : ', 'AECOM')\n",
      "('The url is ok for : ', 'Facebook')\n",
      "('The url is ok for : ', 'Jabil Circuit')\n",
      "('The url is ok for : ', 'CenturyLink')\n",
      "('The url is ok for : ', 'Supervalu')\n",
      "('The url is ok for : ', 'General Mills')\n",
      "('The url is ok for : ', 'Southern')\n",
      "('The url is ok for : ', 'NextEra Energy')\n",
      "('The url is ok for : ', 'Thermo Fisher Scientific')\n",
      "('The url is ok for : ', 'American Electric Power')\n",
      "('The url is ok for : ', 'PG&amp;E Corp.')\n",
      "('The url is ok for : ', 'NGL Energy Partners')\n",
      "('The url is ok for : ', 'Bristol-Myers Squibb')\n",
      "('The url is ok for : ', 'Goodyear Tire &amp; Rubber')\n",
      "('The url is ok for : ', 'Nucor')\n",
      "('The url is ok for : ', 'PNC Financial Services Group')\n",
      "('The url is ok for : ', 'Health Net')\n",
      "('The url is ok for : ', 'Micron Technology')\n",
      "('The url is ok for : ', 'Colgate-Palmolive')\n",
      "('The url is ok for : ', 'Freeport-McMoRan')\n",
      "('The url is ok for : ', 'ConAgra Foods')\n",
      "('The url is ok for : ', 'Gap')\n",
      "('The url is ok for : ', 'Baker Hughes')\n",
      "('The url is ok for : ', 'Bank of New York Mellon Corp.')\n",
      "('The url is ok for : ', 'Dollar Tree')\n",
      "('The url is ok for : ', 'Whole Foods Market')\n",
      "('The url is ok for : ', 'PPG Industries')\n",
      "('The url is ok for : ', 'Genuine Parts')\n",
      "('The url is ok for : ', 'Icahn Enterprises')\n",
      "('The url is ok for : ', 'Performance Food Group')\n",
      "('The url is ok for : ', 'Omnicom Group')\n",
      "('The url is ok for : ', 'DISH Network')\n",
      "('The url is ok for : ', 'FirstEnergy')\n",
      "('The url is ok for : ', 'Monsanto')\n",
      "('The url is ok for : ', 'AES')\n",
      "('The url is ok for : ', 'CarMax')\n",
      "('The url is ok for : ', 'National Oilwell Varco')\n",
      "('The url is ok for : ', 'NRG Energy')\n",
      "('The url is ok for : ', 'Western Digital')\n",
      "('The url is ok for : ', 'Marriott International')\n",
      "('The url is ok for : ', 'Office Depot')\n",
      "('The url is ok for : ', 'Nordstrom')\n",
      "('The url is ok for : ', 'Kinder Morgan')\n",
      "('The url is ok for : ', 'Aramark')\n",
      "('The url is ok for : ', 'DaVita HealthCare Partners')\n",
      "('The url is ok for : ', 'Molina Healthcare')\n",
      "('The url is ok for : ', 'WellCare Health Plans')\n",
      "('The url is ok for : ', 'CBS')\n",
      "('The url is ok for : ', 'Visa')\n",
      "('The url is ok for : ', 'Lincoln National')\n",
      "('The url is ok for : ', 'Ecolab')\n",
      "('The url is ok for : ', 'Kellogg')\n",
      "('The url is ok for : ', 'C.H. Robinson Worldwide')\n",
      "('The url is ok for : ', 'Textron')\n",
      "('The url is ok for : ', 'Loews')\n",
      "('The url is ok for : ', 'Illinois Tool Works')\n",
      "('The url is ok for : ', 'Synnex')\n",
      "('The url is ok for : ', 'Viacom')\n",
      "('The url is ok for : ', 'HollyFrontier')\n",
      "('The url is ok for : ', 'Land O\\xe2\\x80\\x99Lakes')\n",
      "('The url is ok for : ', 'Devon Energy')\n",
      "('The url is ok for : ', 'PBF Energy')\n",
      "('The url is ok for : ', 'Yum Brands')\n",
      "('The url is ok for : ', 'Texas Instruments')\n",
      "('The url is ok for : ', 'CDW')\n",
      "('The url is ok for : ', 'Waste Management')\n",
      "('The url is ok for : ', 'Marsh &amp; McLennan')\n",
      "('The url is ok for : ', 'Chesapeake Energy')\n",
      "('The url is ok for : ', 'Parker-Hannifin')\n",
      "('The url is ok for : ', 'Occidental Petroleum')\n",
      "('The url is ok for : ', 'Guardian Life Ins. Co. of America')\n",
      "('The url is ok for : ', 'Farmers Insurance Exchange')\n",
      "('The url is ok for : ', 'J.C. Penney')\n",
      "('The url is ok for : ', 'Consolidated Edison')\n",
      "('The url is ok for : ', 'Cognizant Technology Solutions')\n",
      "('The url is ok for : ', 'VF')\n",
      "('The url is ok for : ', 'Ameriprise Financial')\n",
      "('The url is ok for : ', 'Computer Sciences')\n",
      "('The url is ok for : ', 'L Brands')\n",
      "('The url is ok for : ', 'Jacobs Engineering Group')\n",
      "('The url is ok for : ', 'Principal Financial')\n",
      "('The url is ok for : ', 'Ross Stores')\n",
      "('The url is ok for : ', 'Bed Bath &amp; Beyond')\n",
      "('The url is ok for : ', 'CSX')\n",
      "('The url is ok for : ', 'Toys \\xe2\\x80\\x9cR\\xe2\\x80\\x9d Us')\n",
      "('The url is ok for : ', 'Las Vegas Sands')\n",
      "('The url is ok for : ', 'Leucadia National')\n",
      "('The url is ok for : ', 'Dominion Resources')\n",
      "('The url is ok for : ', 'United States Steel')\n",
      "('The url is ok for : ', 'L-3 Communications')\n",
      "('The url is ok for : ', 'Edison International')\n",
      "('The url is ok for : ', 'Entergy')\n",
      "('The url is ok for : ', 'ADP')\n",
      "('The url is ok for : ', 'First Data')\n",
      "('The url is ok for : ', 'BlackRock')\n",
      "('The url is ok for : ', 'WestRock')\n",
      "('The url is ok for : ', 'Voya Financial')\n",
      "('The url is ok for : ', 'Sherwin-Williams')\n",
      "('The url is ok for : ', 'Hilton Worldwide Holdings')\n",
      "('The url is ok for : ', 'R.R. Donnelley &amp; Sons')\n",
      "('The url is ok for : ', 'Stanley Black &amp; Decker')\n",
      "('The url is ok for : ', 'Xcel Energy')\n",
      "('The url is ok for : ', 'Murphy USA')\n",
      "('The url is ok for : ', 'CBRE Group')\n",
      "('The url is ok for : ', 'D.R. Horton')\n",
      "('The url is ok for : ', 'Estee Lauder')\n",
      "('The url is ok for : ', 'Praxair')\n",
      "('The url is ok for : ', 'Biogen')\n",
      "('The url is ok for : ', 'State Street Corp.')\n",
      "('The url is ok for : ', 'Unum Group')\n",
      "('The url is ok for : ', 'Reynolds American')\n",
      "('The url is ok for : ', 'Group 1 Automotive')\n",
      "('The url is ok for : ', 'Henry Schein')\n",
      "('The url is ok for : ', 'Hertz Global Holdings')\n",
      "('The url is ok for : ', 'Norfolk Southern')\n",
      "('The url is ok for : ', 'Reinsurance Group of America')\n",
      "('The url is ok for : ', 'Public Service Enterprise Group')\n",
      "('The url is ok for : ', 'BB&amp;T Corp.')\n",
      "('The url is ok for : ', 'DTE Energy')\n",
      "('The url is ok for : ', 'Assurant')\n",
      "('The url is ok for : ', 'Global Partners')\n",
      "('The url is ok for : ', 'Huntsman')\n",
      "('The url is ok for : ', 'Becton Dickinson')\n",
      "('The url is ok for : ', 'Sempra Energy')\n",
      "('The url is ok for : ', 'AutoZone')\n",
      "('The url is ok for : ', 'Navistar International')\n",
      "('The url is ok for : ', 'Precision Castparts')\n",
      "('The url is ok for : ', 'Discover Financial Services')\n",
      "('The url is ok for : ', 'Liberty Interactive')\n",
      "('The url is ok for : ', 'W.W. Grainger')\n",
      "('The url is ok for : ', 'Baxter International')\n",
      "('The url is ok for : ', 'Stryker')\n",
      "('The url is ok for : ', 'Air Products &amp; Chemicals')\n",
      "('The url is ok for : ', 'Western Refining')\n",
      "('The url is ok for : ', 'Universal Health Services')\n",
      "('The url is ok for : ', 'Owens &amp; Minor')\n",
      "('The url is ok for : ', 'Charter Communications')\n",
      "('The url is ok for : ', 'Advance Auto Parts')\n",
      "('The url is ok for : ', 'MasterCard')\n",
      "('The url is ok for : ', 'Applied Materials')\n",
      "('The url is ok for : ', 'Eastman Chemical')\n",
      "('The url is ok for : ', 'Sonic Automotive')\n",
      "('The url is ok for : ', 'Ally Financial')\n",
      "('The url is ok for : ', 'CST Brands')\n",
      "('The url is ok for : ', 'eBay')\n",
      "('The url is ok for : ', 'Lennar')\n",
      "('The url is ok for : ', 'GameStop')\n",
      "('The url is ok for : ', 'Reliance Steel &amp; Aluminum')\n",
      "('The url is ok for : ', 'Hormel Foods')\n",
      "('The url is ok for : ', 'Celgene')\n",
      "('The url is ok for : ', 'Genworth Financial')\n",
      "('The url is ok for : ', 'PayPal Holdings')\n",
      "('The url is ok for : ', 'Priceline Group')\n",
      "('The url is ok for : ', 'MGM Resorts International')\n",
      "('The url is ok for : ', 'Autoliv')\n",
      "('The url is ok for : ', 'Fidelity National Financial')\n",
      "('The url is ok for : ', 'Republic Services')\n",
      "('The url is ok for : ', 'Corning')\n",
      "('The url is ok for : ', 'Peter Kiewit Sons\\xe2\\x80\\x99')\n",
      "('The url is ok for : ', 'Univar')\n",
      "('The url is ok for : ', 'Mosaic')\n",
      "('The url is ok for : ', 'Core-Mark Holding')\n",
      "('The url is ok for : ', 'Thrivent Financial for Lutherans')\n",
      "('The url is ok for : ', 'Cameron International')\n",
      "('The url is ok for : ', 'HD Supply Holdings')\n",
      "('The url is ok for : ', 'Crown Holdings')\n",
      "('The url is ok for : ', 'EOG Resources')\n",
      "('The url is ok for : ', 'Veritiv')\n",
      "('The url is ok for : ', 'Anadarko Petroleum')\n",
      "('The url is ok for : ', 'Laboratory Corp. of America')\n",
      "('The url is ok for : ', 'Pacific Life')\n",
      "('The url is ok for : ', 'News Corp.')\n",
      "('The url is ok for : ', 'Jarden')\n",
      "('The url is ok for : ', 'SunTrust Banks')\n",
      "('The url is ok for : ', 'Avis Budget Group')\n",
      "('The url is ok for : ', 'Broadcom')\n",
      "('The url is ok for : ', 'American Family Insurance Group')\n",
      "('The url is ok for : ', 'Level 3 Communications')\n",
      "('The url is ok for : ', 'Tenneco')\n",
      "('The url is ok for : ', 'United Natural Foods')\n",
      "('The url is ok for : ', 'Dean Foods')\n",
      "('The url is ok for : ', 'Campbell Soup')\n",
      "('The url is ok for : ', 'Mohawk Industries')\n",
      "('The url is ok for : ', 'BorgWarner')\n",
      "('The url is ok for : ', 'PVH')\n",
      "('The url is ok for : ', 'Ball')\n",
      "('The url is ok for : ', 'O\\xe2\\x80\\x99Reilly Automotive')\n",
      "('The url is ok for : ', 'Eversource Energy')\n",
      "('The url is ok for : ', 'Franklin Resources')\n",
      "('The url is ok for : ', 'Masco')\n",
      "('The url is ok for : ', 'Lithia Motors')\n",
      "('The url is ok for : ', 'KKR')\n",
      "('The url is ok for : ', 'Oneok')\n",
      "('The url is ok for : ', 'Newmont Mining')\n",
      "('The url is ok for : ', 'PPL')\n",
      "('The url is ok for : ', 'SpartanNash')\n",
      "('The url is ok for : ', 'Quanta Services')\n",
      "('The url is ok for : ', 'XPO Logistics')\n",
      "('The url is ok for : ', 'Ralph Lauren')\n",
      "('The url is ok for : ', 'Interpublic Group')\n",
      "('The url is ok for : ', 'Steel Dynamics')\n",
      "('The url is ok for : ', 'WESCO International')\n",
      "('The url is ok for : ', 'Quest Diagnostics')\n",
      "('The url is ok for : ', 'Boston Scientific')\n",
      "('The url is ok for : ', 'AGCO')\n",
      "('The url is ok for : ', 'Foot Locker')\n",
      "('The url is ok for : ', 'Hershey')\n",
      "('The url is ok for : ', 'CenterPoint Energy')\n",
      "('The url is ok for : ', 'Williams')\n",
      "('The url is ok for : ', 'Dick\\xe2\\x80\\x99s Sporting Goods')\n",
      "('The url is ok for : ', 'Live Nation Entertainment')\n",
      "('The url is ok for : ', 'Mutual of Omaha Insurance')\n",
      "('The url is ok for : ', 'W.R. Berkley')\n",
      "('The url is ok for : ', 'LKQ')\n",
      "('The url is ok for : ', 'Avon Products')\n",
      "('The url is ok for : ', 'Darden Restaurants')\n",
      "('The url is ok for : ', 'Kindred Healthcare')\n",
      "('The url is ok for : ', 'Weyerhaeuser')\n",
      "('The url is ok for : ', 'Casey\\xe2\\x80\\x99s General Stores')\n",
      "('The url is ok for : ', 'Sealed Air')\n",
      "('The url is ok for : ', 'Fifth Third Bancorp')\n",
      "('The url is ok for : ', 'Dover')\n",
      "('The url is ok for : ', 'Huntington Ingalls Industries')\n",
      "('The url is ok for : ', 'Netflix')\n",
      "('The url is ok for : ', 'Dillard\\xe2\\x80\\x99s')\n",
      "('The url is ok for : ', 'EMCOR Group')\n",
      "('The url is ok for : ', 'Jones Financial')\n",
      "('The url is ok for : ', 'AK Steel Holding')\n",
      "('The url is ok for : ', 'UGI')\n",
      "('The url is ok for : ', 'Expedia')\n",
      "('The url is ok for : ', 'salesforce.com')\n",
      "('The url is ok for : ', 'Targa Resources')\n",
      "('The url is ok for : ', 'Apache')\n",
      "('The url is ok for : ', 'Spirit AeroSystems Holdings')\n",
      "('The url is ok for : ', 'Expeditors International of Washington')\n",
      "('The url is ok for : ', 'Anixter International')\n",
      "('The url is ok for : ', 'Fidelity National Information Services')\n",
      "('The url is ok for : ', 'Asbury Automotive Group')\n",
      "('The url is ok for : ', 'Hess')\n",
      "('The url is ok for : ', 'Ryder System')\n",
      "('The url is ok for : ', 'Terex')\n",
      "('The url is ok for : ', 'Coca-Cola European Partners')\n",
      "('The url is ok for : ', 'Auto-Owners Insurance')\n",
      "('The url is ok for : ', 'Cablevision Systems')\n",
      "('The url is ok for : ', 'Symantec')\n",
      "('The url is ok for : ', 'Charles Schwab')\n",
      "('The url is ok for : ', 'Calpine')\n",
      "('The url is ok for : ', 'CMS Energy')\n",
      "('The url is ok for : ', 'Alliance Data Systems')\n",
      "('The url is ok for : ', 'JetBlue Airways')\n",
      "('The url is ok for : ', 'Discovery Communications')\n",
      "('The url is ok for : ', 'Trinity Industries')\n",
      "('The url is ok for : ', 'Sanmina')\n",
      "('The url is ok for : ', 'NCR')\n",
      "('The url is ok for : ', 'FMC Technologies')\n",
      "('The url is ok for : ', 'Erie Insurance Group')\n",
      "('The url is ok for : ', 'Rockwell Automation')\n",
      "('The url is ok for : ', 'Dr Pepper Snapple Group')\n",
      "('The url is ok for : ', 'iHeartMedia')\n",
      "('The url is ok for : ', 'Tractor Supply')\n",
      "('The url is ok for : ', 'J.B. Hunt Transport Services')\n",
      "('The url is ok for : ', 'Commercial Metals')\n",
      "('The url is ok for : ', 'Owens-Illinois')\n",
      "('The url is ok for : ', 'Harman International Industries')\n",
      "('The url is ok for : ', 'Baxalta')\n",
      "('The url is ok for : ', 'American Financial Group')\n",
      "('The url is ok for : ', 'NetApp')\n",
      "('The url is ok for : ', 'Graybar Electric')\n",
      "('The url is ok for : ', 'Oshkosh')\n",
      "('The url is ok for : ', 'Ameren')\n",
      "('The url is ok for : ', 'A-Mark Precious Metals')\n",
      "('The url is ok for : ', 'Barnes &amp; Noble')\n",
      "('The url is ok for : ', 'Dana Holding')\n",
      "('The url is ok for : ', 'Constellation Brands')\n",
      "('The url is ok for : ', 'LifePoint Health')\n",
      "('The url is ok for : ', 'Zimmer Biomet Holdings')\n",
      "('The url is ok for : ', 'Harley-Davidson')\n",
      "('The url is ok for : ', 'PulteGroup')\n",
      "('The url is ok for : ', 'Newell Brands')\n",
      "('The url is ok for : ', 'Avery Dennison')\n",
      "('The url is ok for : ', 'Jones Lang LaSalle')\n",
      "('The url is ok for : ', 'WEC Energy Group')\n",
      "('The url is ok for : ', 'Marathon Oil')\n",
      "('The url is ok for : ', 'TravelCenters of America')\n",
      "('The url is ok for : ', 'United Rentals')\n",
      "('The url is ok for : ', 'HRG Group')\n",
      "('The url is ok for : ', 'Old Republic International')\n",
      "('The url is ok for : ', 'Windstream Holdings')\n",
      "('The url is ok for : ', 'Starwood Hotels &amp; Resorts')\n",
      "('The url is ok for : ', 'Delek US Holdings')\n",
      "('The url is ok for : ', 'Packaging Corp. of America')\n",
      "('The url is ok for : ', 'Quintiles Transnational Holdings')\n",
      "('The url is ok for : ', 'Hanesbrands')\n",
      "('The url is ok for : ', 'Realogy Holdings')\n",
      "('The url is ok for : ', 'Mattel')\n",
      "('The url is ok for : ', 'Motorola Solutions')\n",
      "('The url is ok for : ', 'J.M. Smucker')\n",
      "('The url is ok for : ', 'Regions Financial')\n",
      "('The url is ok for : ', 'Celanese')\n",
      "('The url is ok for : ', 'Clorox')\n",
      "('The url is ok for : ', 'Ingredion')\n",
      "('The url is ok for : ', 'Genesis Healthcare')\n",
      "('The url is ok for : ', 'Peabody Energy')\n",
      "('The url is ok for : ', 'Alaska Air Group')\n",
      "('The url is ok for : ', 'Seaboard')\n",
      "('The url is ok for : ', 'Frontier Communications')\n",
      "('The url is ok for : ', 'Amphenol')\n",
      "('The url is ok for : ', 'Lansing Trade Group')\n",
      "('The url is ok for : ', 'SanDisk')\n",
      "('The url is ok for : ', 'St. Jude Medical')\n",
      "('The url is ok for : ', 'Wyndham Worldwide')\n",
      "('The url is ok for : ', 'Kelly Services')\n",
      "('The url is ok for : ', 'Western Union')\n",
      "('The url is ok for : ', 'Envision Healthcare Holdings')\n",
      "('The url is ok for : ', 'Visteon')\n",
      "('The url is ok for : ', 'Arthur J. Gallagher')\n",
      "('The url is ok for : ', 'Host Hotels &amp; Resorts')\n",
      "('The url is ok for : ', 'Ashland')\n",
      "('The url is ok for : ', 'Insight Enterprises')\n",
      "('The url is ok for : ', 'Energy Future Holdings')\n",
      "('The url is ok for : ', 'Markel')\n",
      "('The url is ok for : ', 'Essendant')\n",
      "('The url is ok for : ', 'CH2M Hill')\n",
      "('The url is ok for : ', 'Western &amp; Southern Financial Group')\n",
      "('The url is ok for : ', 'Owens Corning')\n",
      "('The url is ok for : ', 'S&amp;P Global')\n",
      "('The url is ok for : ', 'Raymond James Financial')\n",
      "('The url is ok for : ', 'NiSource')\n",
      "('The url is ok for : ', 'Airgas')\n",
      "('The url is ok for : ', 'ABM Industries')\n",
      "('The url is ok for : ', 'Citizens Financial Group')\n",
      "('The url is ok for : ', 'Booz Allen Hamilton Holding')\n",
      "('The url is ok for : ', 'Simon Property Group')\n",
      "('The url is ok for : ', 'Domtar')\n",
      "('The url is ok for : ', 'Rockwell Collins')\n",
      "('The url is ok for : ', 'Lam Research')\n",
      "('The url is ok for : ', 'Fiserv')\n",
      "('The url is ok for : ', 'Spectra Energy')\n",
      "('The url is ok for : ', 'Navient')\n",
      "('The url is ok for : ', 'Big Lots')\n",
      "('The url is ok for : ', 'Telephone &amp; Data Systems')\n",
      "('The url is ok for : ', 'First American Financial')\n",
      "('The url is ok for : ', 'NVR')\n",
      "('The url is ok for : ', 'Cincinnati Financial')\n",
      "('The url is ok for : ', 'Burlington Stores')\n"
     ]
    }
   ],
   "source": [
    "#Try to validate each page url #pip install validators\n",
    "import validators\n",
    "for num in range(len(list_company_website)):\n",
    "    line = 'http://' + str(list_company_website[num])\n",
    "    x = validators.url(line)    \n",
    "    if x == True:\n",
    "        print ('The url is ok for : ', list_company_name[num])\n",
    "    else:        \n",
    "        print (\"not valid\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The next step is to download and save in a new list the 500 sites.\n",
    "## We will create a new function that will do this by reading the list \"list_company_websites\" that we created \n",
    "## with the previous function\n",
    "\n",
    "def list_company_HTML (list_company_website,list_company_name,start,end):\n",
    "    import time\n",
    "    browser2 = urllib2.build_opener()\n",
    "    browser2.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    for i in range (start,end):\n",
    "        k = str(i + 1)\n",
    "        lc = str(list_company_website[i])        \n",
    "        lc = lc.replace(\"'\",\"\")   \n",
    "        lc = lc.replace(\"[\",\"\")\n",
    "        lc = lc.replace(\"]\",\"\")\n",
    "        lcn = str(list_company_name[i])        \n",
    "        lcn = lcn.replace(\"'\",\"\")   \n",
    "        lcn = lcn.replace(\"[\",\"\")\n",
    "        lcn = lcn.replace(\"]\",\"\")\n",
    "        url2= 'http://' + lc\n",
    "        #an exception might be thrown, so the code should be in a try-except block\n",
    "        try:            \n",
    "            response2=browser2.open(url2)\n",
    "        except Exception: # this describes what to do if an exception is thrown\n",
    "             continue     \n",
    "        #read the response in html format. This is essentially a long piece of text\n",
    "        myHTML2=response2.read()\n",
    "        list500_sites.insert(i,myHTML2)\n",
    "        list500_names.insert(i,lcn)\n",
    "        list500_url.insert(i,lc)\n",
    "        list500_num.insert(i,k)\n",
    "        #wait for 2 seconds\n",
    "        time.sleep(2)\n",
    "        #print (\"The site \" + k + \" has been downloaded!\")\n",
    "    print (\"We downloaded: \",len(list500_sites),\" sites!\")\n",
    "    #print (len(list500_names),list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n",
      "('We downloaded: ', 25, ' sites!')\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "stop = 25\n",
    "for i in range (0,1): #i am not downloading all the pages for the time being for reasons of running faster the process during the tests\n",
    "    print (start)\n",
    "    print (stop)    \n",
    "    list_company_HTML (list_company_website,list_company_name,start,stop)\n",
    "    start = stop\n",
    "    stop = stop + 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#As we can see there is one site that hasn't been downloaded in order to keep track of the sites that we could not download\n",
    "#we will create a new list that we will keep them all together there\n",
    "not_d = []\n",
    "def not_downloadables (list500_names,list_company_name):\n",
    "    met = 0\n",
    "    for i in range(0,100):#normally it would be till 500 but now we test for the first 150 we have downloaded\n",
    "        ct = list_company_name[i]\n",
    "        if ct not in list500_names:\n",
    "            not_d.insert(met,ct)\n",
    "    print(not_d)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tesoro', 'Nike', 'Publix Super Markets']\n"
     ]
    }
   ],
   "source": [
    "#Now we will run the function to see which sites haven;t been downloaded\n",
    "not_downloadables (list500_names,list_company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Retreiving the social media from each site\n",
    "#First create empty lists for the ones that we will need to calculate\n",
    "sm_f = []\n",
    "sm_t = []\n",
    "sm_i = []\n",
    "sm_p = []\n",
    "sm_y = []\n",
    "sm_l = []   \n",
    "sm_nm = [] \n",
    "nm = []\n",
    "sm_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then create a function that will feel in those lists so as to make the data frame later on\n",
    "\n",
    "def socialmedia (list500_sites,list500_names,list500_url):\n",
    "    for num in range(len(list500_names)):\n",
    "        if list500_sites[num] !=  \"\":\n",
    "            hand = str(list500_sites[num])\n",
    "            sm = ['facebook.com','twitter.com','instagram.com','pinterest.com','youtube.com','linkedin.com'] \n",
    "            number = 0 \n",
    "            for index in range(len(sm)):\n",
    "                x = sm[index]\n",
    "                photo = re.findall(x,hand)                                \n",
    "                if (len(photo) > 0):\n",
    "                    if x == 'facebook.com':\n",
    "                        answerf = 'yes'\n",
    "                    if x == 'twitter.com':\n",
    "                        answert = 'yes'\n",
    "                    if x == 'instagram.com':\n",
    "                        answeri = 'yes'\n",
    "                    if x == 'pinterest.com':\n",
    "                        answerp = 'yes'\n",
    "                    if x == 'youtube.com':\n",
    "                        answery = 'yes'\n",
    "                    if x =='linkedin.com':\n",
    "                        answerl = 'yes'                   \n",
    "                else:\n",
    "                     if x == 'facebook.com':\n",
    "                        answerf = 'no'\n",
    "                     if x == 'twitter.com':\n",
    "                        answert = 'no'\n",
    "                     if x == 'instagram.com':\n",
    "                        answeri = 'no'\n",
    "                     if x == 'pinterest.com':\n",
    "                        answerp = 'no'\n",
    "                     if x == 'youtube.com':\n",
    "                        answery = 'no'\n",
    "                     if x =='linkedin.com':\n",
    "                        answerl = 'no'                 \n",
    "            sm_nm.insert(num,list500_names[num]) \n",
    "            nm.insert(num,num)\n",
    "            sm_url.insert(num,list500_url[num])\n",
    "            sm_f.insert(num,answerf)\n",
    "            sm_t.insert(num,answert)\n",
    "            sm_i.insert(num,answeri)\n",
    "            sm_p.insert(num,answerp)\n",
    "            sm_y.insert(num,answery)\n",
    "            sm_l.insert(num,answerl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we will run the function for the 25 first sites for starters\n",
    "socialmedia (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>facebook</th>\n",
       "      <th>instagram</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>twitter</th>\n",
       "      <th>url</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>www.walmart.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>www.apple.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company facebook instagram linkedin pinterest twitter  \\\n",
       "0      Walmart      yes       yes       no       yes     yes   \n",
       "1  Exxon Mobil      yes        no       no        no      no   \n",
       "2        Apple       no        no      yes        no      no   \n",
       "\n",
       "                  url youtube  \n",
       "0     www.walmart.com     yes  \n",
       "1  www.exxonmobil.com      no  \n",
       "2       www.apple.com     yes  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally we create the data frame with the elements we found            \n",
    "d = {'company' : pd.Series(sm_nm, index=[nm]),'url' : pd.Series(sm_url, index=[nm]),\n",
    "     'facebook' : pd.Series(sm_f, index=[nm]),'twitter' : pd.Series(sm_t, index=[nm]),\n",
    "     'instagram' : pd.Series(sm_i, index=[nm]),'pinterest' : pd.Series(sm_p, index=[nm]),\n",
    "     'youtube' : pd.Series(sm_y, index=[nm]),'linkedin' : pd.Series(sm_l, index=[nm]),}\n",
    "social_media = pd.DataFrame(d)    \n",
    "social_media.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the lists we will need for the data frame\n",
    "l_nm = []\n",
    "l_ex = []\n",
    "l_in = []\n",
    "l_t = []\n",
    "nm = []\n",
    "l_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the function that will calculate the different type of links\n",
    "def links (list500_sites,list500_names,list500_url):\n",
    "    for num in range(len(list500_names)):\n",
    "        line = str(list500_sites[num])\n",
    "        href = re.findall('href',line)\n",
    "        external = re.findall('href=\"https:',line)\n",
    "        ex = (len(external))\n",
    "        alllinks = (len(href))\n",
    "        internal =  (len(href) - len(external))\n",
    "        l_nm.insert(num,list500_names[num])            \n",
    "        l_ex.insert(num,ex)\n",
    "        l_t.insert(num,alllinks)\n",
    "        l_in.insert(num,internal)\n",
    "        nm.insert(num,num)\n",
    "        l_url.insert(num,list500_url[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run the function in order to find the external, internal and total links of each site\n",
    "#For now we are running for the first 25 sites only\n",
    "links (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>external</th>\n",
       "      <th>internal</th>\n",
       "      <th>total links</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>169</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>23</td>\n",
       "      <td>784</td>\n",
       "      <td>807</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>5</td>\n",
       "      <td>276</td>\n",
       "      <td>281</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company  external  internal  total links                 url\n",
       "0      Walmart        47       122          169     www.walmart.com\n",
       "1  Exxon Mobil        23       784          807  www.exxonmobil.com\n",
       "2        Apple         5       276          281       www.apple.com"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe so as to be able to see the results of the function we run\n",
    "d2 = {'company' : pd.Series(l_nm, index=[nm]),'url' : pd.Series(l_url, index=[nm]),\n",
    "      'external' : pd.Series(l_ex, index=[nm]),'internal' : pd.Series(l_in, index=[nm]),\n",
    "     'total links' : pd.Series(l_t, index=[nm])}\n",
    "sites_links = pd.DataFrame(d2)    \n",
    "sites_links.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The initial lists we will need in order to calculate the loading time\n",
    "lt_nm = [] \n",
    "lt_time = []\n",
    "nm = []\n",
    "lt_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the function that will calculate the loading time\n",
    "def loadtime (list_company_website,list500_names,list500_url):\n",
    "    from time import time\n",
    "    browser2 = urllib2.build_opener()\n",
    "    browser2.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    for num in range(len(list500_names)):\n",
    "        lc = str(list_company_website[num])        \n",
    "        lc = lc.replace(\"'\",\"\")   \n",
    "        lc = lc.replace(\"[\",\"\")\n",
    "        lc = lc.replace(\"]\",\"\")\n",
    "        url2 = 'http://' + lc        \n",
    "        try:\n",
    "            response2 = browser2.open(url2)\n",
    "        except Exception: \n",
    "             continue#     \n",
    "        start_time = time()\n",
    "        myHTML2 = response2.read()\n",
    "        end_time = time()\n",
    "        response2.close()\n",
    "        l_t = round(end_time-start_time, 3) #in order to be more readable we rounded the time\n",
    "        loadt = str(l_t)\n",
    "        lt_nm.insert(num,list500_names[num])            \n",
    "        lt_time.insert(num,loadt)\n",
    "        nm.insert(num,num)\n",
    "        lt_url.insert(num,list500_url[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running the function for the first 25 sites\n",
    "loadtime (list_company_website,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>loading time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>0.415</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>3.307</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>0.078</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company loading time                 url\n",
       "0      Walmart        0.415     www.walmart.com\n",
       "1  Exxon Mobil        3.307  www.exxonmobil.com\n",
       "2        Apple        0.078       www.apple.com"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the data frame with the loading times\n",
    "d3 = {'company' : pd.Series(lt_nm, index=[nm]),'url' : pd.Series(lt_url, index=[nm]),\n",
    "      'loading time' : pd.Series(lt_time, index=[nm])}\n",
    "loading_time = pd.DataFrame(d3)    \n",
    "loading_time.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find out how many and what type of images each site has\n",
    "#first we create the initially empty lists\n",
    "p_p = []\n",
    "p_d = []\n",
    "p_jpg = []\n",
    "p_jpeg = []\n",
    "p_gif = []\n",
    "p_tif = []\n",
    "p_tiff = []\n",
    "p_bmp = []\n",
    "p_jpe = []\n",
    "p_nm = []\n",
    "p_tt =[]\n",
    "nm = []\n",
    "p_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we create the function that will explore the html pages and search for the images\n",
    "def images (list500_sites,list500_names,list500_url):\n",
    "    for num in range(len(list500_names)):\n",
    "        line = str(list500_sites[num])\n",
    "        image = ['.png','.dib','.jpg','.jpeg','.bmp','.jpe','.gif','.tif','.tiff'] \n",
    "        totalnumber = 0 \n",
    "        for index in range(len(image)):\n",
    "            x = image[index]\n",
    "            photo = re.findall(x,line)\n",
    "            if x == '.png':\n",
    "                p = str (len(photo))\n",
    "            if x == '.dib':\n",
    "                d = str (len(photo))\n",
    "            if x == '.jpg':\n",
    "                jpg = str (len(photo))\n",
    "            if x == '.jpeg':\n",
    "                jpeg = str (len(photo))\n",
    "            if x == '.gif':\n",
    "                gif = str (len(photo))\n",
    "            if x == '.tif':\n",
    "                tif = str (len(photo))\n",
    "            if x == '.tiff':\n",
    "                tiff = str (len(photo))\n",
    "            if x == '.bmp':\n",
    "                bmp = str (len(photo))\n",
    "            if x == '.jpe':\n",
    "                jpe = str (len(photo))\n",
    "            totalnumber = len(photo) + totalnumber\n",
    "        total = str (totalnumber)\n",
    "        p_nm.insert(num,list500_names[num])            \n",
    "        p_p.insert(num,p)  \n",
    "        p_d.insert(num,d)  \n",
    "        p_jpg.insert(num,jpg)  \n",
    "        p_jpeg.insert(num,jpeg)  \n",
    "        p_gif.insert(num,gif)  \n",
    "        p_tif.insert(num,tif)  \n",
    "        p_tiff.insert(num,tiff)  \n",
    "        p_bmp.insert(num,bmp)  \n",
    "        p_jpe.insert(num,jpe)  \n",
    "        p_tt.insert(num,total)\n",
    "        nm.insert(num,num)\n",
    "        p_url.insert(num,list500_url[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we run the function for the first 20 sites for now\n",
    "images (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.bmp</th>\n",
       "      <th>.dib</th>\n",
       "      <th>.gif</th>\n",
       "      <th>.jpe</th>\n",
       "      <th>.jpeg</th>\n",
       "      <th>.jpg</th>\n",
       "      <th>.png</th>\n",
       "      <th>.tif</th>\n",
       "      <th>.tiff</th>\n",
       "      <th>company</th>\n",
       "      <th>total images</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>84</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>367</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>23</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  .bmp .dib .gif .jpe .jpeg .jpg .png .tif .tiff      company total images  \\\n",
       "0    0    0   26  104   104   84   43    6     0      Walmart          367   \n",
       "1    0    0    1    0     0   16    2    4     0  Exxon Mobil           23   \n",
       "2    0    0    1    0     0    0    2    0     0        Apple            3   \n",
       "\n",
       "                  url  \n",
       "0     www.walmart.com  \n",
       "1  www.exxonmobil.com  \n",
       "2       www.apple.com  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally we create a dataframe in order to see the results of the function\n",
    "d4 = {'company' : pd.Series(p_nm, index=[nm]),'url' : pd.Series(p_url, index=[nm]),\n",
    "      '.png' : pd.Series(p_p, index=[nm]),'.dib' : pd.Series(p_d, index=[nm]),\n",
    "'.jpg' : pd.Series(p_jpg, index=[nm]),'.jpeg' : pd.Series(p_jpeg, index=[nm]),\n",
    "'.bmp' : pd.Series(p_bmp, index=[nm]),'.jpe' : pd.Series(p_jpe, index=[nm]),\n",
    "'.gif' : pd.Series(p_gif, index=[nm]),'.tif' : pd.Series(p_tif, index=[nm]),\n",
    "'.tiff' : pd.Series(p_tiff, index=[nm]), 'total images' : pd.Series(p_tt, index=[nm])}\n",
    "images_types = pd.DataFrame(d4)    \n",
    "images_types.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we will find the different dimensions that each site uses\n",
    "#initially we create the empty lists we will need\n",
    "nm = []\n",
    "s_comp = []\n",
    "s_dimensions = []\n",
    "s_times = []\n",
    "s_tt_dif_dim = []\n",
    "ht = [] #list of different heights in each case\n",
    "wt = [] #list of different widths in each case\n",
    "h_w = [] # combinations of height and width\n",
    "dif_size = []  \n",
    "un_size = [] \n",
    "s_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#With the below function we will gather in a variable all the different dimensions \n",
    "#and in another one all the times that each dimension occures for each html code\n",
    "def find_dif_sizes (list500_sites,list500_names,list500_url):\n",
    "    for num in range(len(list500_names)):\n",
    "        nm.insert(num,num)                  \n",
    "        s_comp.insert(num,list500_names[num])\n",
    "        s_url.insert(num,list500_url[num])\n",
    "        line = str(list500_sites[num]) #read each line of the list500_sites that contains each html code\n",
    "        soup = BeautifulSoup(line, \"lxml\")\n",
    "        # we create 2 local variables so as to gather the different dimensions and occurencies  of each page seperately\n",
    "        s_dimensions_local = []\n",
    "        s_times_local = []\n",
    "        hw = 0 # we use it for the lists of height and width\n",
    "        for tag in soup.find_all('img'): # find all the img in the first site html\n",
    "            #Since in some cases either the height or the width is missing we would like to keep only the ones that have both dimensions\n",
    "             h = tag.attrs.get('height', None)\n",
    "             w = tag.attrs.get('width', None)\n",
    "             #we use if to check which ones have both        \n",
    "             if h != None:\n",
    "                 if w != None:\n",
    "                     ht.insert(hw,h)\n",
    "                     wt.insert(hw,w)\n",
    "                     hw = hw + 1                        \n",
    "        hw2 = 0\n",
    "        for l in range(len(ht)):\n",
    "             h_w_c = ht[l] + 'x' + wt[l]    #we create a str with the form (300x300) so as to be more easily to read later on \n",
    "             h_w.insert(hw2,h_w_c)  #we put it in a new list\n",
    "             hw2 = hw2 + 1    \n",
    "        if h_w == []:#we check if there are not any dimensions available\n",
    "             nm.insert(num,num)                  \n",
    "             s_comp.insert(num,list500_names[num])\n",
    "             s_dimensions.insert(num,0)\n",
    "             s_times.insert(num,0)    \n",
    "        if h_w != []:#now we continue with the cases where the dimensions are indeed available             \n",
    "             from collections import Counter\n",
    "             hw_unique = Counter(h_w)\n",
    "             hw_unique2 = str(hw_unique) #the unique different dimensions for the specific site\n",
    "            #Due to the fact that we are talking about a list we have to split the parts we need \n",
    "             split1 = hw_unique2.split('{')\n",
    "             a = split1[1]\n",
    "             split2 = a.split('}')\n",
    "             b = split2[0]\n",
    "             split3 = b.split(',')\n",
    "             finalsplit = []\n",
    "             fs = []\n",
    "             z = 0\n",
    "             m = 1\n",
    "             j = 0\n",
    "             z1 = 0\n",
    "             m1 = 1\n",
    "            #each of the items in split3 has a form '300x300 : 15' and in order to create the dataframe we have \n",
    "            #to split this form and keep the informations in different list\n",
    "             for numb in split3:                \n",
    "                 oldstring = numb\n",
    "                 newstring = oldstring.replace(\"'\", \"\")\n",
    "                 new = newstring.replace(\"'\",\"\")\n",
    "                 string = new.replace(\" \",\"\")\n",
    "                 finalstring = string.split(':')\n",
    "                    #the finalstring is a list that contains the dimensions and the occurencies\n",
    "                    #in order toseperate in different lists we create an additional loop\n",
    "                 for xx in range(len(finalstring)):\n",
    "                     ax = finalstring[xx]\n",
    "                     if 'x' in ax:\n",
    "                         s_dimensions_local.insert(z1,finalstring[xx])\n",
    "                         z1 = z1 + 1\n",
    "                     else:\n",
    "                         s_times_local.insert(m1,finalstring[xx])\n",
    "                         m1 = m1 + 1  \n",
    "            #Now we can add to the lists the parts we created so as to have them all gathered together             \n",
    "             s_dimensions.insert(num,s_dimensions_local)\n",
    "             s_times.insert(num,s_times_local)                \n",
    "    print(\"Completed\")\n",
    "    print (s_comp,nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n",
      "(['Walmart', 'Exxon Mobil', 'Apple', 'Berkshire Hathaway', 'McKesson', 'UnitedHealth Group', 'CVS Health', 'General Motors', 'Ford Motor', 'AT&amp;T', 'General Electric', 'AmerisourceBergen', 'Verizon', 'Chevron', 'Costco', 'Fannie Mae', 'Kroger', 'Amazon.com', 'Walgreens Boots Alliance', 'HP', 'Cardinal Health', 'Express Scripts Holding', 'J.P. Morgan Chase', 'Boeing', 'Microsoft', 'Bank of America Corp.', 'Wells Fargo', 'Home Depot', 'Citigroup', 'Phillips 66', 'IBM', 'Valero Energy', 'Anthem', 'Procter &amp; Gamble', 'State Farm Insurance Cos.', 'Alphabet', 'Comcast', 'Target', 'Johnson &amp; Johnson', 'MetLife', 'Archer Daniels Midland', 'Marathon Petroleum', 'Freddie Mac', 'PepsiCo', 'United Technologies', 'Aetna', 'Lowe\\xe2\\x80\\x99s', 'UPS', 'AIG', 'Prudential Financial', 'Intel', 'Humana', 'Disney', 'Cisco Systems', 'Pfizer', 'Dow Chemical', 'Sysco', 'FedEx', 'Caterpillar', 'Lockheed Martin', 'New York Life Insurance', 'Coca-Cola', 'HCA Holdings', 'Ingram Micro', 'Energy Transfer Equity', 'Tyson Foods', 'American Airlines Group', 'Delta Air Lines', 'Nationwide', 'Johnson Controls', 'Best Buy', 'Merck', 'Liberty Mutual Insurance Group', 'Goldman Sachs Group', 'Honeywell International', 'Massachusetts Mutual Life Insurance', 'Oracle', 'Morgan Stanley', 'Cigna', 'United Continental Holdings', 'Allstate', 'TIAA', 'INTL FCStone', 'CHS', 'American Express', 'Gilead Sciences', 'General Dynamics', 'TJX', 'ConocoPhillips', 'World Fuel Services', '3M', 'Mondelez International', 'Exelon', 'Twenty-First Century Fox', 'Deere', 'Time Warner', 'Northwestern Mutual'], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96])\n"
     ]
    }
   ],
   "source": [
    "#Run the function for the first 20 sites\n",
    "find_dif_sizes (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the unique different image dimensions and put them on a list\n",
    "def unique_dif_sizes (s_dimensions,list500_names):\n",
    "    ds = 0\n",
    "    for num in range(len(list500_names)):\n",
    "        for s in s_dimensions[num]:\n",
    "            dif_size.insert(ds,s)\n",
    "            ds = ds + 1\n",
    "    dsu = 0\n",
    "    for i in dif_size:\n",
    "        if i not in un_size:\n",
    "            un_size.insert(dsu,i)\n",
    "            dsu = dsu + 1\n",
    "    print(un_size)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['144x144', '15x75', '44x556', '800x1200', '24pxx133px', '21pxx173px', '70x125', '1x1', '50x45', '400x300', '292pxx292px', '200pxx200px', '1279pxx984px', '300pxx1500px', '29x29', '115x223', '160x233', '41x192', '28x221', '300x993', '15x12', '70x70', '170x300', '120x220', '83x250', '115x150', '150x150', '11x8', '75x85', 'x', '23x27', '262x100%', '86x226', '280x691', '42x168', '1x700', '27x156', '24x24', '1x10', '10x1', '8x10', '1x660', '19x1', '17x16', '25x125', '2x2', '397x700', '640x1920', '843x1900', '76x209', '53x84', '61x120', '35x35', '10pxx10px', '107x128', '197x875', '403x961', '20x113', '40x90', '0x0', '421x638', '254x638', '24x83', '300x1320', '160x300', '134x122', '160x475', '382x449', '210x320', '47x123', '32x116', '576x1024', '681x1024', '20x20', '100x100', '80x100', '450x1600', '200x1600', '16x16', '468x990', '42x86']\n"
     ]
    }
   ],
   "source": [
    "#Run the finction unique_dif_sizes\n",
    "unique_dif_sizes (s_dimensions,list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The lists we will need for the next function\n",
    "t_f_s = []\n",
    "ttf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function in order to check whether or not each company has these dimensions\n",
    "def dimensions_per_company (un_size,list500_names):\n",
    "    t_f_s.insert(0,un_size)\n",
    "    ttf.insert(0,t_f_s)\n",
    "    for num in range(len(list500_names)):\n",
    "        s1a = s_dimensions[num] #dimensions of site num\n",
    "        where = [] #empty list\n",
    "        wh = 0\n",
    "        haveornot = []\n",
    "        for er in range (len(un_size)):\n",
    "            for sizea in s1a:\n",
    "                if sizea == un_size[er]:\n",
    "                    where.insert(wh,str(er))\n",
    "                    break\n",
    "            if str(er) in where:\n",
    "               haveornot.insert(er,True)                    \n",
    "            else:\n",
    "               haveornot.insert(er,False)\n",
    "                    \n",
    "        t_f_s.insert(num + 1,haveornot)\n",
    "        ttf.insert(num + 1,t_f_s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run the function dimensions_per_company\n",
    "dimensions_per_company (un_size,list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Walmart', 'Exxon Mobil', 'Apple', 'Berkshire Hathaway', 'McKesson', 'UnitedHealth Group', 'CVS Health', 'General Motors', 'Ford Motor', 'AT&amp;T', 'General Electric', 'AmerisourceBergen', 'Verizon', 'Chevron', 'Costco', 'Fannie Mae', 'Kroger', 'Amazon.com', 'Walgreens Boots Alliance', 'HP', 'Cardinal Health', 'Express Scripts Holding', 'J.P. Morgan Chase', 'Boeing', 'Microsoft', 'Bank of America Corp.', 'Wells Fargo', 'Home Depot', 'Citigroup', 'Phillips 66', 'IBM', 'Valero Energy', 'Anthem', 'Procter &amp; Gamble', 'State Farm Insurance Cos.', 'Alphabet', 'Comcast', 'Target', 'Johnson &amp; Johnson', 'MetLife', 'Archer Daniels Midland', 'Marathon Petroleum', 'Freddie Mac', 'PepsiCo', 'United Technologies', 'Aetna', 'Lowe\\xe2\\x80\\x99s', 'UPS', 'AIG', 'Prudential Financial', 'Intel', 'Humana', 'Disney', 'Cisco Systems', 'Pfizer', 'Dow Chemical', 'Sysco', 'FedEx', 'Caterpillar', 'Lockheed Martin', 'New York Life Insurance', 'Coca-Cola', 'HCA Holdings', 'Ingram Micro', 'Energy Transfer Equity', 'Tyson Foods', 'American Airlines Group', 'Delta Air Lines', 'Nationwide', 'Johnson Controls', 'Best Buy', 'Merck', 'Liberty Mutual Insurance Group', 'Goldman Sachs Group', 'Honeywell International', 'Massachusetts Mutual Life Insurance', 'Oracle', 'Morgan Stanley', 'Cigna', 'United Continental Holdings', 'Allstate', 'TIAA', 'INTL FCStone', 'CHS', 'American Express', 'Gilead Sciences', 'General Dynamics', 'TJX', 'ConocoPhillips', 'World Fuel Services', '3M', 'Mondelez International', 'Exelon', 'Twenty-First Century Fox', 'Deere', 'Time Warner', 'Northwestern Mutual']\n"
     ]
    }
   ],
   "source": [
    "print(s_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company                 url\n",
       "0      Walmart     www.walmart.com\n",
       "1  Exxon Mobil  www.exxonmobil.com\n",
       "2        Apple       www.apple.com"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an initial dataframe where we will add the sizes later on\n",
    "d7 = {'company' : pd.Series(s_comp, index=[nm]),'url' : pd.Series(s_url, index=[nm])}\n",
    "sizess = pd.DataFrame(d7)    \n",
    "sizess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we want to break the variable t_f_s in order to add the columns to the dataframe                  \n",
    "#Finally we create the data frame with the elements we found \n",
    "def final_dimensions_dataframe (un_size,t_f_s,list500_names):\n",
    "    for q in range(len(un_size)):\n",
    "        names = un_size[q]\n",
    "        var = []\n",
    "        for num in range(len(list500_names)):\n",
    "            a = t_f_s[num+1]\n",
    "            var.insert(num,a[q])\n",
    "        sizess[names] = pd.Series(var, index=sizess.index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>144x144</th>\n",
       "      <th>15x75</th>\n",
       "      <th>44x556</th>\n",
       "      <th>800x1200</th>\n",
       "      <th>24pxx133px</th>\n",
       "      <th>21pxx173px</th>\n",
       "      <th>70x125</th>\n",
       "      <th>1x1</th>\n",
       "      <th>...</th>\n",
       "      <th>576x1024</th>\n",
       "      <th>681x1024</th>\n",
       "      <th>20x20</th>\n",
       "      <th>100x100</th>\n",
       "      <th>80x100</th>\n",
       "      <th>450x1600</th>\n",
       "      <th>200x1600</th>\n",
       "      <th>16x16</th>\n",
       "      <th>468x990</th>\n",
       "      <th>42x86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>www.walmart.com</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>www.apple.com</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       company                 url 144x144  15x75 44x556 800x1200 24pxx133px  \\\n",
       "0      Walmart     www.walmart.com    True  False  False    False      False   \n",
       "1  Exxon Mobil  www.exxonmobil.com    True  False  False    False      False   \n",
       "2        Apple       www.apple.com    True  False  False    False      False   \n",
       "\n",
       "  21pxx173px 70x125    1x1  ...   576x1024 681x1024  20x20 100x100 80x100  \\\n",
       "0      False  False  False  ...      False    False  False   False  False   \n",
       "1      False  False  False  ...      False    False  False   False  False   \n",
       "2      False  False  False  ...      False    False  False   False  False   \n",
       "\n",
       "  450x1600 200x1600  16x16 468x990  42x86  \n",
       "0    False    False  False   False  False  \n",
       "1    False    False  False   False  False  \n",
       "2    False    False  False   False  False  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the function final_dimensions_dataframe\n",
    "final_dimensions_dataframe (un_size,t_f_s,list500_names)\n",
    "sizess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we would like to find the words in the text and the unique words of each html page\n",
    "#First of all we need to have a dictionary with which we would check if the word we found truly exists\n",
    "#The dictionary is available in the internet from a github acount from where we are going to read it\n",
    "url_dictionary = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n",
    "browser = urllib2.build_opener()\n",
    "browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "response = browser.open(url_dictionary)\n",
    "html_dictionary = response.read()\n",
    "html_dictionary\n",
    "dicti = str(html_dictionary)\n",
    "#dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict_new = dicti.split(\"\\\\n\")\n",
    "dict_new = dicti.split(\"\\n\")\n",
    "dict_new[49] #the first 49 parts are not words so we have to remove them from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_final = []\n",
    "df = 0\n",
    "for i in range (50,len(dict_new)):\n",
    "    forfinal = dict_new[i]\n",
    "    forfinal = forfinal.replace(\"'\",\"\")\n",
    "    dict_final.insert(df,forfinal)\n",
    "    df = df + 1\n",
    "dict_final[0] #This is the original dictionary with which we will check each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#And now we will find each html file which words has inside\n",
    "empty = []\n",
    "wordsin = []\n",
    "ocin = []\n",
    "def html_which_word (x,list500_sites):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start_t = time()\n",
    "    for num in range(0,x):\n",
    "        line = str(list500_sites[num]) \n",
    "        wordcount={}\n",
    "        corwordcount={}\n",
    "        simeiastiksis = [\"/\",\".\",\",\",\"=\",\">\",\"<\",\"?\",\"|\",\":\",\"_\",\"]\",\"[\",\"$\",\"&\",\"%\",\"(\",\")\",\"{\",\"}\",'\"',\";\",\"\\\\\",\"-\",\"!\",\"+\",\"#\",\"=\",\"@\",\"^\",\"*\",\"'\"]\n",
    "        for ss in range(len(simeiastiksis)):\n",
    "            simeio = simeiastiksis[ss]     \n",
    "            line = line.replace(simeio, \" \")\n",
    "        for word1 in line.split():\n",
    "            word1 = word1.lower()\n",
    "            if word1 in dict_final:\n",
    "                if word1 not in wordcount:\n",
    "                    wordcount[word1] = 1\n",
    "                else:\n",
    "                    wordcount[word1] += 1     \n",
    "        wordsin_local = []\n",
    "        wl = 0\n",
    "        ocin_local = []\n",
    "        for k,v in wordcount.items():\n",
    "               #print (k,v)\n",
    "               wordsin_local.insert(wl,str(k))\n",
    "               ocin_local.insert(wl,str(v))\n",
    "               wl = wl + 1\n",
    "        wordsin.insert(num,wordsin_local) # final list with all the words in each site\n",
    "        ocin.insert(num,ocin_local)  #final list with all the occurencies of the words in each site\n",
    "    end_t = time()\n",
    "    total_t = round(end_t - start_t,3)\n",
    "    total_ = round(total_t / 60,1)\n",
    "    print('finished ',str(x) ,' sites in: ', str(total_),' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('finished ', '2', ' sites in: ', '3.5', ' minutes')\n"
     ]
    }
   ],
   "source": [
    "html_which_word (2,list500_sites) #test the code for 2 sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company                 url\n",
       "0      Walmart     www.walmart.com\n",
       "1  Exxon Mobil  www.exxonmobil.com\n",
       "2        Apple       www.apple.com"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the dataframe for the words and unique words\n",
    "d8 = {'company' : pd.Series(list500_names, index=[nm]),'url' : pd.Series(list500_url, index=[nm])}\n",
    "wordss = pd.DataFrame(d8)    \n",
    "wordss.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>total_words</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>www.walmart.com</td>\n",
       "      <td>1492</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "      <td>801</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>www.apple.com</td>\n",
       "      <td>390</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company                 url  total_words  unique_words\n",
       "0      Walmart     www.walmart.com         1492           403\n",
       "1  Exxon Mobil  www.exxonmobil.com          801           151\n",
       "2        Apple       www.apple.com          390           128"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the two lists we will need in order to make the dataframe\n",
    "l1 = []\n",
    "l2 = []\n",
    "for num in range(len(list500_names)):   \n",
    "    line = str(list500_sites[num]) \n",
    "    total_words = len(wordsin[num])\n",
    "    occurencies = ocin[num] \n",
    "    l1.insert(num,total_words)\n",
    "    count = 0 \n",
    "    for a in occurencies :\n",
    "        if a == '1':\n",
    "            count = count + 1\n",
    "    l2.insert(num,count)\n",
    "wordss['total_words'] = pd.Series(l1, index=sizess.index)\n",
    "wordss['unique_words'] = pd.Series(l2, index=sizess.index)          \n",
    "wordss.head(3)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to validate the html code we will use the w3 validator\n",
    "#We will validate each url and then we will open the url of the validation page\n",
    "#so as to extract the errors, the info warnings and the non-document-error io informations \n",
    "#First we create the empty lists we would use later on\n",
    "num_errors = []\n",
    "num_info_warnings = []\n",
    "num_non_doc = [] \n",
    "nm = []\n",
    "num_open_page = []\n",
    "empty = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we create the function that will pull the informations we want\n",
    "def html_validation (list500_url,list500_names):\n",
    "    for num in range(len(list500_names)):\n",
    "        url_check = \"https://validator.w3.org/nu/?doc=https://\" + list500_url[num]\n",
    "        browser = urllib2.build_opener()\n",
    "        browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "        response = browser.open(url_check)\n",
    "        html_check = response.read()\n",
    "        html_check\n",
    "        check = str(html_check)\n",
    "        er = 0\n",
    "        err = 0\n",
    "        errr = 0\n",
    "        e = False\n",
    "        if check != empty:\n",
    "            e = True\n",
    "            soup = BeautifulSoup(check,\"lxml\")\n",
    "            o = 0\n",
    "            keyf = []\n",
    "            for row in soup.html.body.findAll('div'):\n",
    "                keyf.insert(o,row)\n",
    "                o = o + 1\n",
    "            #print(len(keyf),list500_url[num], \"site number: \", str(num))        \n",
    "            if len(keyf) != 0:       \n",
    "                    keyfin = str(keyf[2]) #the elements we need is in the 2nd div of the code\n",
    "                    dol= re.findall('class=\"error\"',keyfin)            \n",
    "                    er = er + len(dol)\n",
    "                    doll= re.findall('class=\"info warning\"',keyfin)            \n",
    "                    err = err + len(doll)\n",
    "                    dolll= re.findall('class=\"non-document-error io\"',keyfin)            \n",
    "                    errr = errr + len(dolll)\n",
    "        num_errors.insert(num,er)\n",
    "        num_info_warnings.insert(num,err)\n",
    "        num_non_doc.insert(num,errr)  \n",
    "        nm.insert(num,num) \n",
    "        num_open_page.insert(num,e)\n",
    "        #print(er,err,errr,e)\n",
    "        print(\"Done for site: \", str(num + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done for site: ', '1')\n",
      "('Done for site: ', '2')\n",
      "('Done for site: ', '3')\n",
      "('Done for site: ', '4')\n",
      "('Done for site: ', '5')\n",
      "('Done for site: ', '6')\n",
      "('Done for site: ', '7')\n",
      "('Done for site: ', '8')\n",
      "('Done for site: ', '9')\n",
      "('Done for site: ', '10')\n",
      "('Done for site: ', '11')\n",
      "('Done for site: ', '12')\n",
      "('Done for site: ', '13')\n",
      "('Done for site: ', '14')\n",
      "('Done for site: ', '15')\n",
      "('Done for site: ', '16')\n",
      "('Done for site: ', '17')\n",
      "('Done for site: ', '18')\n",
      "('Done for site: ', '19')\n",
      "('Done for site: ', '20')\n",
      "('Done for site: ', '21')\n",
      "('Done for site: ', '22')\n",
      "('Done for site: ', '23')\n",
      "('Done for site: ', '24')\n",
      "('Done for site: ', '25')\n",
      "('Done for site: ', '26')\n",
      "('Done for site: ', '27')\n",
      "('Done for site: ', '28')\n",
      "('Done for site: ', '29')\n",
      "('Done for site: ', '30')\n",
      "('Done for site: ', '31')\n",
      "('Done for site: ', '32')\n",
      "('Done for site: ', '33')\n",
      "('Done for site: ', '34')\n",
      "('Done for site: ', '35')\n",
      "('Done for site: ', '36')\n",
      "('Done for site: ', '37')\n",
      "('Done for site: ', '38')\n",
      "('Done for site: ', '39')\n",
      "('Done for site: ', '40')\n",
      "('Done for site: ', '41')\n",
      "('Done for site: ', '42')\n",
      "('Done for site: ', '43')\n",
      "('Done for site: ', '44')\n",
      "('Done for site: ', '45')\n",
      "('Done for site: ', '46')\n",
      "('Done for site: ', '47')\n",
      "('Done for site: ', '48')\n",
      "('Done for site: ', '49')\n",
      "('Done for site: ', '50')\n",
      "('Done for site: ', '51')\n",
      "('Done for site: ', '52')\n",
      "('Done for site: ', '53')\n",
      "('Done for site: ', '54')\n",
      "('Done for site: ', '55')\n",
      "('Done for site: ', '56')\n",
      "('Done for site: ', '57')\n",
      "('Done for site: ', '58')\n",
      "('Done for site: ', '59')\n",
      "('Done for site: ', '60')\n",
      "('Done for site: ', '61')\n",
      "('Done for site: ', '62')\n",
      "('Done for site: ', '63')\n",
      "('Done for site: ', '64')\n",
      "('Done for site: ', '65')\n",
      "('Done for site: ', '66')\n",
      "('Done for site: ', '67')\n",
      "('Done for site: ', '68')\n",
      "('Done for site: ', '69')\n",
      "('Done for site: ', '70')\n",
      "('Done for site: ', '71')\n",
      "('Done for site: ', '72')\n",
      "('Done for site: ', '73')\n",
      "('Done for site: ', '74')\n",
      "('Done for site: ', '75')\n",
      "('Done for site: ', '76')\n",
      "('Done for site: ', '77')\n",
      "('Done for site: ', '78')\n",
      "('Done for site: ', '79')\n",
      "('Done for site: ', '80')\n",
      "('Done for site: ', '81')\n",
      "('Done for site: ', '82')\n",
      "('Done for site: ', '83')\n",
      "('Done for site: ', '84')\n",
      "('Done for site: ', '85')\n",
      "('Done for site: ', '86')\n",
      "('Done for site: ', '87')\n",
      "('Done for site: ', '88')\n",
      "('Done for site: ', '89')\n",
      "('Done for site: ', '90')\n",
      "('Done for site: ', '91')\n",
      "('Done for site: ', '92')\n",
      "('Done for site: ', '93')\n",
      "('Done for site: ', '94')\n",
      "('Done for site: ', '95')\n",
      "('Done for site: ', '96')\n",
      "('Done for site: ', '97')\n"
     ]
    }
   ],
   "source": [
    "#Now we will run the function we created\n",
    "html_validation (list500_url,list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The_page_opened</th>\n",
       "      <th>company</th>\n",
       "      <th>non-document-error</th>\n",
       "      <th>number_of_errors</th>\n",
       "      <th>number_of_warning</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>0</td>\n",
       "      <td>741</td>\n",
       "      <td>1</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  The_page_opened      company  non-document-error  number_of_errors  \\\n",
       "0            True      Walmart                   0               741   \n",
       "1            True  Exxon Mobil                   0                55   \n",
       "2            True        Apple                   0                14   \n",
       "\n",
       "   number_of_warning                 url  \n",
       "0                  1     www.walmart.com  \n",
       "1                 29  www.exxonmobil.com  \n",
       "2                  6       www.apple.com  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After the checks we will create the dataframe with the informations we want\n",
    "d9 = {'company' : pd.Series(list500_names, index=[nm]),'url' : pd.Series(list500_url, index=[nm]),\n",
    "      'The_page_opened' : pd.Series(num_open_page, index=[nm]),'number_of_errors' : pd.Series(num_errors, index=[nm]),\n",
    "      'number_of_warning' : pd.Series(num_info_warnings, index=[nm]),'non-document-error' : pd.Series(num_non_doc, index=[nm])}\n",
    "html_val = pd.DataFrame(d9)    \n",
    "html_val.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The next step is to take some informations from the fortune 500 site for each company\n",
    "#In order to achieve that we should open the pages for each one of the sites seperately\n",
    "#Since there is a pattern in the way the pages are named it shouldn't be difficult\n",
    "#Firstly we should create the pattern with which we will download the pages\n",
    "#By running the code we can see that the names of each comany are not written exactly as we have saved them\n",
    "#So we do need to alter the names first in order for the below function to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a new list with alterations in order for the names\n",
    "#to match the ones that fortune 500 uses so that we can download the html page\n",
    "list_company_name_new = []\n",
    "for num in range (0,500):\n",
    "    cn = list_company_name[num]\n",
    "    cn = cn.replace(\" \", \"-\")\n",
    "    cn = cn.replace(\"&\", \"\")\n",
    "    cn = cn.replace(\"’\", \"\")\n",
    "    cn = cn.replace(\".\", \"-\")\n",
    "    cn = cn.replace(\"amp;\", \"\")    \n",
    "    company = cn.lower()\n",
    "    list_company_name_new.insert(num,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fortune_pages = []\n",
    "def fortune500 (list_company_name_new):\n",
    "    for num3 in range (0,20): #we put 20 for testing\n",
    "        i = str (num3 +1)    \n",
    "        companyname =  list_company_name_new[num3]\n",
    "        browser = urllib2.build_opener() #because i work from different computers with different pyhton version some commands are not recognizable in each version\n",
    "        browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "        site_fortune = \"http://beta.fortune.com/fortune500/\"+companyname+\"-\"+ i    \n",
    "        page_fortune = browser.open(site_fortune)\n",
    "        html_fortune = page_fortune.read()    \n",
    "        print(\"fortune page for company: \", list_company_name_new[num3],i)\n",
    "        fortune_pages.insert(num3, html_fortune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fortune page for company: ', 'Walmart', '1')\n",
      "('fortune page for company: ', 'Exxon-Mobil', '2')\n",
      "('fortune page for company: ', 'Apple', '3')\n",
      "('fortune page for company: ', 'Berkshire-Hathaway', '4')\n",
      "('fortune page for company: ', 'McKesson', '5')\n",
      "('fortune page for company: ', 'UnitedHealth-Group', '6')\n",
      "('fortune page for company: ', 'CVS-Health', '7')\n",
      "('fortune page for company: ', 'General-Motors', '8')\n",
      "('fortune page for company: ', 'Ford-Motor', '9')\n",
      "('fortune page for company: ', 'ATT', '10')\n",
      "('fortune page for company: ', 'General-Electric', '11')\n",
      "('fortune page for company: ', 'AmerisourceBergen', '12')\n",
      "('fortune page for company: ', 'Verizon', '13')\n",
      "('fortune page for company: ', 'Chevron', '14')\n",
      "('fortune page for company: ', 'Costco', '15')\n",
      "('fortune page for company: ', 'Fannie-Mae', '16')\n",
      "('fortune page for company: ', 'Kroger', '17')\n",
      "('fortune page for company: ', 'Amazon-com', '18')\n",
      "('fortune page for company: ', 'Walgreens-Boots-Alliance', '19')\n",
      "('fortune page for company: ', 'HP', '20')\n"
     ]
    }
   ],
   "source": [
    "#Run the function we created\n",
    "fortune500 (list_company_name_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now that we have opened the url we are going to extract some informations that we need from them\n",
    "#In order to do that initially we have to create the variables we will need\n",
    "keyf =[]\n",
    "per =[]\n",
    "rev_dol = []\n",
    "rev_per = []\n",
    "prof_dol = []\n",
    "prof_per = []\n",
    "assets_dol = []\n",
    "assets_per = []\n",
    "tse_dol = []\n",
    "tse_per = []\n",
    "mar_dol = []\n",
    "mar_per = []\n",
    "market = []\n",
    "nm = []\n",
    "ln = []\n",
    "urln = []\n",
    "empty = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range (0,20):   #we put 20 for testing\n",
    "    nm.insert(n,n)\n",
    "    ln.insert(n,list_company_name[n])\n",
    "    urln.insert(n,list_company_website[n])\n",
    "    files = fortune_pages[n]\n",
    "    soup = BeautifulSoup(files,\"lxml\")\n",
    "    o=0\n",
    "    for row in soup.html.body.findAll('tbody'):\n",
    "        keyf.insert(o,row)\n",
    "        o=o+1\n",
    "    keyfin = keyf[0] #the elements we need is in the first tbody of the code\n",
    "    data = keyfin.findAll('td')\n",
    "    \n",
    "    one = str(data[0]) # revenue\n",
    "    two = str(data[1]) # revenue in dollars we need to extract this\n",
    "    revdol= re.findall('>\\$(.+?)</td>',two) #we keep only the numbers\n",
    "    if revdol[0] != empty:\n",
    "        w = revdol[0]\n",
    "        a = w.replace(\"[\", \"\")\n",
    "        r = a.replace(\"]\",\"\")\n",
    "        rev_dol.insert(n,r)\n",
    "    tria = str(data[2])# revenue in percentage we need to extract this as well\n",
    "    revper= re.findall('>(.+?)%</td>',tria) #we keep only the numbers\n",
    "    if revper != empty:    \n",
    "        w = revper[0]\n",
    "        a = w.replace(\"[\", \"\")\n",
    "        r1 = a.replace(\"]\",\"\")    \n",
    "        rev_per.insert(n,r1) \n",
    "    \n",
    "    four = str(data[3])   # profit     \n",
    "    five = str(data[4])   # profit in dollars we need to extract this   \n",
    "    profdol= re.findall('>\\$(.+?)</td>',five) #we keep only the numbers\n",
    "    if profdol != empty:\n",
    "        w = profdol[0]\n",
    "        a = w.replace(\"[\", \"\")\n",
    "        p = a.replace(\"]\",\"\")\n",
    "        prof_dol.insert(n,p)\n",
    "    six = str(data[5])    # profit in percentage we need to extract this as well   \n",
    "    profper = re.findall('>(.+?)%</td>',six) #we keep only the numbers\n",
    "    if profper != empty:\n",
    "        w = profper[0]\n",
    "        a = w.replace(\"[\", \"\")\n",
    "        p1 = a.replace(\"]\",\"\")    \n",
    "        prof_per.insert(n,p1)\n",
    "    \n",
    "    seven = str(data[6]) #assets\n",
    "    eight = str(data[7]) #assets in dollars we need to extract this\n",
    "    assetsdol= re.findall('>\\$(.+?)</td>',eight) #we keep only the numbers\n",
    "    if assetsdol != empty:\n",
    "        w = assetsdol[0]\n",
    "        a = w.replace(\"[\", \"\")\n",
    "        ass = a.replace(\"]\",\"\")\n",
    "        assets_dol.insert(n,ass)\n",
    "    \n",
    "    ten = str(data[9]) #Total Stockholder Equity ($M)    \n",
    "    eleven = str(data[10]) #Total Stockholder Equity ($M) in dollars we need to extract this\n",
    "    tsedol= re.findall('>\\$(.+?)</td>',eleven) #we keep only the numbers\n",
    "    if tsedol != empty:\n",
    "        w = tsedol[0]\n",
    "        a = w.replace(\"[\", \"\")\n",
    "        ts = a.replace(\"]\",\"\")\n",
    "        tse_dol.insert(n,ts)\n",
    "    \n",
    "    thirteen = str(data[12]) # market value\n",
    "    fourteen = str(data[13]) # market value in dollars we need to extract this\n",
    "    mardol= re.findall('>\\$(.+?)</td>',fourteen) #we keep only the numbers\n",
    "    if mardol != empty:\n",
    "        w = mardol[0]\n",
    "        a = w.replace(\"[\", \"\")\n",
    "        mar = a.replace(\"]\",\"\")\n",
    "        mar_dol.insert(n,mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets $</th>\n",
       "      <th>Market value $</th>\n",
       "      <th>Revenues $</th>\n",
       "      <th>Revenues %</th>\n",
       "      <th>Total Stockholder Equity $</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199,581</td>\n",
       "      <td>215,356</td>\n",
       "      <td>482,130</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>80,546</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336,758</td>\n",
       "      <td>347,129</td>\n",
       "      <td>246,204</td>\n",
       "      <td>-35.6</td>\n",
       "      <td>170,811</td>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290,479</td>\n",
       "      <td>604,304</td>\n",
       "      <td>233,715</td>\n",
       "      <td>27.9</td>\n",
       "      <td>119,355</td>\n",
       "      <td>Apple</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552,257</td>\n",
       "      <td>350,279</td>\n",
       "      <td>210,821</td>\n",
       "      <td>8.3</td>\n",
       "      <td>255,550</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>www.berkshirehathaway.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53,870</td>\n",
       "      <td>35,945</td>\n",
       "      <td>181,241</td>\n",
       "      <td>31.3</td>\n",
       "      <td>8,001</td>\n",
       "      <td>McKesson</td>\n",
       "      <td>www.mckesson.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111,383</td>\n",
       "      <td>122,542</td>\n",
       "      <td>157,107</td>\n",
       "      <td>20.4</td>\n",
       "      <td>33,830</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>www.unitedhealthgroup.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93,657</td>\n",
       "      <td>113,947</td>\n",
       "      <td>153,290</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37,196</td>\n",
       "      <td>CVS Health</td>\n",
       "      <td>www.cvshealth.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>194,520</td>\n",
       "      <td>48,543</td>\n",
       "      <td>152,356</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>39,871</td>\n",
       "      <td>General Motors</td>\n",
       "      <td>www.gm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>224,925</td>\n",
       "      <td>53,758</td>\n",
       "      <td>149,558</td>\n",
       "      <td>3.8</td>\n",
       "      <td>28,642</td>\n",
       "      <td>Ford Motor</td>\n",
       "      <td>www.ford.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>402,672</td>\n",
       "      <td>240,943</td>\n",
       "      <td>146,801</td>\n",
       "      <td>10.8</td>\n",
       "      <td>122,671</td>\n",
       "      <td>AT&amp;amp;T</td>\n",
       "      <td>www.att.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>492,692</td>\n",
       "      <td>295,174</td>\n",
       "      <td>140,389</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>98,274</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27,736</td>\n",
       "      <td>19,511</td>\n",
       "      <td>135,962</td>\n",
       "      <td>13.7</td>\n",
       "      <td>634</td>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>244,640</td>\n",
       "      <td>220,646</td>\n",
       "      <td>131,620</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16,428</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>266,103</td>\n",
       "      <td>179,653</td>\n",
       "      <td>131,118</td>\n",
       "      <td>-35.7</td>\n",
       "      <td>152,716</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>www.chevron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33,440</td>\n",
       "      <td>69,183</td>\n",
       "      <td>116,199</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10,617</td>\n",
       "      <td>Costco</td>\n",
       "      <td>www.costco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3,221,917</td>\n",
       "      <td>1,621</td>\n",
       "      <td>110,359</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>4,030</td>\n",
       "      <td>Fannie Mae</td>\n",
       "      <td>www.fanniemae.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33,897</td>\n",
       "      <td>36,815</td>\n",
       "      <td>109,830</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6,820</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>65,444</td>\n",
       "      <td>279,511</td>\n",
       "      <td>107,006</td>\n",
       "      <td>20.2</td>\n",
       "      <td>13,384</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>www.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68,782</td>\n",
       "      <td>90,874</td>\n",
       "      <td>103,444</td>\n",
       "      <td>35.4</td>\n",
       "      <td>30,861</td>\n",
       "      <td>Walgreens Boots Alliance</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>106,882</td>\n",
       "      <td>21,272</td>\n",
       "      <td>103,355</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>27,768</td>\n",
       "      <td>HP</td>\n",
       "      <td>www.hp.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Assets $ Market value $ Revenues $ Revenues % Total Stockholder Equity $  \\\n",
       "0     199,581        215,356    482,130       -0.7                     80,546   \n",
       "1     336,758        347,129    246,204      -35.6                    170,811   \n",
       "2     290,479        604,304    233,715       27.9                    119,355   \n",
       "3     552,257        350,279    210,821        8.3                    255,550   \n",
       "4      53,870         35,945    181,241       31.3                      8,001   \n",
       "5     111,383        122,542    157,107       20.4                     33,830   \n",
       "6      93,657        113,947    153,290       10.0                     37,196   \n",
       "7     194,520         48,543    152,356       -2.3                     39,871   \n",
       "8     224,925         53,758    149,558        3.8                     28,642   \n",
       "9     402,672        240,943    146,801       10.8                    122,671   \n",
       "10    492,692        295,174    140,389       -5.3                     98,274   \n",
       "11     27,736         19,511    135,962       13.7                        634   \n",
       "12    244,640        220,646    131,620        3.6                     16,428   \n",
       "13    266,103        179,653    131,118      -35.7                    152,716   \n",
       "14     33,440         69,183    116,199        3.2                     10,617   \n",
       "15  3,221,917          1,621    110,359       -5.2                      4,030   \n",
       "16     33,897         36,815    109,830        1.3                      6,820   \n",
       "17     65,444        279,511    107,006       20.2                     13,384   \n",
       "18     68,782         90,874    103,444       35.4                     30,861   \n",
       "19    106,882         21,272    103,355       -7.3                     27,768   \n",
       "\n",
       "                     company                             url  \n",
       "0                    Walmart                 www.walmart.com  \n",
       "1                Exxon Mobil              www.exxonmobil.com  \n",
       "2                      Apple                   www.apple.com  \n",
       "3         Berkshire Hathaway       www.berkshirehathaway.com  \n",
       "4                   McKesson                www.mckesson.com  \n",
       "5         UnitedHealth Group       www.unitedhealthgroup.com  \n",
       "6                 CVS Health               www.cvshealth.com  \n",
       "7             General Motors                      www.gm.com  \n",
       "8                 Ford Motor                    www.ford.com  \n",
       "9                   AT&amp;T                     www.att.com  \n",
       "10          General Electric                      www.ge.com  \n",
       "11         AmerisourceBergen       www.amerisourcebergen.com  \n",
       "12                   Verizon                 www.verizon.com  \n",
       "13                   Chevron                 www.chevron.com  \n",
       "14                    Costco                  www.costco.com  \n",
       "15                Fannie Mae               www.fanniemae.com  \n",
       "16                    Kroger             www.thekrogerco.com  \n",
       "17                Amazon.com                  www.amazon.com  \n",
       "18  Walgreens Boots Alliance  www.walgreensbootsalliance.com  \n",
       "19                        HP                      www.hp.com  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d10 = {'company' : pd.Series(ln, index=[nm]),'url' : pd.Series(urln, index=[nm]),\n",
    "      'Revenues $' : pd.Series(rev_dol, index=[nm]),'Revenues %' : pd.Series(rev_per, index=[nm]),\n",
    "      'Assets $' : pd.Series(assets_dol, index=[nm]),\n",
    "      'Total Stockholder Equity $' : pd.Series(tse_dol, index=[nm]),\n",
    "      'Market value $' : pd.Series(mar_dol, index=[nm])}\n",
    "fort500 = pd.DataFrame(d10)    \n",
    "fort500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
