{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First we import the libraries we will need\n",
    "import urllib2\n",
    "#import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First of all we need to find all the name of the sites that belong to fortune 500. This can happen if we seperate\n",
    "#The information needed from the below link\n",
    "url = \"http://www.zyxware.com/articles/4344/list-of-fortune-500-companies-and-their-websites\"\n",
    "list_company_number =[]\n",
    "list_company_name = []\n",
    "list_company_website = []\n",
    "list500_sites = []\n",
    "list500_names = []\n",
    "list500_num = []\n",
    "list500_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to extract the needed informations we will create 3 lists. The first one will contain the rank of each site, the\n",
    "#second one will contain the name of the company and the 3rd one will contain the actual link of the company's site.\n",
    "#For achieving this purpose we will create a funstion that will in its turn create those three list.\n",
    "#In order to know if the function worked we will ask it to return the first element of each list along with a sentence.\n",
    "def websites (url):\n",
    "    browser = urllib2.build_opener()\n",
    "    browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    response = browser.open(url)# this might throw an exception if something goes wrong.\n",
    "    myHTML = response.read()\n",
    "    soup = BeautifulSoup(myHTML,\"lxml\")    \n",
    "    o = 0\n",
    "    td_list =[]\n",
    "    for row2 in soup.html.body.findAll('td'):\n",
    "        td_list.insert(o, row2)\n",
    "        o = o + 1\n",
    "    a = 0\n",
    "    b = 1\n",
    "    c = 2\n",
    "    list_numbering = 0\n",
    "    for i in range (0,500):        \n",
    "        num = str(td_list[a])\n",
    "        company = str(td_list[b])\n",
    "        site = str(td_list[c])\n",
    "        c_num = re.findall('>(.+?)</td>',num)  \n",
    "        c_num = str(c_num[0])\n",
    "        c_name = re.findall('>(.+?)</td>',company)\n",
    "        c_name = str(c_name[0])\n",
    "        c_site = re.findall('\">(.+?)</a>',site)\n",
    "        c_site = str(c_site[0])        \n",
    "        list_company_number.insert(list_numbering,c_num)\n",
    "        list_company_name.insert(list_numbering,c_name)\n",
    "        list_company_website.insert(list_numbering,c_site)\n",
    "        a = a + 3\n",
    "        b = b + 3\n",
    "        c = c + 3\n",
    "        list_numbering =  list_numbering + 1 \n",
    "    print ('The three lists are ready')\n",
    "    print (list_company_number[0])\n",
    "    print (list_company_name[0])\n",
    "    print (list_company_website[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three lists are ready\n",
      "1\n",
      "Walmart\n",
      "www.walmart.com\n"
     ]
    }
   ],
   "source": [
    "# After creating the function we should now test that it actually works correctly\n",
    "websites (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The next step is to download and save in a new list the 500 sites.\n",
    "## We will create a new function that will do this by reading the list \"list_company_websites\" that we created \n",
    "## with the previous function\n",
    "\n",
    "def list_company_HTML (list_company_website,list_company_name,start,end):\n",
    "    import time\n",
    "    browser2 = urllib2.build_opener()\n",
    "    browser2.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    for i in range (start,end):\n",
    "        k = str(i+1)\n",
    "        lc = str(list_company_website[i])        \n",
    "        lc = lc.replace(\"'\",\"\")   \n",
    "        lc = lc.replace(\"[\",\"\")\n",
    "        lc = lc.replace(\"]\",\"\")\n",
    "        lcn = str(list_company_name[i])        \n",
    "        lcn = lcn.replace(\"'\",\"\")   \n",
    "        lcn = lcn.replace(\"[\",\"\")\n",
    "        lcn = lcn.replace(\"]\",\"\")\n",
    "        url2= 'http://'+lc\n",
    "        #an exception might be thrown, so the code should be in a try-except block\n",
    "        try:\n",
    "            #use the browser to get the url.\n",
    "            response2=browser2.open(url2)# this might throw an exception if something goes wrong.\n",
    "        except Exception: # this describes what to do if an exception is thrown\n",
    "             continue#ignore this page.      \n",
    "        #read the response in html format. This is essentially a long piece of text\n",
    "        myHTML2=response2.read()\n",
    "        list500_sites.insert(i,myHTML2)\n",
    "        list500_names.insert(i,lcn)\n",
    "        list500_url.insert(i,lc)\n",
    "        list500_num.insert(i,k)\n",
    "        #wait for 2 seconds\n",
    "        time.sleep(2)\n",
    "        #print (\"The site \" + k + \" has been downloaded!\")\n",
    "    print (\"We downloaded: \",len(list500_sites),\" sites!\")\n",
    "    #print (len(list500_names),list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n",
      "('We downloaded: ', 24, ' sites!')\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "stop = 25\n",
    "for i in range (0,1): #i am not downloading all the pages for the time being for reasons of running faster the process during the tests\n",
    "    print (start)\n",
    "    print (stop)    \n",
    "    list_company_HTML (list_company_website,list_company_name,start,stop)\n",
    "    start = stop\n",
    "    stop = stop + 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Retreiving the social media from each site\n",
    "#First create empty lists for the ones that we will need to calculate\n",
    "sm_f = []\n",
    "sm_t = []\n",
    "sm_i = []\n",
    "sm_p = []\n",
    "sm_y = []\n",
    "sm_l = []   \n",
    "sm_nm = [] \n",
    "nm = []\n",
    "sm_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then create a function that will feel in those lists so as to make the data frame later on\n",
    "\n",
    "def socialmedia (list500_sites,list500_names,list500_url,start,end):\n",
    "    for num in range(start,end):\n",
    "        if list500_sites[num] != \"\":\n",
    "            hand = str(list500_sites[num])\n",
    "            sm = ['facebook.com','twitter.com','instagram.com','pinterest.com','youtube.com','linkedin.com'] \n",
    "            number = 0 \n",
    "            for index in range(len(sm)):\n",
    "                x = sm[index]\n",
    "                photo = re.findall(x,hand)                                \n",
    "                if (len(photo)>0):\n",
    "                    if x == 'facebook.com':\n",
    "                        answerf = True\n",
    "                    if x == 'twitter.com':\n",
    "                        answert = True\n",
    "                    if x == 'instagram.com':\n",
    "                        answeri = True\n",
    "                    if x == 'pinterest.com':\n",
    "                        answerp = True\n",
    "                    if x == 'youtube.com':\n",
    "                        answery = True\n",
    "                    if x =='linkedin.com':\n",
    "                        answerl = True                   \n",
    "                else:\n",
    "                     if x == 'facebook.com':\n",
    "                        answerf = False\n",
    "                     if x == 'twitter.com':\n",
    "                        answert = False\n",
    "                     if x == 'instagram.com':\n",
    "                        answeri = False\n",
    "                     if x == 'pinterest.com':\n",
    "                        answerp = False\n",
    "                     if x == 'youtube.com':\n",
    "                        answery = False\n",
    "                     if x =='linkedin.com':\n",
    "                        answerl = False                \n",
    "            sm_nm.insert(num,list500_names[num]) \n",
    "            nm.insert(num,num)\n",
    "            sm_url.insert(num,list500_url[num])\n",
    "            sm_f.insert(num,answerf)\n",
    "            sm_t.insert(num,answert)\n",
    "            sm_i.insert(num,answeri)\n",
    "            sm_p.insert(num,answerp)\n",
    "            sm_y.insert(num,answery)\n",
    "            sm_l.insert(num,answerl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we will run the function for the 20 first sites for starters\n",
    "socialmedia (list500_sites,list500_names,list500_url,0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>facebook</th>\n",
       "      <th>instagram</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>twitter</th>\n",
       "      <th>url</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>www.walmart.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>www.apple.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company facebook instagram linkedin pinterest twitter  \\\n",
       "0      Walmart     True      True    False      True    True   \n",
       "1  Exxon Mobil    False     False    False     False   False   \n",
       "2        Apple    False     False     True     False   False   \n",
       "\n",
       "                  url youtube  \n",
       "0     www.walmart.com    True  \n",
       "1  www.exxonmobil.com   False  \n",
       "2       www.apple.com    True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally we create the data frame with the elements we found            \n",
    "d = {'company' : pd.Series(sm_nm, index=[nm]),'url' : pd.Series(sm_url, index=[nm]),\n",
    "     'facebook' : pd.Series(sm_f, index=[nm]),'twitter' : pd.Series(sm_t, index=[nm]),\n",
    "     'instagram' : pd.Series(sm_i, index=[nm]),'pinterest' : pd.Series(sm_p, index=[nm]),\n",
    "     'youtube' : pd.Series(sm_y, index=[nm]),'linkedin' : pd.Series(sm_l, index=[nm]),}\n",
    "social_media = pd.DataFrame(d)    \n",
    "social_media.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the lists we will need for the data frame\n",
    "l_nm = []\n",
    "l_ex = []\n",
    "l_in = []\n",
    "l_t = []\n",
    "nm = []\n",
    "l_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the function that will calculate the different type of links\n",
    "def links (list500_sites,list500_names,list500_url,start,end):\n",
    "    for num in range(start,end):\n",
    "        line = str(list500_sites[num])\n",
    "        href = re.findall('href',line)\n",
    "        external = re.findall('href=\"https:',line)\n",
    "        ex = (len(external))\n",
    "        alllinks = (len(href))\n",
    "        internal =  (len(href) - len(external))\n",
    "        l_nm.insert(num,list500_names[num])            \n",
    "        l_ex.insert(num,ex)\n",
    "        l_t.insert(num,alllinks)\n",
    "        l_in.insert(num,internal)\n",
    "        nm.insert(num,num)\n",
    "        l_url.insert(num,list500_url[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run the function in order to find the external, internal and total links of each site\n",
    "#For now we are running for the first 20 sites only\n",
    "links (list500_sites,list500_names,list500_url,0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>external</th>\n",
       "      <th>internal</th>\n",
       "      <th>total links</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>67</td>\n",
       "      <td>98</td>\n",
       "      <td>165</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>23</td>\n",
       "      <td>783</td>\n",
       "      <td>806</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>5</td>\n",
       "      <td>277</td>\n",
       "      <td>282</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company  external  internal  total links                 url\n",
       "0      Walmart        67        98          165     www.walmart.com\n",
       "1  Exxon Mobil        23       783          806  www.exxonmobil.com\n",
       "2        Apple         5       277          282       www.apple.com"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe so as to be able to see the results of the function we run\n",
    "d2 = {'company' : pd.Series(l_nm, index=[nm]),'url' : pd.Series(l_url, index=[nm]),\n",
    "      'external' : pd.Series(l_ex, index=[nm]),'internal' : pd.Series(l_in, index=[nm]),\n",
    "     'total links' : pd.Series(l_t, index=[nm])}\n",
    "sites_links = pd.DataFrame(d2)    \n",
    "sites_links.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The initial lists we will need in order to calculate the loading time\n",
    "lt_nm = [] \n",
    "lt_time = []\n",
    "nm = []\n",
    "lt_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the function that will calculate the loading time\n",
    "def loadtime (list_company_website,list500_names,start,end):\n",
    "    from time import time\n",
    "    browser2 = urllib2.build_opener()\n",
    "    browser2.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    for num in range(start,end):\n",
    "        lc = str(list_company_website[num])        \n",
    "        lc = lc.replace(\"'\",\"\")   \n",
    "        lc = lc.replace(\"[\",\"\")\n",
    "        lc = lc.replace(\"]\",\"\")\n",
    "        url2= 'http://'+lc\n",
    "        try:\n",
    "            response2=browser2.open(url2)# this might throw an exception if something goes wrong.\n",
    "        except Exception: # this describes what to do if an exception is thrown\n",
    "             continue   \n",
    "        start_time = time()\n",
    "        myHTML2=response2.read()\n",
    "        end_time = time()\n",
    "        response2.close()\n",
    "        l_t = round(end_time-start_time, 3)\n",
    "        loadt = str(l_t)\n",
    "        lt_nm.insert(num,list500_names[num])            \n",
    "        lt_time.insert(num,loadt)\n",
    "        nm.insert(num,num)\n",
    "        lt_url.insert(num,lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running the function for the first 20 sites\n",
    "loadtime (list_company_website,list500_names,0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>loading time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>0.422</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>5.943</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>0.094</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.berkshirehathaway.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McKesson</td>\n",
       "      <td>0.156</td>\n",
       "      <td>www.mckesson.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>0.886</td>\n",
       "      <td>www.unitedhealthgroup.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CVS Health</td>\n",
       "      <td>0.078</td>\n",
       "      <td>www.cvshealth.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>General Motors</td>\n",
       "      <td>0.047</td>\n",
       "      <td>www.gm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ford Motor</td>\n",
       "      <td>0.11</td>\n",
       "      <td>www.ford.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AT&amp;amp;T</td>\n",
       "      <td>1.531</td>\n",
       "      <td>www.att.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>0.031</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>0.141</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chevron</td>\n",
       "      <td>0.093</td>\n",
       "      <td>www.chevron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Costco</td>\n",
       "      <td>0.125</td>\n",
       "      <td>www.costco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>0.312</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Walgreens Boots Alliance</td>\n",
       "      <td>0.533</td>\n",
       "      <td>www.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HP</td>\n",
       "      <td>0.616</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cardinal Health</td>\n",
       "      <td>0.203</td>\n",
       "      <td>www.hp.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company loading time                             url\n",
       "0                    Walmart        0.422                 www.walmart.com\n",
       "1                Exxon Mobil        5.943              www.exxonmobil.com\n",
       "2                      Apple        0.094                   www.apple.com\n",
       "3         Berkshire Hathaway          0.0       www.berkshirehathaway.com\n",
       "4                   McKesson        0.156                www.mckesson.com\n",
       "5         UnitedHealth Group        0.886       www.unitedhealthgroup.com\n",
       "6                 CVS Health        0.078               www.cvshealth.com\n",
       "7             General Motors        0.047                      www.gm.com\n",
       "8                 Ford Motor         0.11                    www.ford.com\n",
       "9                   AT&amp;T        1.531                     www.att.com\n",
       "10          General Electric        0.031                      www.ge.com\n",
       "11         AmerisourceBergen          0.0       www.amerisourcebergen.com\n",
       "12                   Verizon        0.141                 www.verizon.com\n",
       "13                   Chevron        0.093                 www.chevron.com\n",
       "14                    Costco        0.125                  www.costco.com\n",
       "16                Amazon.com        0.312             www.thekrogerco.com\n",
       "17  Walgreens Boots Alliance        0.533                  www.amazon.com\n",
       "18                        HP        0.616  www.walgreensbootsalliance.com\n",
       "19           Cardinal Health        0.203                      www.hp.com"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the data frame with the loading times\n",
    "d3 = {'company' : pd.Series(lt_nm, index=[nm]),'url' : pd.Series(lt_url, index=[nm]),\n",
    "      'loading time' : pd.Series(lt_time, index=[nm])}\n",
    "loading_time = pd.DataFrame(d3)    \n",
    "loading_time #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find out how many and what type of images each site has\n",
    "#first we create the initially empty lists\n",
    "p_p = []\n",
    "p_d = []\n",
    "p_jpg = []\n",
    "p_jpeg = []\n",
    "p_gif = []\n",
    "p_tif = []\n",
    "p_tiff = []\n",
    "p_bmp = []\n",
    "p_jpe = []\n",
    "p_nm = []\n",
    "p_tt = []\n",
    "nm = []\n",
    "p_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we create the function that will explore the html pages and search for the images\n",
    "def images (list500_sites,list500_names,list500_url,start,end):\n",
    "    for num in range(start,end):\n",
    "        line = str(list500_sites[num])\n",
    "        image = ['.png','.dib','.jpg','.jpeg','.bmp','.jpe','.gif','.tif','.tiff'] \n",
    "        totalnumber = 0 \n",
    "        for index in range(len(image)):\n",
    "            x = image[index]\n",
    "            photo = re.findall(x,line)\n",
    "            if x == '.png':\n",
    "                p = str (len(photo))\n",
    "            if x == '.dib':\n",
    "                d = str (len(photo))\n",
    "            if x == '.jpg':\n",
    "                jpg = str (len(photo))\n",
    "            if x == '.jpeg':\n",
    "                jpeg = str (len(photo))\n",
    "            if x == '.gif':\n",
    "                gif = str (len(photo))\n",
    "            if x == '.tif':\n",
    "                tif = str (len(photo))\n",
    "            if x == '.tiff':\n",
    "                tiff = str (len(photo))\n",
    "            if x == '.bmp':\n",
    "                bmp = str (len(photo))\n",
    "            if x == '.jpe':\n",
    "                jpe = str (len(photo))\n",
    "            totalnumber = len(photo) + totalnumber\n",
    "        total = str (totalnumber)\n",
    "        p_nm.insert(num,list500_names[num])            \n",
    "        p_p.insert(num,p)  \n",
    "        p_d.insert(num,d)  \n",
    "        p_jpg.insert(num,jpg)  \n",
    "        p_jpeg.insert(num,jpeg)  \n",
    "        p_gif.insert(num,gif)  \n",
    "        p_tif.insert(num,tif)  \n",
    "        p_tiff.insert(num,tiff)  \n",
    "        p_bmp.insert(num,bmp)  \n",
    "        p_jpe.insert(num,jpe)  \n",
    "        p_tt.insert(num,total)  \n",
    "        nm.insert(num,num)\n",
    "        p_url.insert(num,list500_url[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then we run the function for the first 20 sites for now\n",
    "images (list500_sites,list500_names,list500_url,0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.bmp</th>\n",
       "      <th>.dib</th>\n",
       "      <th>.gif</th>\n",
       "      <th>.jpe</th>\n",
       "      <th>.jpeg</th>\n",
       "      <th>.jpg</th>\n",
       "      <th>.png</th>\n",
       "      <th>.tif</th>\n",
       "      <th>.tiff</th>\n",
       "      <th>company</th>\n",
       "      <th>total images</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>353</td>\n",
       "      <td>www.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>23</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>www.apple.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  .bmp .dib .gif .jpe .jpeg .jpg .png .tif .tiff      company total images  \\\n",
       "0    0    0   22  103   103   76   43    6     0      Walmart          353   \n",
       "1    0    0    1    0     0   16    2    4     0  Exxon Mobil           23   \n",
       "2    0    0    1    0     0    0    2    0     0        Apple            3   \n",
       "\n",
       "                  url  \n",
       "0     www.walmart.com  \n",
       "1  www.exxonmobil.com  \n",
       "2       www.apple.com  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally we create a dataframe in order to see the results of the function\n",
    "d4 = {'company' : pd.Series(p_nm, index=[nm]),'url' : pd.Series(p_url, index=[nm]),'total images' : pd.Series(p_tt, index=[nm]),\n",
    "      '.png' : pd.Series(p_p, index=[nm]),'.dib' : pd.Series(p_d, index=[nm]),\n",
    "      '.jpg' : pd.Series(p_jpg, index=[nm]),'.jpeg' : pd.Series(p_jpeg, index=[nm]),\n",
    "      '.bmp' : pd.Series(p_bmp, index=[nm]),'.jpe' : pd.Series(p_jpe, index=[nm]),\n",
    "      '.gif' : pd.Series(p_gif, index=[nm]),'.tif' : pd.Series(p_tif, index=[nm]),\n",
    "      '.tiff' : pd.Series(p_tiff, index=[nm])}\n",
    "images_types = pd.DataFrame(d4)    \n",
    "images_types.head(3) #we see the first 3 in the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
