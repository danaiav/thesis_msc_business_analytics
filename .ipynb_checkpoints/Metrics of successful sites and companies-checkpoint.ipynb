{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First we import the libraries we will need\n",
    "import urllib\n",
    "import urllib2\n",
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First of all we need to find all the name of the sites that belong to fortune 500. This can happen if we seperate\n",
    "#The information needed from the below link\n",
    "url = \"http://www.zyxware.com/articles/4344/list-of-fortune-500-companies-and-their-websites\"\n",
    "list_company_number =[]\n",
    "list_company_name = []\n",
    "list_company_website = []\n",
    "list500_sites = []\n",
    "list500_names = []\n",
    "list500_num = []\n",
    "list500_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In order to extract the needed informations we will create 3 lists. The first one will contain the rank of each site, the\n",
    "#second one will contain the name of the company and the 3rd one will contain the actual link of the company's site.\n",
    "#For achieving this purpose we will create a funstion that will in its turn create those three list.\n",
    "#In order to know if the function worked we will ask it to return the first element of each list along with a sentence.\n",
    "def websites (url): \n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    browser = urllib2.build_opener() \n",
    "    browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    response = browser.open(url)# this might throw an exception if something goes wrong.\n",
    "    myHTML = response.read()\n",
    "    soup = BeautifulSoup(myHTML,\"lxml\")    \n",
    "    o = 0\n",
    "    td_list =[]\n",
    "    for row2 in soup.html.body.findAll('td'):\n",
    "        td_list.insert(o, row2)\n",
    "        o = o + 1\n",
    "    a = 0\n",
    "    b = 1\n",
    "    c = 2\n",
    "    list_numbering = 0\n",
    "    for i in range (0,500):        \n",
    "        num = str(td_list[a])\n",
    "        company = str(td_list[b])\n",
    "        site = str(td_list[c])\n",
    "        c_num = re.findall('>(.+?)</td>',num)  \n",
    "        c_num = str(c_num[0])\n",
    "        c_name = re.findall('>(.+?)</td>',company)\n",
    "        c_name = str(c_name[0])\n",
    "        c_site = re.findall('\">(.+?)</a>',site)\n",
    "        c_site = str(c_site[0])        \n",
    "        list_company_number.insert(list_numbering,c_num)\n",
    "        list_company_name.insert(list_numbering,c_name)\n",
    "        list_company_website.insert(list_numbering,c_site)\n",
    "        a = a + 3\n",
    "        b = b + 3\n",
    "        c = c + 3\n",
    "        list_numbering =  list_numbering + 1 \n",
    "    end = time ()\n",
    "    duration = round (end - start, 1)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are ready in  1.7  seconds\n"
     ]
    }
   ],
   "source": [
    "# After creating the function we should now test that it actually works correctly\n",
    "websites (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation is complete! There were 0 not valid pages\n"
     ]
    }
   ],
   "source": [
    "#Try to validate each page url #pip install validators\n",
    "import validators\n",
    "nv = 0\n",
    "for num in range(len(list_company_website)):\n",
    "    line = 'http://' + str(list_company_website[num])\n",
    "    x = validators.url(line)    \n",
    "    if x != True:\n",
    "        nv = nv +1\n",
    "print \"The validation is complete! There were\" , nv, \"not valid pages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_company_HTML (list_company_website,list_company_name,start,end):\n",
    "    import time\n",
    "    browser2 = urllib2.build_opener()\n",
    "    browser2.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    for i in range (start,end):\n",
    "        k = str(i + 1)        \n",
    "        lc = str(list_company_website[i])        \n",
    "        lc = lc.replace(\"'\",\"\")   \n",
    "        lc = lc.replace(\"[\",\"\")\n",
    "        lc = lc.replace(\"]\",\"\")\n",
    "        lcn = str(list_company_name[i])        \n",
    "        lcn = lcn.replace(\"'\",\"\")   \n",
    "        lcn = lcn.replace(\"[\",\"\")\n",
    "        lcn = lcn.replace(\"]\",\"\")   \n",
    "        url2= 'http://' + lc\n",
    "        #an exception might be thrown, so the code should be in a try-except block\n",
    "        try:            \n",
    "            response2=browser2.open(url2)\n",
    "        except Exception: # this describes what to do if an exception is thrown\n",
    "             continue     \n",
    "        #read the response in html format. This is essentially a long piece of text\n",
    "        myHTML2=response2.read()  \n",
    "        list500_sites.insert(i,myHTML2)\n",
    "        list500_names.insert(i,lcn)\n",
    "        list500_url.insert(i,lc)\n",
    "        list500_num.insert(i,k)\n",
    "        #if os.path.exists ('html/'+str(k)+'_'+lcn+'.html'): os.remove('html/'+str(k)+'_'+lcn+'.html')\n",
    "        #fwriter=open('html/'+str(k)+'_'+lcn+'.html','w')\n",
    "        #fwriter.write(str(myHTML2))        \n",
    "        #wait for 2 seconds\n",
    "        time.sleep(2)\n",
    "        print (\"The site \" + k + \" has been downloaded!\")    \n",
    "    print \"We saved: \",str(i + 1),\" sites!\"\n",
    "    #print (len(list500_names),list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The site 11 has been downloaded!\n",
      "The site 12 has been downloaded!\n",
      "The site 13 has been downloaded!\n",
      "The site 14 has been downloaded!\n",
      "The site 15 has been downloaded!\n",
      "The site 17 has been downloaded!\n",
      "The site 18 has been downloaded!\n",
      "The site 19 has been downloaded!\n",
      "The site 20 has been downloaded!\n",
      "We saved:  20  sites!\n"
     ]
    }
   ],
   "source": [
    "list_company_HTML (list_company_website,list_company_name,10,20) #THE NEXT TO DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#As we can see there is one site that hasn't been downloaded in order to keep track of the sites that we could not download\n",
    "#we will create a new list that we will keep them all together there\n",
    "not_d = []\n",
    "def not_downloadables (list500_names,list_company_name):\n",
    "    met = 0    \n",
    "    for i in range(10,20):\n",
    "        b = 0\n",
    "        if list_company_name[i] in list500_names:\n",
    "            b = 1\n",
    "        if b == 0:\n",
    "            ct = list_company_name[i]\n",
    "            not_d.insert(met,ct)\n",
    "            met = met + 1\n",
    "    print not_d        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fannie Mae']\n"
     ]
    }
   ],
   "source": [
    "#Now we will run the function to see which sites haven;t been downloaded\n",
    "not_downloadables (list500_names,list_company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we will perfom a reliability test for the text that is included in the html code of the company's page\n",
    "from pattern import metrics\n",
    "readability = []\n",
    "rdb = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readable (list500_names,list500_sites):\n",
    "    for i in range (len(list500_names)):\n",
    "            myHTML = list500_sites[i] \n",
    "            a = metrics.flesch_reading_ease(myHTML) * 100\n",
    "            a = round (a, 1)\n",
    "            if a > 90:    \n",
    "                readability.insert(i,\"Very easy\")\n",
    "                rdb.insert(i,6)\n",
    "            elif a > 80:\n",
    "                readability.insert(i,\"Easy\")\n",
    "                rdb.insert(i,5)\n",
    "            elif a > 70:\n",
    "                readability.insert(i,\"Fairly easy\")\n",
    "                rdb.insert(i,4)\n",
    "            elif a > 60:\n",
    "                readability.insert(i,\"Standard\")\n",
    "                rdb.insert(i,3)\n",
    "            elif a > 50:\n",
    "                readability.insert(i,\"Fairly difficult\")\n",
    "                rdb.insert(i,2)\n",
    "            elif a > 30:\n",
    "                readability.insert(i,\"Difficult\")\n",
    "                rdb.insert(i,1)\n",
    "            else:\n",
    "                readability.insert(i,\"Very Confusing\")\n",
    "                rdb.insert(i,0)\n",
    "    print \"The function is completed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function is completed!\n"
     ]
    }
   ],
   "source": [
    "readable (list500_names,list500_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Readability</th>\n",
       "      <th>Readability_index</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>www.chevron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>Costco</td>\n",
       "      <td>www.costco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>www.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>Walgreens Boots Alliance</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Very Confusing</td>\n",
       "      <td>0</td>\n",
       "      <td>HP</td>\n",
       "      <td>www.hp.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Readability  Readability_index                   company  \\\n",
       "11  Very Confusing                  0          General Electric   \n",
       "12  Very Confusing                  0         AmerisourceBergen   \n",
       "13  Very Confusing                  0                   Verizon   \n",
       "14  Very Confusing                  0                   Chevron   \n",
       "15  Very Confusing                  0                    Costco   \n",
       "17  Very Confusing                  0                    Kroger   \n",
       "18  Very Confusing                  0                Amazon.com   \n",
       "19  Very Confusing                  0  Walgreens Boots Alliance   \n",
       "20  Very Confusing                  0                        HP   \n",
       "\n",
       "                               url  \n",
       "11                      www.ge.com  \n",
       "12       www.amerisourcebergen.com  \n",
       "13                 www.verizon.com  \n",
       "14                 www.chevron.com  \n",
       "15                  www.costco.com  \n",
       "17             www.thekrogerco.com  \n",
       "18                  www.amazon.com  \n",
       "19  www.walgreensbootsalliance.com  \n",
       "20                      www.hp.com  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {'company' : pd.Series(list500_names, index=[list500_num]),'url' : pd.Series(list500_url, index=[list500_num]),\n",
    "      'Readability' : pd.Series(readability, index=[list500_num]),'Readability_index' : pd.Series(rdb, index=[list500_num])}\n",
    "fre = pd.DataFrame(d1)    \n",
    "fre #.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Retreiving the social media from each site\n",
    "#First create empty lists for the ones that we will need to calculate\n",
    "sm_f = []\n",
    "sm_t = []\n",
    "sm_i = []\n",
    "sm_p = []\n",
    "sm_y = []\n",
    "sm_l = []   \n",
    "sm_nm = [] \n",
    "nm = []\n",
    "sm_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then create a function that will feel in those lists so as to make the data frame later on\n",
    "\n",
    "def socialmedia (list500_sites,list500_names,list500_url):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    for i in range(len(list500_names)):\n",
    "            myHTML = list500_sites[i]\n",
    "            sm = ['facebook.com','twitter.com','instagram.com','pinterest.com','youtube.com','linkedin.com'] \n",
    "            number = 0 \n",
    "            for index in range(len(sm)):\n",
    "                x = sm[index]\n",
    "                photo = re.findall(x,myHTML)                                \n",
    "                if (len(photo) > 0):\n",
    "                    if x == 'facebook.com':\n",
    "                        answerf = 'yes'\n",
    "                    if x == 'twitter.com':\n",
    "                        answert = 'yes'\n",
    "                    if x == 'instagram.com':\n",
    "                        answeri = 'yes'\n",
    "                    if x == 'pinterest.com':\n",
    "                        answerp = 'yes'\n",
    "                    if x == 'youtube.com':\n",
    "                        answery = 'yes'\n",
    "                    if x =='linkedin.com':\n",
    "                        answerl = 'yes'                   \n",
    "                else:\n",
    "                     if x == 'facebook.com':\n",
    "                        answerf = 'no'\n",
    "                     if x == 'twitter.com':\n",
    "                        answert = 'no'\n",
    "                     if x == 'instagram.com':\n",
    "                        answeri = 'no'\n",
    "                     if x == 'pinterest.com':\n",
    "                        answerp = 'no'\n",
    "                     if x == 'youtube.com':\n",
    "                        answery = 'no'\n",
    "                     if x =='linkedin.com':\n",
    "                        answerl = 'no'                 \n",
    "            sm_nm.insert(i,list500_names[i]) \n",
    "            nm.insert(i,i)\n",
    "            sm_url.insert(i,list500_url[i])\n",
    "            sm_f.insert(num,answerf)\n",
    "            sm_t.insert(num,answert)\n",
    "            sm_i.insert(num,answeri)\n",
    "            sm_p.insert(num,answerp)\n",
    "            sm_y.insert(num,answery)\n",
    "            sm_l.insert(num,answerl)\n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are completed in ', minutes, ' minutes' \n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are completed in  0.0  minutes\n",
      "The lists are ready in  0.003  seconds\n"
     ]
    }
   ],
   "source": [
    "#Now we will run the function for the 25 first sites for starters\n",
    "socialmedia (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>facebook</th>\n",
       "      <th>instagram</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>twitter</th>\n",
       "      <th>url</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>www.ge.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>www.verizon.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company facebook instagram linkedin pinterest twitter  \\\n",
       "0   General Electric      yes       yes      yes       yes     yes   \n",
       "1  AmerisourceBergen       no        no       no        no      no   \n",
       "2            Verizon       no        no       no        no      no   \n",
       "\n",
       "                         url youtube  \n",
       "0                 www.ge.com     yes  \n",
       "1  www.amerisourcebergen.com      no  \n",
       "2            www.verizon.com      no  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally we create the data frame with the elements we found            \n",
    "d2 = {'company' : pd.Series(sm_nm, index=[nm]),'url' : pd.Series(sm_url, index=[nm]),\n",
    "     'facebook' : pd.Series(sm_f, index=[nm]),'twitter' : pd.Series(sm_t, index=[nm]),\n",
    "     'instagram' : pd.Series(sm_i, index=[nm]),'pinterest' : pd.Series(sm_p, index=[nm]),\n",
    "     'youtube' : pd.Series(sm_y, index=[nm]),'linkedin' : pd.Series(sm_l, index=[nm]),}\n",
    "social_media = pd.DataFrame(d2)    \n",
    "social_media.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the lists we will need for the data frame\n",
    "l_nm = []\n",
    "l_ex = []\n",
    "l_in = []\n",
    "l_t = []\n",
    "nm = []\n",
    "l_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the function that will calculate the different type of links\n",
    "def links (list500_sites,list500_names,list500_url):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    for num in range(len(list500_names)):        \n",
    "            myHTML = list500_sites[num] \n",
    "            href = re.findall('href',myHTML)\n",
    "            external = re.findall('href=\"https:',myHTML)\n",
    "            ex = (len(external))\n",
    "            alllinks = (len(href))\n",
    "            internal =  (len(href) - len(external))\n",
    "            l_nm.insert(num,list500_names[num])            \n",
    "            l_ex.insert(num,ex)\n",
    "            l_t.insert(num,alllinks)\n",
    "            l_in.insert(num,internal)\n",
    "            nm.insert(num,num)\n",
    "            l_url.insert(num,list500_url[num])\n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', minutes, ' minutes'\n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are ready in  0.0  minutes\n",
      "The lists are ready in  0.002  seconds\n"
     ]
    }
   ],
   "source": [
    "#Run the function in order to find the external, internal and total links of each site\n",
    "#For now we are running for the first 25 sites only\n",
    "links (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>external</th>\n",
       "      <th>internal</th>\n",
       "      <th>total links</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company  external  internal  total links  \\\n",
       "0   General Electric         1       128          129   \n",
       "1  AmerisourceBergen         0         0            0   \n",
       "2            Verizon         0        54           54   \n",
       "\n",
       "                         url  \n",
       "0                 www.ge.com  \n",
       "1  www.amerisourcebergen.com  \n",
       "2            www.verizon.com  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe so as to be able to see the results of the function we run\n",
    "d3 = {'company' : pd.Series(l_nm, index=[nm]),'url' : pd.Series(l_url, index=[nm]),\n",
    "      'external' : pd.Series(l_ex, index=[nm]),'internal' : pd.Series(l_in, index=[nm]),\n",
    "     'total links' : pd.Series(l_t, index=[nm])}\n",
    "sites_links = pd.DataFrame(d3)    \n",
    "sites_links.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The initial lists we will need in order to calculate the loading time\n",
    "lt_nm = [] \n",
    "lt_time = []\n",
    "nm = []\n",
    "lt_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the function that will calculate the loading time\n",
    "def loadtime (list_company_website,list500_names,list500_url):\n",
    "    from time import time\n",
    "    browser2 = urllib2.build_opener()\n",
    "    browser2.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    for num in range(len(list500_names)):\n",
    "        lc = str(list_company_website[num])        \n",
    "        lc = lc.replace(\"'\",\"\")   \n",
    "        lc = lc.replace(\"[\",\"\")\n",
    "        lc = lc.replace(\"]\",\"\")\n",
    "        url2 = 'http://' + lc        \n",
    "        try:\n",
    "            response2 = browser2.open(url2)\n",
    "        except Exception: \n",
    "             continue#     \n",
    "        start_time = time()\n",
    "        myHTML2 = response2.read()\n",
    "        end_time = time()\n",
    "        response2.close()\n",
    "        l_t = round(end_time-start_time, 3) #in order to be more readable we rounded the time\n",
    "        loadt = str(l_t)\n",
    "        lt_nm.insert(num,list500_names[num])            \n",
    "        lt_time.insert(num,loadt)\n",
    "        nm.insert(num,num)\n",
    "        lt_url.insert(num,list500_url[num])\n",
    "    print \"The function is completed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function is completed!\n"
     ]
    }
   ],
   "source": [
    "#running the function for the first 25 sites\n",
    "loadtime (list_company_website,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>loading time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>1.492</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>3.325</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>0.082</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company loading time                        url\n",
       "0   General Electric        1.492                 www.ge.com\n",
       "1  AmerisourceBergen        3.325  www.amerisourcebergen.com\n",
       "2            Verizon        0.082            www.verizon.com"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the data frame with the loading times\n",
    "d4 = {'company' : pd.Series(lt_nm, index=[nm]),'url' : pd.Series(lt_url, index=[nm]),\n",
    "      'loading time' : pd.Series(lt_time, index=[nm])}\n",
    "loading_time = pd.DataFrame(d4)    \n",
    "loading_time.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find out how many and what type of images each site has\n",
    "#first we create the initially empty lists\n",
    "p_p = []\n",
    "p_d = []\n",
    "p_jpg = []\n",
    "p_jpeg = []\n",
    "p_gif = []\n",
    "p_tif = []\n",
    "p_tiff = []\n",
    "p_bmp = []\n",
    "p_jpe = []\n",
    "p_nm = []\n",
    "p_tt =[]\n",
    "nm = []\n",
    "p_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we create the function that will explore the html pages and search for the images\n",
    "def images (list500_sites,list500_names,list500_url):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    for num in range(len(list500_names)):\n",
    "            myHTML = list500_sites[num] \n",
    "            image = ['.png','.dib','.jpg','.jpeg','.bmp','.jpe','.gif','.tif','.tiff'] \n",
    "            totalnumber = 0 \n",
    "            for index in range(len(image)):\n",
    "                x = image[index]\n",
    "                photo = re.findall(x,myHTML)\n",
    "                if x == '.png':\n",
    "                    p = str (len(photo))\n",
    "                if x == '.dib':\n",
    "                    d = str (len(photo))\n",
    "                if x == '.jpg':\n",
    "                    jpg = str (len(photo))\n",
    "                if x == '.jpeg':\n",
    "                    jpeg = str (len(photo))\n",
    "                if x == '.gif':\n",
    "                    gif = str (len(photo))\n",
    "                if x == '.tif':\n",
    "                    tif = str (len(photo))\n",
    "                if x == '.tiff':\n",
    "                    tiff = str (len(photo))\n",
    "                if x == '.bmp':\n",
    "                    bmp = str (len(photo))\n",
    "                if x == '.jpe':\n",
    "                    jpe = str (len(photo))\n",
    "                totalnumber = len(photo) + totalnumber\n",
    "            total = str (totalnumber)\n",
    "            p_nm.insert(num,list500_names[num])            \n",
    "            p_p.insert(num,p)  \n",
    "            p_d.insert(num,d)  \n",
    "            p_jpg.insert(num,jpg)  \n",
    "            p_jpeg.insert(num,jpeg)  \n",
    "            p_gif.insert(num,gif)  \n",
    "            p_tif.insert(num,tif)  \n",
    "            p_tiff.insert(num,tiff)  \n",
    "            p_bmp.insert(num,bmp)  \n",
    "            p_jpe.insert(num,jpe)  \n",
    "            p_tt.insert(num,total)\n",
    "            nm.insert(num,num)\n",
    "            p_url.insert(num,list500_url[num])\n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', minutes, ' minutes'\n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are ready in  0.0  minutes\n",
      "The lists are ready in  0.048  seconds\n"
     ]
    }
   ],
   "source": [
    "#Then we run the function for the first 20 sites for now\n",
    "images (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.bmp</th>\n",
       "      <th>.dib</th>\n",
       "      <th>.gif</th>\n",
       "      <th>.jpe</th>\n",
       "      <th>.jpeg</th>\n",
       "      <th>.jpg</th>\n",
       "      <th>.png</th>\n",
       "      <th>.tif</th>\n",
       "      <th>.tiff</th>\n",
       "      <th>company</th>\n",
       "      <th>total images</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>10</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>0</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>2</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  .bmp .dib .gif .jpe .jpeg .jpg .png .tif .tiff            company  \\\n",
       "0    0    0    1    1     0    6    2    0     0   General Electric   \n",
       "1    0    0    0    0     0    0    0    0     0  AmerisourceBergen   \n",
       "2    0    0    0    0     0    0    2    0     0            Verizon   \n",
       "\n",
       "  total images                        url  \n",
       "0           10                 www.ge.com  \n",
       "1            0  www.amerisourcebergen.com  \n",
       "2            2            www.verizon.com  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally we create a dataframe in order to see the results of the function\n",
    "d5 = {'company' : pd.Series(p_nm, index=[nm]),'url' : pd.Series(p_url, index=[nm]),\n",
    "      '.png' : pd.Series(p_p, index=[nm]),'.dib' : pd.Series(p_d, index=[nm]),\n",
    "'.jpg' : pd.Series(p_jpg, index=[nm]),'.jpeg' : pd.Series(p_jpeg, index=[nm]),\n",
    "'.bmp' : pd.Series(p_bmp, index=[nm]),'.jpe' : pd.Series(p_jpe, index=[nm]),\n",
    "'.gif' : pd.Series(p_gif, index=[nm]),'.tif' : pd.Series(p_tif, index=[nm]),\n",
    "'.tiff' : pd.Series(p_tiff, index=[nm]), 'total images' : pd.Series(p_tt, index=[nm])}\n",
    "images_types = pd.DataFrame(d5)    \n",
    "images_types.head(3) #we see the first 3 in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we will find the different dimensions that each site uses\n",
    "#initially we create the empty lists we will need\n",
    "nm = []\n",
    "s_comp = []\n",
    "s_dimensions = []\n",
    "s_times = []\n",
    "s_tt_dif_dim = []\n",
    "ht = [] #list of different heights in each case\n",
    "wt = [] #list of different widths in each case\n",
    "h_w = [] # combinations of height and width\n",
    "dif_size = []  \n",
    "un_size = [] \n",
    "s_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With the below function we will gather in a variable all the different dimensions \n",
    "#and in another one all the times that each dimension occures for each html code\n",
    "def find_dif_sizes (list500_sites,list500_names,list500_url):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    for num in range(len(list500_names)):\n",
    "            nm.insert(num,num)                  \n",
    "            s_comp.insert(num,list500_names[num])\n",
    "            s_url.insert(num,list500_url[num])\n",
    "            myHTML = list500_sites[num] \n",
    "            soup = BeautifulSoup(myHTML, \"lxml\")\n",
    "            # we create 2 local variables so as to gather the different dimensions and occurencies  of each page seperately\n",
    "            s_dimensions_local = []\n",
    "            s_times_local = []\n",
    "            hw = 0 # we use it for the lists of height and width\n",
    "            for tag in soup.find_all('img'): # find all the img in the first site html\n",
    "                #Since in some cases either the height or the width is missing we would like to keep only the ones that have both dimensions\n",
    "                 h = tag.attrs.get('height', None)\n",
    "                 w = tag.attrs.get('width', None)\n",
    "                 #we use if to check which ones have both        \n",
    "                 if h != None:\n",
    "                     if w != None:\n",
    "                         ht.insert(hw,h)\n",
    "                         wt.insert(hw,w)\n",
    "                         hw = hw + 1                        \n",
    "            hw2 = 0\n",
    "            for l in range(len(ht)):\n",
    "                 h_w_c = ht[l] + 'x' + wt[l]    #we create a str with the form (300x300) so as to be more easily to read later on \n",
    "                 h_w.insert(hw2,h_w_c)  #we put it in a new list\n",
    "                 hw2 = hw2 + 1    \n",
    "            if h_w == []:#we check if there are not any dimensions available\n",
    "                 nm.insert(num,num)                  \n",
    "                 s_comp.insert(num,list500_names[num])\n",
    "                 s_dimensions.insert(num,0)\n",
    "                 s_times.insert(num,0)    \n",
    "            if h_w != []:#now we continue with the cases where the dimensions are indeed available             \n",
    "                 from collections import Counter\n",
    "                 hw_unique = Counter(h_w)\n",
    "                 hw_unique2 = str(hw_unique) #the unique different dimensions for the specific site\n",
    "                #Due to the fact that we are talking about a list we have to split the parts we need \n",
    "                 split1 = hw_unique2.split('{')\n",
    "                 a = split1[1]\n",
    "                 split2 = a.split('}')\n",
    "                 b = split2[0]\n",
    "                 split3 = b.split(',')\n",
    "                 finalsplit = []\n",
    "                 fs = []\n",
    "                 z = 0\n",
    "                 m = 1\n",
    "                 j = 0\n",
    "                 z1 = 0\n",
    "                 m1 = 1\n",
    "                #each of the items in split3 has a form '300x300 : 15' and in order to create the dataframe we have \n",
    "                #to split this form and keep the informations in different list\n",
    "                 for numb in split3:                \n",
    "                     oldstring = numb\n",
    "                     newstring = oldstring.replace(\"'\", \"\")\n",
    "                     new = newstring.replace(\"'\",\"\")\n",
    "                     string = new.replace(\" \",\"\")\n",
    "                     finalstring = string.split(':')\n",
    "                        #the finalstring is a list that contains the dimensions and the occurencies\n",
    "                        #in order toseperate in different lists we create an additional loop\n",
    "                     for xx in range(len(finalstring)):\n",
    "                         ax = finalstring[xx]\n",
    "                         if 'x' in ax:\n",
    "                             s_dimensions_local.insert(z1,finalstring[xx])\n",
    "                             z1 = z1 + 1\n",
    "                         else:\n",
    "                             s_times_local.insert(m1,finalstring[xx])\n",
    "                             m1 = m1 + 1  \n",
    "                #Now we can add to the lists the parts we created so as to have them all gathered together             \n",
    "                 s_dimensions.insert(num,s_dimensions_local)\n",
    "                 s_times.insert(num,s_times_local)                \n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', minutes, ' minutes'\n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are ready in  0.0  minutes\n",
      "The lists are ready in  0.159  seconds\n"
     ]
    }
   ],
   "source": [
    "#Run the function for the first 20 sites\n",
    "find_dif_sizes (list500_sites,list500_names,list500_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the unique different image dimensions and put them on a list\n",
    "def unique_dif_sizes (s_dimensions,list500_names):\n",
    "    ds = 0\n",
    "    for num in range(len(list500_names)):\n",
    "        for s in s_dimensions[num]:\n",
    "            dif_size.insert(ds,s)\n",
    "            ds = ds + 1\n",
    "    dsu = 0\n",
    "    for i in dif_size:\n",
    "        if i not in un_size:\n",
    "            un_size.insert(dsu,i)\n",
    "            dsu = dsu + 1\n",
    "    print(un_size)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['70x125', '1x1', '50x45', '400x300']\n"
     ]
    }
   ],
   "source": [
    "#Run the finction unique_dif_sizes\n",
    "unique_dif_sizes (s_dimensions,list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The lists we will need for the next function\n",
    "t_f_s = []\n",
    "ttf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function in order to check whether or not each company has these dimensions\n",
    "def dimensions_per_company (un_size,list500_names):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    t_f_s.insert(0,un_size)\n",
    "    ttf.insert(0,t_f_s)\n",
    "    for num in range(len(list500_names)):\n",
    "        s1a = s_dimensions[num] #dimensions of site num\n",
    "        where = [] #empty list\n",
    "        wh = 0\n",
    "        haveornot = []\n",
    "        for er in range (len(un_size)):\n",
    "            for sizea in s1a:\n",
    "                if sizea == un_size[er]:\n",
    "                    where.insert(wh,str(er))\n",
    "                    break\n",
    "            if str(er) in where:\n",
    "               haveornot.insert(er,True)                    \n",
    "            else:\n",
    "               haveornot.insert(er,False)\n",
    "                    \n",
    "        t_f_s.insert(num + 1,haveornot)\n",
    "        ttf.insert(num + 1,t_f_s)  \n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', minutes, ' minutes'\n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are ready in  0.0  minutes\n",
      "The lists are ready in  0.0  seconds\n"
     ]
    }
   ],
   "source": [
    "#Run the function dimensions_per_company\n",
    "dimensions_per_company (un_size,list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['General Electric', 'AmerisourceBergen', 'Verizon', 'Chevron', 'Costco', 'Kroger', 'Amazon.com', 'Walgreens Boots Alliance', 'HP']\n"
     ]
    }
   ],
   "source": [
    "print(s_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company                        url\n",
       "0   General Electric                 www.ge.com\n",
       "1  AmerisourceBergen  www.amerisourcebergen.com\n",
       "2            Verizon            www.verizon.com"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an initial dataframe where we will add the sizes later on\n",
    "d6 = {'company' : pd.Series(s_comp, index=[nm]),'url' : pd.Series(s_url, index=[nm])}\n",
    "sizess = pd.DataFrame(d6)    \n",
    "sizess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we want to break the variable t_f_s in order to add the columns to the dataframe                  \n",
    "#Finally we create the data frame with the elements we found \n",
    "def final_dimensions_dataframe (un_size,t_f_s,list500_names):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    for q in range(len(un_size)):\n",
    "        names = un_size[q]\n",
    "        var = []\n",
    "        for num in range(len(list500_names)):\n",
    "            a = t_f_s[num+1]\n",
    "            var.insert(num,a[q])\n",
    "        sizess[names] = pd.Series(var, index=sizess.index) \n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', minutes, ' minutes'\n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are ready in  0.0  minutes\n",
      "The lists are ready in  0.002  seconds\n"
     ]
    }
   ],
   "source": [
    "#Run the function final_dimensions_dataframe\n",
    "final_dimensions_dataframe (un_size,t_f_s,list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>70x125</th>\n",
       "      <th>1x1</th>\n",
       "      <th>50x45</th>\n",
       "      <th>400x300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company                        url 70x125   1x1  50x45 400x300\n",
       "0   General Electric                 www.ge.com   True  True  False   False\n",
       "1  AmerisourceBergen  www.amerisourcebergen.com   True  True  False   False\n",
       "2            Verizon            www.verizon.com   True  True  False   False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we would like to find the words in the text and the unique words of each html page\n",
    "#First of all we need to have a dictionary with which we would check if the word we found truly exists\n",
    "#The dictionary is available in the internet from a github acount from where we are going to read it\n",
    "url_dictionary = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n",
    "browser = urllib2.build_opener()\n",
    "browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "response = browser.open(url_dictionary)\n",
    "html_dictionary = response.read()\n",
    "html_dictionary\n",
    "dicti = str(html_dictionary)\n",
    "#dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a1'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict_new = dicti.split(\"\\\\n\")\n",
    "dict_new = dicti.split(\"\\n\")\n",
    "dict_new[49] #the first 49 parts are not words so we have to remove them from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_final = []\n",
    "df = 0\n",
    "for i in range (50,len(dict_new)):\n",
    "    forfinal = dict_new[i]\n",
    "    forfinal = forfinal.replace(\"'\",\"\")\n",
    "    dict_final.insert(df,forfinal)\n",
    "    df = df + 1\n",
    "dict_final[0] #This is the original dictionary with which we will check each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#And now we will find each html file which words has inside\n",
    "empty = []\n",
    "wordsin = []\n",
    "ocin = []\n",
    "def html_which_word (list500_names):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start_t = time()\n",
    "    for num in range(len(list500_sites)):\n",
    "            line = list500_sites[num] \n",
    "            wordcount={}\n",
    "            corwordcount={}\n",
    "            simeiastiksis = [\"/\",\".\",\",\",\"=\",\">\",\"<\",\"?\",\"|\",\":\",\"_\",\"]\",\"[\",\"$\",\"&\",\"%\",\"(\",\")\",\"{\",\"}\",'\"',\";\",\"\\\\\",\"-\",\"!\",\"+\",\"#\",\"=\",\"@\",\"^\",\"*\",\"'\"]\n",
    "            for ss in range(len(simeiastiksis)):\n",
    "                simeio = simeiastiksis[ss]     \n",
    "                line = line.replace(simeio, \" \")\n",
    "            for word1 in line.split():\n",
    "                word1 = word1.lower()\n",
    "                if word1 in dict_final:\n",
    "                    if word1 not in wordcount:\n",
    "                        wordcount[word1] = 1\n",
    "                    else:\n",
    "                        wordcount[word1] += 1     \n",
    "            wordsin_local = []\n",
    "            wl = 0\n",
    "            ocin_local = []\n",
    "            for k,v in wordcount.items():\n",
    "                   #print (k,v)\n",
    "                   wordsin_local.insert(wl,str(k))\n",
    "                   ocin_local.insert(wl,str(v))\n",
    "                   wl = wl + 1\n",
    "            wordsin.insert(num,wordsin_local) # final list with all the words in each site\n",
    "            ocin.insert(num,ocin_local)  #final list with all the occurencies of the words in each site\n",
    "    end_t = time()\n",
    "    total_t = round(end_t - start_t,3)\n",
    "    total_ = round(total_t / 60,1)\n",
    "    print('finished ',str(x) ,' sites in: ', str(total_),' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('finished ', 'True', ' sites in: ', '2.2', ' minutes')\n"
     ]
    }
   ],
   "source": [
    "html_which_word (list500_names) #test the code for 2 sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company                        url\n",
       "0   General Electric                 www.ge.com\n",
       "1  AmerisourceBergen  www.amerisourcebergen.com\n",
       "2            Verizon            www.verizon.com"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the dataframe for the words and unique words\n",
    "d7 = {'company' : pd.Series(list500_names, index=[nm]),'url' : pd.Series(list500_url, index=[nm])}\n",
    "wordss = pd.DataFrame(d7)    \n",
    "wordss.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>total_words</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "      <td>505</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "      <td>301</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company                        url  total_words  unique_words\n",
       "0   General Electric                 www.ge.com          505           169\n",
       "1  AmerisourceBergen  www.amerisourcebergen.com            6             5\n",
       "2            Verizon            www.verizon.com          301           131"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the two lists we will need in order to make the dataframe\n",
    "l1 = []\n",
    "l2 = []\n",
    "for num in range(len(list500_names)):\n",
    "        line = list500_sites[num] \n",
    "        total_words = len(wordsin[num])\n",
    "        occurencies = ocin[num] \n",
    "        l1.insert(num,total_words)\n",
    "        count = 0 \n",
    "        for a in occurencies :\n",
    "            if a == '1':\n",
    "                count = count + 1\n",
    "        l2.insert(num,count)\n",
    "wordss['total_words'] = pd.Series(l1, index=sizess.index)\n",
    "wordss['unique_words'] = pd.Series(l2, index=sizess.index)          \n",
    "wordss.head(3)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to validate the html code we will use the w3 validator\n",
    "#We will validate each url and then we will open the url of the validation page\n",
    "#so as to extract the errors, the info warnings and the non-document-error io informations \n",
    "#First we create the empty lists we would use later on\n",
    "num_errors = []\n",
    "num_info_warnings = []\n",
    "num_non_doc = [] \n",
    "nm = []\n",
    "num_open_page = []\n",
    "empty = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we create the function that will pull the informations we want\n",
    "def html_validation (list500_url,list500_names):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    for num in range(len(list500_names)):\n",
    "        line = list500_url[num] \n",
    "        url_check = \"https://validator.w3.org/nu/?doc=https://\" + line\n",
    "        browser = urllib2.build_opener()\n",
    "        browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "        response = browser.open(url_check)\n",
    "        html_check = response.read()\n",
    "        html_check\n",
    "        check = str(html_check)\n",
    "        er = 0\n",
    "        err = 0\n",
    "        errr = 0\n",
    "        e = False\n",
    "        if check != empty:\n",
    "            e = True\n",
    "            soup = BeautifulSoup(check,\"lxml\")\n",
    "            o = 0\n",
    "            keyf = []\n",
    "            for row in soup.html.body.findAll('div'):\n",
    "                keyf.insert(o,row)\n",
    "                o = o + 1\n",
    "            #print(len(keyf),list500_url[num], \"site number: \", str(num))        \n",
    "            if len(keyf) != 0:       \n",
    "                    keyfin = str(keyf[2]) #the elements we need is in the 2nd div of the code\n",
    "                    dol= re.findall('class=\"error\"',keyfin)            \n",
    "                    er = er + len(dol)\n",
    "                    doll= re.findall('class=\"info warning\"',keyfin)            \n",
    "                    err = err + len(doll)\n",
    "                    dolll= re.findall('class=\"non-document-error io\"',keyfin)            \n",
    "                    errr = errr + len(dolll)\n",
    "        num_errors.insert(num,er)\n",
    "        num_info_warnings.insert(num,err)\n",
    "        num_non_doc.insert(num,errr)  \n",
    "        nm.insert(num,num) \n",
    "        num_open_page.insert(num,e)\n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', minutes, ' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are ready in  0.7  minutes\n"
     ]
    }
   ],
   "source": [
    "#Now we will run the function we created\n",
    "html_validation (list500_url,list500_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The_page_opened</th>\n",
       "      <th>company</th>\n",
       "      <th>non-document-error</th>\n",
       "      <th>number_of_errors</th>\n",
       "      <th>number_of_warning</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  The_page_opened            company  non-document-error  number_of_errors  \\\n",
       "0            True   General Electric                   0                10   \n",
       "1            True  AmerisourceBergen                   0                 3   \n",
       "2            True            Verizon                   0                20   \n",
       "\n",
       "   number_of_warning                        url  \n",
       "0                  0                 www.ge.com  \n",
       "1                  0  www.amerisourcebergen.com  \n",
       "2                  6            www.verizon.com  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After the checks we will create the dataframe with the informations we want\n",
    "d8 = {'company' : pd.Series(list500_names, index=[nm]),'url' : pd.Series(list500_url, index=[nm]),\n",
    "      'The_page_opened' : pd.Series(num_open_page, index=[nm]),'number_of_errors' : pd.Series(num_errors, index=[nm]),\n",
    "      'number_of_warning' : pd.Series(num_info_warnings, index=[nm]),'non-document-error' : pd.Series(num_non_doc, index=[nm])}\n",
    "html_val = pd.DataFrame(d8)    \n",
    "html_val.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The next step is to take some informations from the fortune 500 site for each company\n",
    "#In order to achieve that we should open the pages for each one of the sites seperately\n",
    "#Since there is a pattern in the way the pages are named it shouldn't be difficult\n",
    "#Firstly we should create the pattern with which we will download the pages\n",
    "#By running the code we can see that the names of each comany are not written exactly as we have saved them\n",
    "#So we do need to alter the names first in order for the below function to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a new list with alterations in order for the names\n",
    "#to match the ones that fortune 500 uses so that we can download the html page\n",
    "list_company_name_new = []\n",
    "for num in range (0,500):\n",
    "    cn = list_company_name[num]\n",
    "    cn = cn.replace(\" \", \"-\")\n",
    "    cn = cn.replace(\"&\", \"\")\n",
    "    cn = cn.replace(\"’\", \"\")\n",
    "    cn = cn.replace(\".\", \"-\")\n",
    "    cn = cn.replace(\"amp;\", \"\")    \n",
    "    company = cn.lower()\n",
    "    list_company_name_new.insert(num,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fortune_pages = []\n",
    "def fortune500 (list_company_name_new):\n",
    "    from time import time # I used it to see how much time it does to run the function\n",
    "    start = time ()\n",
    "    for num3 in range (10,20): #we put 25 for testing\n",
    "        i = str (num3 +1)    \n",
    "        companyname =  list_company_name_new[num3]\n",
    "        browser = urllib2.build_opener() #because i work from different computers with different pyhton version some commands are not recognizable in each version\n",
    "        browser.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "        site_fortune = \"http://beta.fortune.com/fortune500/\"+companyname+\"-\"+ i    \n",
    "        page_fortune = browser.open(site_fortune)\n",
    "        html_fortune = page_fortune.read()    \n",
    "        print(\"fortune page for company: \", list_company_name_new[num3],i)\n",
    "        fortune_pages.insert(num3, html_fortune)\n",
    "    end = time ()\n",
    "    duration = round (end - start, 3)\n",
    "    minutes = round (duration /60, 1)\n",
    "    print 'The lists are ready in ', minutes, ' minutes'\n",
    "    print 'The lists are ready in ', duration, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fortune page for company: ', 'General-Electric', '11')\n",
      "('fortune page for company: ', 'AmerisourceBergen', '12')\n",
      "('fortune page for company: ', 'Verizon', '13')\n",
      "('fortune page for company: ', 'Chevron', '14')\n",
      "('fortune page for company: ', 'Costco', '15')\n",
      "('fortune page for company: ', 'Fannie-Mae', '16')\n",
      "('fortune page for company: ', 'Kroger', '17')\n",
      "('fortune page for company: ', 'Amazon-com', '18')\n",
      "('fortune page for company: ', 'Walgreens-Boots-Alliance', '19')\n",
      "('fortune page for company: ', 'HP', '20')\n",
      "The lists are ready in  0.6  minutes\n",
      "The lists are ready in  33.389  seconds\n"
     ]
    }
   ],
   "source": [
    "#Run the function we created\n",
    "fortune500 (list_company_name_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now that we have opened the url we are going to extract some informations that we need from them\n",
    "#In order to do that initially we have to create the variables we will need\n",
    "keyf =[]\n",
    "per =[]\n",
    "rev_dol = []\n",
    "rev_per = []\n",
    "prof_dol = []\n",
    "prof_per = []\n",
    "assets_dol = []\n",
    "assets_per = []\n",
    "tse_dol = []\n",
    "tse_per = []\n",
    "mar_dol = []\n",
    "mar_per = []\n",
    "market = []\n",
    "nm = []\n",
    "ln = []\n",
    "urln = []\n",
    "empty = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fortune_metrics (list_company_name,list_company_website):\n",
    "    x = 0\n",
    "    for n in range (10,20):   #we put 25 for testing\n",
    "        nm.insert(x,n)\n",
    "        ln.insert(x,list_company_name[n])\n",
    "        urln.insert(x,list_company_website[n])\n",
    "        files = fortune_pages[x]\n",
    "        soup = BeautifulSoup(files,\"lxml\")\n",
    "        o=0\n",
    "        for row in soup.html.body.findAll('tbody'):\n",
    "            keyf.insert(o,row)\n",
    "            o=o+1\n",
    "        keyfin = keyf[0] #the elements we need is in the first tbody of the code\n",
    "        data = keyfin.findAll('td')\n",
    "\n",
    "        one = str(data[0]) # revenue\n",
    "        two = str(data[1]) # revenue in dollars we need to extract this\n",
    "        revdol= re.findall('>\\$(.+?)</td>',two) #we keep only the numbers\n",
    "        if revdol[0] != empty:\n",
    "            w = revdol[0]\n",
    "            a = w.replace(\"[\", \"\")\n",
    "            r = a.replace(\"]\",\"\")\n",
    "            rev_dol.insert(x,r)\n",
    "        tria = str(data[2])# revenue in percentage we need to extract this as well\n",
    "        revper= re.findall('>(.+?)%</td>',tria) #we keep only the numbers\n",
    "        if revper != empty:    \n",
    "            w = revper[0]\n",
    "            a = w.replace(\"[\", \"\")\n",
    "            r1 = a.replace(\"]\",\"\")    \n",
    "            rev_per.insert(x,r1) \n",
    "\n",
    "        four = str(data[3])   # profit     \n",
    "        five = str(data[4])   # profit in dollars we need to extract this   \n",
    "        profdol= re.findall('>\\$(.+?)</td>',five) #we keep only the numbers\n",
    "        if profdol != empty:\n",
    "            w = profdol[0]\n",
    "            a = w.replace(\"[\", \"\")\n",
    "            p = a.replace(\"]\",\"\")\n",
    "            prof_dol.insert(x,p)\n",
    "        six = str(data[5])    # profit in percentage we need to extract this as well   \n",
    "        profper = re.findall('>(.+?)%</td>',six) #we keep only the numbers\n",
    "        if profper != empty:\n",
    "            w = profper[0]\n",
    "            a = w.replace(\"[\", \"\")\n",
    "            p1 = a.replace(\"]\",\"\")    \n",
    "            prof_per.insert(x,p1)\n",
    "\n",
    "        seven = str(data[6]) #assets\n",
    "        eight = str(data[7]) #assets in dollars we need to extract this\n",
    "        assetsdol= re.findall('>\\$(.+?)</td>',eight) #we keep only the numbers\n",
    "        if assetsdol != empty:\n",
    "            w = assetsdol[0]\n",
    "            a = w.replace(\"[\", \"\")\n",
    "            ass = a.replace(\"]\",\"\")\n",
    "            assets_dol.insert(x,ass)\n",
    "\n",
    "        ten = str(data[9]) #Total Stockholder Equity ($M)    \n",
    "        eleven = str(data[10]) #Total Stockholder Equity ($M) in dollars we need to extract this\n",
    "        tsedol= re.findall('>\\$(.+?)</td>',eleven) #we keep only the numbers\n",
    "        if tsedol != empty:\n",
    "            w = tsedol[0]\n",
    "            a = w.replace(\"[\", \"\")\n",
    "            ts = a.replace(\"]\",\"\")\n",
    "            tse_dol.insert(x,ts)\n",
    "\n",
    "        thirteen = str(data[12]) # market value\n",
    "        fourteen = str(data[13]) # market value in dollars we need to extract this\n",
    "        mardol= re.findall('>\\$(.+?)</td>',fourteen) #we keep only the numbers\n",
    "        if mardol != empty:\n",
    "            w = mardol[0]\n",
    "            a = w.replace(\"[\", \"\")\n",
    "            mar = a.replace(\"]\",\"\")\n",
    "            mar_dol.insert(x,mar)\n",
    "        x = x + 1\n",
    "    print \"The function is complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function is complete!\n"
     ]
    }
   ],
   "source": [
    "fortune_metrics (list_company_name,list_company_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets $</th>\n",
       "      <th>Market value $</th>\n",
       "      <th>Revenues $</th>\n",
       "      <th>Revenues %</th>\n",
       "      <th>Total Stockholder Equity $</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>492,692</td>\n",
       "      <td>295,174</td>\n",
       "      <td>140,389</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>98,274</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27,736</td>\n",
       "      <td>19,511</td>\n",
       "      <td>135,962</td>\n",
       "      <td>13.7</td>\n",
       "      <td>634</td>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>244,640</td>\n",
       "      <td>220,646</td>\n",
       "      <td>131,620</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16,428</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>266,103</td>\n",
       "      <td>179,653</td>\n",
       "      <td>131,118</td>\n",
       "      <td>-35.7</td>\n",
       "      <td>152,716</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>www.chevron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33,440</td>\n",
       "      <td>69,183</td>\n",
       "      <td>116,199</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10,617</td>\n",
       "      <td>Costco</td>\n",
       "      <td>www.costco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3,221,917</td>\n",
       "      <td>1,621</td>\n",
       "      <td>110,359</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>4,030</td>\n",
       "      <td>Fannie Mae</td>\n",
       "      <td>www.fanniemae.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33,897</td>\n",
       "      <td>36,815</td>\n",
       "      <td>109,830</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6,820</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>65,444</td>\n",
       "      <td>279,511</td>\n",
       "      <td>107,006</td>\n",
       "      <td>20.2</td>\n",
       "      <td>13,384</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>www.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68,782</td>\n",
       "      <td>90,874</td>\n",
       "      <td>103,444</td>\n",
       "      <td>35.4</td>\n",
       "      <td>30,861</td>\n",
       "      <td>Walgreens Boots Alliance</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>106,882</td>\n",
       "      <td>21,272</td>\n",
       "      <td>103,355</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>27,768</td>\n",
       "      <td>HP</td>\n",
       "      <td>www.hp.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Assets $ Market value $ Revenues $ Revenues % Total Stockholder Equity $  \\\n",
       "10    492,692        295,174    140,389       -5.3                     98,274   \n",
       "11     27,736         19,511    135,962       13.7                        634   \n",
       "12    244,640        220,646    131,620        3.6                     16,428   \n",
       "13    266,103        179,653    131,118      -35.7                    152,716   \n",
       "14     33,440         69,183    116,199        3.2                     10,617   \n",
       "15  3,221,917          1,621    110,359       -5.2                      4,030   \n",
       "16     33,897         36,815    109,830        1.3                      6,820   \n",
       "17     65,444        279,511    107,006       20.2                     13,384   \n",
       "18     68,782         90,874    103,444       35.4                     30,861   \n",
       "19    106,882         21,272    103,355       -7.3                     27,768   \n",
       "\n",
       "                     company                             url  \n",
       "10          General Electric                      www.ge.com  \n",
       "11         AmerisourceBergen       www.amerisourcebergen.com  \n",
       "12                   Verizon                 www.verizon.com  \n",
       "13                   Chevron                 www.chevron.com  \n",
       "14                    Costco                  www.costco.com  \n",
       "15                Fannie Mae               www.fanniemae.com  \n",
       "16                    Kroger             www.thekrogerco.com  \n",
       "17                Amazon.com                  www.amazon.com  \n",
       "18  Walgreens Boots Alliance  www.walgreensbootsalliance.com  \n",
       "19                        HP                      www.hp.com  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d9 = {'company' : pd.Series(ln, index=[nm]),'url' : pd.Series(urln, index=[nm]),\n",
    "      'Revenues $' : pd.Series(rev_dol, index=[nm]),'Revenues %' : pd.Series(rev_per, index=[nm]),\n",
    "      'Assets $' : pd.Series(assets_dol, index=[nm]),\n",
    "      'Total Stockholder Equity $' : pd.Series(tse_dol, index=[nm]),\n",
    "      'Market value $' : pd.Series(mar_dol, index=[nm])}\n",
    "fort500 = pd.DataFrame(d9)    \n",
    "fort500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets $</th>\n",
       "      <th>Market value $</th>\n",
       "      <th>Revenues $</th>\n",
       "      <th>Revenues %</th>\n",
       "      <th>Total Stockholder Equity $</th>\n",
       "      <th>company</th>\n",
       "      <th>url_x</th>\n",
       "      <th>The_page_opened</th>\n",
       "      <th>non-document-error</th>\n",
       "      <th>number_of_errors</th>\n",
       "      <th>number_of_warning</th>\n",
       "      <th>url_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492,692</td>\n",
       "      <td>295,174</td>\n",
       "      <td>140,389</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>98,274</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>www.ge.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.ge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27,736</td>\n",
       "      <td>19,511</td>\n",
       "      <td>135,962</td>\n",
       "      <td>13.7</td>\n",
       "      <td>634</td>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244,640</td>\n",
       "      <td>220,646</td>\n",
       "      <td>131,620</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16,428</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>www.verizon.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>www.verizon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266,103</td>\n",
       "      <td>179,653</td>\n",
       "      <td>131,118</td>\n",
       "      <td>-35.7</td>\n",
       "      <td>152,716</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>www.chevron.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>www.chevron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33,440</td>\n",
       "      <td>69,183</td>\n",
       "      <td>116,199</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10,617</td>\n",
       "      <td>Costco</td>\n",
       "      <td>www.costco.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>www.costco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3,221,917</td>\n",
       "      <td>1,621</td>\n",
       "      <td>110,359</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>4,030</td>\n",
       "      <td>Fannie Mae</td>\n",
       "      <td>www.fanniemae.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33,897</td>\n",
       "      <td>36,815</td>\n",
       "      <td>109,830</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6,820</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65,444</td>\n",
       "      <td>279,511</td>\n",
       "      <td>107,006</td>\n",
       "      <td>20.2</td>\n",
       "      <td>13,384</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>www.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68,782</td>\n",
       "      <td>90,874</td>\n",
       "      <td>103,444</td>\n",
       "      <td>35.4</td>\n",
       "      <td>30,861</td>\n",
       "      <td>Walgreens Boots Alliance</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106,882</td>\n",
       "      <td>21,272</td>\n",
       "      <td>103,355</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>27,768</td>\n",
       "      <td>HP</td>\n",
       "      <td>www.hp.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>www.hp.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Assets $ Market value $ Revenues $ Revenues % Total Stockholder Equity $  \\\n",
       "0    492,692        295,174    140,389       -5.3                     98,274   \n",
       "1     27,736         19,511    135,962       13.7                        634   \n",
       "2    244,640        220,646    131,620        3.6                     16,428   \n",
       "3    266,103        179,653    131,118      -35.7                    152,716   \n",
       "4     33,440         69,183    116,199        3.2                     10,617   \n",
       "5  3,221,917          1,621    110,359       -5.2                      4,030   \n",
       "6     33,897         36,815    109,830        1.3                      6,820   \n",
       "7     65,444        279,511    107,006       20.2                     13,384   \n",
       "8     68,782         90,874    103,444       35.4                     30,861   \n",
       "9    106,882         21,272    103,355       -7.3                     27,768   \n",
       "\n",
       "                    company                           url_x The_page_opened  \\\n",
       "0          General Electric                      www.ge.com            True   \n",
       "1         AmerisourceBergen       www.amerisourcebergen.com            True   \n",
       "2                   Verizon                 www.verizon.com            True   \n",
       "3                   Chevron                 www.chevron.com            True   \n",
       "4                    Costco                  www.costco.com            True   \n",
       "5                Fannie Mae               www.fanniemae.com             NaN   \n",
       "6                    Kroger             www.thekrogerco.com            True   \n",
       "7                Amazon.com                  www.amazon.com            True   \n",
       "8  Walgreens Boots Alliance  www.walgreensbootsalliance.com            True   \n",
       "9                        HP                      www.hp.com            True   \n",
       "\n",
       "   non-document-error  number_of_errors  number_of_warning  \\\n",
       "0                 0.0              10.0                0.0   \n",
       "1                 0.0               3.0                0.0   \n",
       "2                 0.0              20.0                6.0   \n",
       "3                 0.0             183.0                8.0   \n",
       "4                 0.0             149.0               26.0   \n",
       "5                 NaN               NaN                NaN   \n",
       "6                 1.0               0.0                0.0   \n",
       "7                 0.0              15.0                5.0   \n",
       "8                 0.0               1.0                3.0   \n",
       "9                 0.0              45.0               19.0   \n",
       "\n",
       "                            url_y  \n",
       "0                      www.ge.com  \n",
       "1       www.amerisourcebergen.com  \n",
       "2                 www.verizon.com  \n",
       "3                 www.chevron.com  \n",
       "4                  www.costco.com  \n",
       "5                             NaN  \n",
       "6             www.thekrogerco.com  \n",
       "7                  www.amazon.com  \n",
       "8  www.walgreensbootsalliance.com  \n",
       "9                      www.hp.com  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fort500.merge(html_val, left_on='company', right_on='company', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets $</th>\n",
       "      <th>Market value $</th>\n",
       "      <th>Revenues $</th>\n",
       "      <th>Revenues %</th>\n",
       "      <th>Total Stockholder Equity $</th>\n",
       "      <th>company</th>\n",
       "      <th>The_page_opened</th>\n",
       "      <th>non-document-error</th>\n",
       "      <th>number_of_errors</th>\n",
       "      <th>number_of_warning</th>\n",
       "      <th>...</th>\n",
       "      <th>.dib</th>\n",
       "      <th>.gif</th>\n",
       "      <th>.jpe</th>\n",
       "      <th>.jpeg</th>\n",
       "      <th>.jpg</th>\n",
       "      <th>.png</th>\n",
       "      <th>.tif</th>\n",
       "      <th>.tiff</th>\n",
       "      <th>total images</th>\n",
       "      <th>loading time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492,692</td>\n",
       "      <td>295,174</td>\n",
       "      <td>140,389</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>98,274</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27,736</td>\n",
       "      <td>19,511</td>\n",
       "      <td>135,962</td>\n",
       "      <td>13.7</td>\n",
       "      <td>634</td>\n",
       "      <td>AmerisourceBergen</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244,640</td>\n",
       "      <td>220,646</td>\n",
       "      <td>131,620</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16,428</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266,103</td>\n",
       "      <td>179,653</td>\n",
       "      <td>131,118</td>\n",
       "      <td>-35.7</td>\n",
       "      <td>152,716</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33,440</td>\n",
       "      <td>69,183</td>\n",
       "      <td>116,199</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10,617</td>\n",
       "      <td>Costco</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33,897</td>\n",
       "      <td>36,815</td>\n",
       "      <td>109,830</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6,820</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65,444</td>\n",
       "      <td>279,511</td>\n",
       "      <td>107,006</td>\n",
       "      <td>20.2</td>\n",
       "      <td>13,384</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68,782</td>\n",
       "      <td>90,874</td>\n",
       "      <td>103,444</td>\n",
       "      <td>35.4</td>\n",
       "      <td>30,861</td>\n",
       "      <td>Walgreens Boots Alliance</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106,882</td>\n",
       "      <td>21,272</td>\n",
       "      <td>103,355</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>27,768</td>\n",
       "      <td>HP</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Assets $ Market value $ Revenues $ Revenues % Total Stockholder Equity $  \\\n",
       "0  492,692        295,174    140,389       -5.3                     98,274   \n",
       "1   27,736         19,511    135,962       13.7                        634   \n",
       "2  244,640        220,646    131,620        3.6                     16,428   \n",
       "3  266,103        179,653    131,118      -35.7                    152,716   \n",
       "4   33,440         69,183    116,199        3.2                     10,617   \n",
       "5   33,897         36,815    109,830        1.3                      6,820   \n",
       "6   65,444        279,511    107,006       20.2                     13,384   \n",
       "7   68,782         90,874    103,444       35.4                     30,861   \n",
       "8  106,882         21,272    103,355       -7.3                     27,768   \n",
       "\n",
       "                    company The_page_opened  non-document-error  \\\n",
       "0          General Electric            True                   0   \n",
       "1         AmerisourceBergen            True                   0   \n",
       "2                   Verizon            True                   0   \n",
       "3                   Chevron            True                   0   \n",
       "4                    Costco            True                   0   \n",
       "5                    Kroger            True                   1   \n",
       "6                Amazon.com            True                   0   \n",
       "7  Walgreens Boots Alliance            True                   0   \n",
       "8                        HP            True                   0   \n",
       "\n",
       "   number_of_errors  number_of_warning     ...      .dib  .gif  .jpe  .jpeg  \\\n",
       "0                10                  0     ...         0     1     1      0   \n",
       "1                 3                  0     ...         0     0     0      0   \n",
       "2                20                  6     ...         0     0     0      0   \n",
       "3               183                  8     ...         0     4     0      0   \n",
       "4               149                 26     ...         0     8     0      0   \n",
       "5                 0                  0     ...         0     1     0      0   \n",
       "6                15                  5     ...         0     0     0      0   \n",
       "7                 1                  3     ...         0     0     0      0   \n",
       "8                45                 19     ...         0     0     0      0   \n",
       "\n",
       "  .jpg .png .tif .tiff total images loading time  \n",
       "0    6    2    0     0           10        1.492  \n",
       "1    0    0    0     0            0        3.325  \n",
       "2    0    2    0     0            2        0.082  \n",
       "3   11   13    0     0           28        0.001  \n",
       "4   29   47   12     1           97        0.156  \n",
       "5    9   31    3     0           44        0.799  \n",
       "6    1    0    0     0            1        0.119  \n",
       "7    8    0    1     0            9        0.075  \n",
       "8   13    1    0     0           14        0.142  \n",
       "\n",
       "[9 rows x 41 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(fort500, html_val, how='inner', on=['company', 'company'])\n",
    "result2 = pd.merge(social_media, fre, how='inner', on=['company', 'company'])\n",
    "result3 = pd.merge(wordss, sizess, how='inner', on=['company', 'company'])\n",
    "result4 = pd.merge(images_types, loading_time, how='inner', on=['company', 'company'])\n",
    "result5 = pd.merge(result, sites_links, how='inner', on=['company', 'company'])\n",
    "result6 = pd.merge(result5, result2, how='inner', on=['company', 'company'])\n",
    "result7 = pd.merge(result6, result3, how='inner', on=['company', 'company'])\n",
    "final2 = pd.merge(result7, result4, how='inner', on=['company', 'company'])\n",
    "del final2['url_x_x']\n",
    "del final2['url_x_y']\n",
    "del final2['url_y_y']\n",
    "final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final2.to_csv('total_10_20.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', 'Assets'], ['$', 'Market'], ['value'], ['$', 'Revenues'], ['$', 'Revenues'], ['%', 'Total'], ['Stockholder'], ['Equity'], ['$', 'company', 'The_page_opened', 'non-document-error', 'number_of_errors', 'number_of_warning', 'url_y_x', 'external', 'internal', 'total'], ['links', 'url', 'facebook', 'instagram', 'linkedin', 'pinterest', 'twitter', 'youtube', 'Readability', 'Readability_index', 'total_words', 'unique_words', 'url_y_x', '70x125', '1x1', '50x45', '400x300', '.bmp', '.dib', '.gif', '.jpe', '.jpeg', '.jpg', '.png', '.tif', '.tiff', 'total'], ['images', 'loading'], ['time'], ['0', '492,692', '295,174', '140,389', '-5.3', '98,274', 'General'], ['Electric', 'True', '0', '10', '0', 'www.ge.com', '1', '128', '129', 'www.ge.com', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'Very'], ['Confusing', '0', '505', '169', 'www.ge.com', 'True', 'True', 'False', 'False', '0', '0', '1', '1', '0', '6', '2', '0', '0', '10', '1.492'], ['1', '27,736', '19,511', '135,962', '13.7', '634', 'AmerisourceBergen', 'True', '0', '3', '0', 'www.amerisourcebergen.com', '0', '0', '0', 'www.amerisourcebergen.com', 'no', 'no', 'no', 'no', 'no', 'no', 'Very'], ['Confusing', '0', '6', '5', 'www.amerisourcebergen.com', 'True', 'True', 'False', 'False', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3.325'], ['2', '244,640', '220,646', '131,620', '3.6', '16,428', 'Verizon', 'True', '0', '20', '6', 'www.verizon.com', '0', '54', '54', 'www.verizon.com', 'no', 'no', 'no', 'no', 'no', 'no', 'Very'], ['Confusing', '0', '301', '131', 'www.verizon.com', 'True', 'True', 'False', 'False', '0', '0', '0', '0', '0', '0', '2', '0', '0', '2', '0.082'], ['3', '266,103', '179,653', '131,118', '-35.7', '152,716', 'Chevron', 'True', '0', '183', '8', 'www.chevron.com', '6', '287', '293', 'www.chevron.com', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'Very'], ['Confusing', '0', '525', '121', 'www.chevron.com', 'True', 'True', 'True', 'False', '0', '0', '4', '0', '0', '11', '13', '0', '0', '28', '0.001'], ['4', '33,440', '69,183', '116,199', '3.2', '10,617', 'Costco', 'True', '0', '149', '26', 'www.costco.com', '24', '254', '278', 'www.costco.com', 'yes', 'no', 'no', 'yes', 'no', 'no', 'Very'], ['Confusing', '0', '1579', '531', 'www.costco.com', 'True', 'True', 'True', 'True', '0', '0', '8', '0', '0', '29', '47', '12', '1', '97', '0.156'], ['5', '33,897', '36,815', '109,830', '1.3', '6,820', 'Kroger', 'True', '1', '0', '0', 'www.thekrogerco.com', '10', '95', '105', 'www.thekrogerco.com', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'Very'], ['Confusing', '0', '502', '271', 'www.thekrogerco.com', 'True', 'True', 'True', 'True', '0', '0', '1', '0', '0', '9', '31', '3', '0', '44', '0.799'], ['6', '65,444', '279,511', '107,006', '20.2', '13,384', 'Amazon.com', 'True', '0', '15', '5', 'www.amazon.com', '0', '3', '3', 'www.amazon.com', 'no', 'no', 'no', 'no', 'no', 'no', 'Very'], ['Confusing', '0', '197', '102', 'www.amazon.com', 'True', 'True', 'True', 'True', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0.119'], ['7', '68,782', '90,874', '103,444', '35.4', '30,861', 'Walgreens'], ['Boots'], ['Alliance', 'True', '0', '1', '3', 'www.walgreensbootsalliance.com', '0', '115', '115', 'www.walgreensbootsalliance.com', 'no', 'no', 'no', 'no', 'yes', 'no', 'Very'], ['Confusing', '0', '456', '125', 'www.walgreensbootsalliance.com', 'True', 'True', 'True', 'True', '0', '0', '0', '0', '0', '8', '0', '1', '0', '9', '0.075'], ['8', '106,882', '21,272', '103,355', '-7.3', '27,768', 'HP', 'True', '0', '45', '19', 'www.hp.com', '0', '174', '174', 'www.hp.com', 'no', 'no', 'no', 'no', 'no', 'yes', 'Very'], ['Confusing', '0', '417', '159', 'www.hp.com', 'True', 'True', 'True', 'True', '0', '0', '0', '0', '0', '13', '1', '0', '0', '14', '0.142']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('total_10_20.csv', 'r') as f:\n",
    "    data = [i.split(\";\") for i in f.read().split()]\n",
    "    print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data10 = pd.read_csv(\"total_10.csv\", sep=';')  \n",
    "data10_20 = pd.read_csv(\"total_10_20.csv\", sep=';')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.bmp</th>\n",
       "      <th>.dib</th>\n",
       "      <th>.gif</th>\n",
       "      <th>.jpe</th>\n",
       "      <th>.jpeg</th>\n",
       "      <th>.jpg</th>\n",
       "      <th>.png</th>\n",
       "      <th>.tif</th>\n",
       "      <th>.tiff</th>\n",
       "      <th>144x144</th>\n",
       "      <th>...</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>total images</th>\n",
       "      <th>total links</th>\n",
       "      <th>total_words</th>\n",
       "      <th>twitter</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>url</th>\n",
       "      <th>url_y_x</th>\n",
       "      <th>url_y_x.1</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>85</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>415</td>\n",
       "      <td>1186</td>\n",
       "      <td>1509</td>\n",
       "      <td>yes</td>\n",
       "      <td>347</td>\n",
       "      <td>www.walmart.com</td>\n",
       "      <td>www.walmart.com</td>\n",
       "      <td>www.walmart.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>23</td>\n",
       "      <td>807</td>\n",
       "      <td>805</td>\n",
       "      <td>no</td>\n",
       "      <td>156</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "      <td>www.exxonmobil.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>318</td>\n",
       "      <td>no</td>\n",
       "      <td>127</td>\n",
       "      <td>www.apple.com</td>\n",
       "      <td>www.apple.com</td>\n",
       "      <td>www.apple.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>170</td>\n",
       "      <td>no</td>\n",
       "      <td>103</td>\n",
       "      <td>www.berkshirehathaway.com</td>\n",
       "      <td>www.berkshirehathaway.com</td>\n",
       "      <td>www.berkshirehathaway.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>13</td>\n",
       "      <td>142</td>\n",
       "      <td>504</td>\n",
       "      <td>yes</td>\n",
       "      <td>172</td>\n",
       "      <td>www.mckesson.com</td>\n",
       "      <td>www.mckesson.com</td>\n",
       "      <td>www.mckesson.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>724</td>\n",
       "      <td>yes</td>\n",
       "      <td>284</td>\n",
       "      <td>www.unitedhealthgroup.com</td>\n",
       "      <td>www.unitedhealthgroup.com</td>\n",
       "      <td>www.unitedhealthgroup.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>20</td>\n",
       "      <td>154</td>\n",
       "      <td>716</td>\n",
       "      <td>yes</td>\n",
       "      <td>270</td>\n",
       "      <td>www.cvshealth.com</td>\n",
       "      <td>www.cvshealth.com</td>\n",
       "      <td>www.cvshealth.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>117</td>\n",
       "      <td>220</td>\n",
       "      <td>456</td>\n",
       "      <td>yes</td>\n",
       "      <td>113</td>\n",
       "      <td>www.gm.com</td>\n",
       "      <td>www.gm.com</td>\n",
       "      <td>www.gm.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>133</td>\n",
       "      <td>193</td>\n",
       "      <td>1238</td>\n",
       "      <td>no</td>\n",
       "      <td>507</td>\n",
       "      <td>www.ford.com</td>\n",
       "      <td>www.ford.com</td>\n",
       "      <td>www.ford.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>56</td>\n",
       "      <td>371</td>\n",
       "      <td>924</td>\n",
       "      <td>yes</td>\n",
       "      <td>235</td>\n",
       "      <td>www.att.com</td>\n",
       "      <td>www.att.com</td>\n",
       "      <td>www.att.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>505</td>\n",
       "      <td>yes</td>\n",
       "      <td>169</td>\n",
       "      <td>www.ge.com</td>\n",
       "      <td>www.ge.com</td>\n",
       "      <td>www.ge.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "      <td>www.amerisourcebergen.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>301</td>\n",
       "      <td>no</td>\n",
       "      <td>131</td>\n",
       "      <td>www.verizon.com</td>\n",
       "      <td>www.verizon.com</td>\n",
       "      <td>www.verizon.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>28</td>\n",
       "      <td>293</td>\n",
       "      <td>525</td>\n",
       "      <td>yes</td>\n",
       "      <td>121</td>\n",
       "      <td>www.chevron.com</td>\n",
       "      <td>www.chevron.com</td>\n",
       "      <td>www.chevron.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>97</td>\n",
       "      <td>278</td>\n",
       "      <td>1579</td>\n",
       "      <td>no</td>\n",
       "      <td>531</td>\n",
       "      <td>www.costco.com</td>\n",
       "      <td>www.costco.com</td>\n",
       "      <td>www.costco.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>44</td>\n",
       "      <td>105</td>\n",
       "      <td>502</td>\n",
       "      <td>yes</td>\n",
       "      <td>271</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "      <td>www.thekrogerco.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>no</td>\n",
       "      <td>102</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>9</td>\n",
       "      <td>115</td>\n",
       "      <td>456</td>\n",
       "      <td>yes</td>\n",
       "      <td>125</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "      <td>www.walgreensbootsalliance.com</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "      <td>417</td>\n",
       "      <td>no</td>\n",
       "      <td>159</td>\n",
       "      <td>www.hp.com</td>\n",
       "      <td>www.hp.com</td>\n",
       "      <td>www.hp.com</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   .bmp  .dib  .gif  .jpe  .jpeg  .jpg  .png  .tif  .tiff 144x144   ...    \\\n",
       "0     0     0    51   103    103    85    56    17      0    True   ...     \n",
       "1     0     0     1     0      0    16     2     4      0    True   ...     \n",
       "2     0     0     1     0      0     0     2     0      0    True   ...     \n",
       "3     0     0     1     0      0     0     0     0      0    True   ...     \n",
       "4     0     0     0     0      0     6     7     0      0    True   ...     \n",
       "5     0     0     0     0      0     0     0     0      0    True   ...     \n",
       "6     0     0     1     1      0     1    16     1      0    True   ...     \n",
       "7     0     0     0     0      0    17    92     8      0    True   ...     \n",
       "8     0     0     1     0      0   104     6    22      0    True   ...     \n",
       "9     0     1     1     0      0    20    29     5      0    True   ...     \n",
       "0     0     0     1     1      0     6     2     0      0     NaN   ...     \n",
       "1     0     0     0     0      0     0     0     0      0     NaN   ...     \n",
       "2     0     0     0     0      0     0     2     0      0     NaN   ...     \n",
       "3     0     0     4     0      0    11    13     0      0     NaN   ...     \n",
       "4     0     0     8     0      0    29    47    12      1     NaN   ...     \n",
       "5     0     0     1     0      0     9    31     3      0     NaN   ...     \n",
       "6     0     0     0     0      0     1     0     0      0     NaN   ...     \n",
       "7     0     0     0     0      0     8     0     1      0     NaN   ...     \n",
       "8     0     0     0     0      0    13     1     0      0     NaN   ...     \n",
       "\n",
       "  pinterest total images total links total_words twitter unique_words  \\\n",
       "0       yes          415        1186        1509     yes          347   \n",
       "1        no           23         807         805      no          156   \n",
       "2        no            3          95         318      no          127   \n",
       "3        no            1          18         170      no          103   \n",
       "4        no           13         142         504     yes          172   \n",
       "5        no            0         121         724     yes          284   \n",
       "6        no           20         154         716     yes          270   \n",
       "7        no          117         220         456     yes          113   \n",
       "8        no          133         193        1238      no          507   \n",
       "9       yes           56         371         924     yes          235   \n",
       "0       yes           10         129         505     yes          169   \n",
       "1        no            0           0           6      no            5   \n",
       "2        no            2          54         301      no          131   \n",
       "3        no           28         293         525     yes          121   \n",
       "4       yes           97         278        1579      no          531   \n",
       "5       yes           44         105         502     yes          271   \n",
       "6        no            1           3         197      no          102   \n",
       "7        no            9         115         456     yes          125   \n",
       "8        no           14         174         417      no          159   \n",
       "\n",
       "                              url                         url_y_x  \\\n",
       "0                 www.walmart.com                 www.walmart.com   \n",
       "1              www.exxonmobil.com              www.exxonmobil.com   \n",
       "2                   www.apple.com                   www.apple.com   \n",
       "3       www.berkshirehathaway.com       www.berkshirehathaway.com   \n",
       "4                www.mckesson.com                www.mckesson.com   \n",
       "5       www.unitedhealthgroup.com       www.unitedhealthgroup.com   \n",
       "6               www.cvshealth.com               www.cvshealth.com   \n",
       "7                      www.gm.com                      www.gm.com   \n",
       "8                    www.ford.com                    www.ford.com   \n",
       "9                     www.att.com                     www.att.com   \n",
       "0                      www.ge.com                      www.ge.com   \n",
       "1       www.amerisourcebergen.com       www.amerisourcebergen.com   \n",
       "2                 www.verizon.com                 www.verizon.com   \n",
       "3                 www.chevron.com                 www.chevron.com   \n",
       "4                  www.costco.com                  www.costco.com   \n",
       "5             www.thekrogerco.com             www.thekrogerco.com   \n",
       "6                  www.amazon.com                  www.amazon.com   \n",
       "7  www.walgreensbootsalliance.com  www.walgreensbootsalliance.com   \n",
       "8                      www.hp.com                      www.hp.com   \n",
       "\n",
       "                        url_y_x.1 youtube  \n",
       "0                 www.walmart.com     yes  \n",
       "1              www.exxonmobil.com      no  \n",
       "2                   www.apple.com     yes  \n",
       "3       www.berkshirehathaway.com      no  \n",
       "4                www.mckesson.com     yes  \n",
       "5       www.unitedhealthgroup.com      no  \n",
       "6               www.cvshealth.com     yes  \n",
       "7                      www.gm.com     yes  \n",
       "8                    www.ford.com      no  \n",
       "9                     www.att.com     yes  \n",
       "0                      www.ge.com     yes  \n",
       "1       www.amerisourcebergen.com      no  \n",
       "2                 www.verizon.com      no  \n",
       "3                 www.chevron.com     yes  \n",
       "4                  www.costco.com      no  \n",
       "5             www.thekrogerco.com     yes  \n",
       "6                  www.amazon.com      no  \n",
       "7  www.walgreensbootsalliance.com      no  \n",
       "8                      www.hp.com     yes  \n",
       "\n",
       "[19 rows x 50 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [data10, data10_20]\n",
    "result = pd.concat(frames)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
