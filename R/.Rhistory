#Then we create ggplots in order to see in what frequency the links appear
par(mfrow=c(1,1))
library(ggplot2)
ggplot(data=total_500_final,aes(x=total.links))+geom_histogram(binwidth=50, colour = "darkblue", fill ="blue")
ggplot(total_500_final, aes(Revenues, total.links)) + geom_point(size=3, colour = "darkblue")
ggplot(data=total_500_final,aes(x=external))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(total_500_final, aes(Revenues, external)) + geom_point(size=3, colour = "darkred")
ggplot(data=total_500_final,aes(x=internal))+geom_histogram(binwidth=50, colour = "darkgreen", fill ="green")
ggplot(total_500_final, aes(Revenues, internal)) + geom_point(size=3, colour = "darkgreen")
#And we can also see for correlations
total_500_links <- total_500_final[,c(4,21:23)]
library(corrplot)
library(caret)
tl <- cor(total_500_links)
tl
corrplot(cor(total_500_links),method="number")
#We can see that the total links with the internal links have a correlation almost 95%.
#So we will not include the total links in the regression model
#########################################################################################################
#Now we will see the loading time per site
ggplot(data=total_500_final,aes(x=loading.time))+geom_histogram(binwidth=1, colour = "pink", fill ="purple")
ggplot(total_500_final, aes(Revenues, loading.time)) + geom_point(size=3, colour = "purple")
#########################################################################################################
#Now we will see the total words, the unique words and the sentences how are distributed alone and in relationhsip with the revenues.
ggplot(data=total_500_final,aes(x=Sentences))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(total_500_final, aes(Revenues, Sentences)) + geom_point(size=3, colour = "purple")
#########################
ggplot(data=total_500_final,aes(x=Unique.words))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(total_500_final, aes(Revenues, Unique.words)) + geom_point(size=3, colour = "purple")
#########################
ggplot(data=total_500_final,aes(x=Words))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(total_500_final, aes(Revenues, Words)) + geom_point(size=3, colour = "purple")
#############################
#And we can also see for correlations
total_500_lt_w <- total_500_final[,c(4,18:20,727)]
library(corrplot)
library(caret)
tl <- cor(total_500_lt_w)
tl
corrplot(cor(total_500_lt_w),method="number")
################################
#Next we will check the Flesh Measure alone and in relationship with revenues
ggplot(data=total_500_final,aes(x=Flesh_Mesaure))+geom_histogram(binwidth=50, colour = "darkred", fill ="red")
ggplot(total_500_final, aes(Revenues, Flesh_Mesaure)) + geom_point(size=3, colour = "purple")
############################
total_500_final$Readability <- gsub("Very easy", "01_VE", total_500_final$Readability )
total_500_final$Readability <- gsub("Easy", "02_E", total_500_final$Readability )
total_500_final$Readability <- gsub("Fairly easy", "03_FE", total_500_final$Readability )
total_500_final$Readability <- gsub("Standard", "04_St", total_500_final$Readability )
total_500_final$Readability <- gsub("Fairly difficult", "05_FD", total_500_final$Readability )
total_500_final$Readability <- gsub("Difficult", "06_D", total_500_final$Readability )
total_500_final$Readability <- gsub("Very Confusing", "07_VC", total_500_final$Readability )
barplot(table(total_500_final$Readability),col ="dark red")
total_500_final$Readability <- gsub("01_VE","1", total_500_final$Readability )
total_500_final$Readability <- gsub("02_E", "2", total_500_final$Readability )
total_500_final$Readability <- gsub("03_FE", "3", total_500_final$Readability )
total_500_final$Readability <- gsub("04_St", "4", total_500_final$Readability )
total_500_final$Readability <- gsub("05_FD", "5", total_500_final$Readability )
total_500_final$Readability <- gsub("06_D", "6" ,total_500_final$Readability )
total_500_final$Readability <- gsub("07_VC", "7",total_500_final$Readability )
total_500_final$Readability <- as.numeric(total_500_final$Readability )
ggplot(data=total_500_final,aes(x=Readability))+geom_bar(binwidth=1, colour = "darkred", fill ="red")
ggplot(total_500_final, aes(Revenues, Readability)) + geom_point(size=3, colour = "purple")
#And we can also see for correlations
total_500_r <- total_500_final[,c(4,16,17)]
library(corrplot)
library(caret)
tl <- cor(total_500_r)
tl
corrplot(cor(total_500_r),method="number")
#########################################################################################################
#Now we will see the number of errors and warnings alone and in relationship with the Revenues
ggplot(data=total_500_final,aes(x=number_of_errors))+geom_histogram(binwidth=50, colour = "red")
ggplot(total_500_final, aes(Revenues, number_of_errors)) + geom_point(size=3, colour = "dark red")
ggplot(data=total_500_final,aes(x=number_of_warning))+geom_histogram(binwidth=20, colour = "red")
ggplot(total_500_final, aes(Revenues, number_of_warning)) + geom_point(size=3, colour = "dark blue")
#########################################################################################################
#########################################################################################################
#Now we will see the non.document.error and the page not opened variables alone and in relationship with the Revenues
ggplot(data=total_500_final,aes(x=non.document.error))+geom_histogram(binwidth=1, colour = "red")
ggplot(total_500_final, aes(Revenues, non.document.error)) + geom_point(size=1, colour = "dark red")
ggplot(data=total_500_final,aes(x=The_page_opened))+geom_histogram(binwidth=1, colour = "red")
ggplot(total_500_final, aes(Revenues, The_page_opened)) + geom_point(size=3, colour = "dark blue")
#In the page not opened we can see that the variable has only the price 1 that means that the page opened so there is no point in using it in the analysis as it does not affect the outcome
#########################################################################################################
#And we can also see for correlations
total_500_html <- total_500_final[,c(4,7:9)]
library(corrplot)
library(caret)
tl <- cor(total_500_html)
tl
corrplot(cor(total_500_html),method="number")
#Now we will see the total images alone and in relationship with the revenues
ggplot(data=total_500_final,aes(x=total.images))+geom_histogram(binwidth=100, colour = "darkred", fill ="red")
ggplot(total_500_final, aes(Revenues, total.images)) + geom_point(size=3, colour = "dark blue")
#########################################################################################################
#We will see now the frequency of image types that is being used
par(mfrow=c(1,1))
k = c(717:725)
for(i in 1:9){
a <- k[i]
image_type<- round(table(total_500_final[,a])/408,3)
barplot(image_type,xlab=names(total_500_final)[a],ylab = "Shares of images per site", col = "dark green")}
#It is obvious that the most common images type are .jpg, gif and .png
#We will check now the types in relationship with the revenues
ggplot(total_500_final, aes(Revenues, .bmp)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .dib)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .gif)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .jpe)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .jpeg)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .jpg)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .png)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .tif)) + geom_point(size=3, colour = "dark blue")
ggplot(total_500_final, aes(Revenues, .tiff)) + geom_point(size=3, colour = "dark blue")
#And we can also see for correlations
total_500_im<- total_500_final[,c(4,717:726)]
library(corrplot)
library(caret)
tl <- cor(total_500_im)
tl
corrplot(cor(total_500_im),method="number")
#We will see now the frequency of image sizes that is being used
k = c()
#Check for sizes that are half and half divided in existing and not
for(i in 24:716){
image_size<- round(table(total_500_final[,i]))
if ((image_size[[1]]==408)==TRUE){
k <- union(k, c(i))
}}
#####################
#Number 24 is all onw price so we want use it
names(total_500_final)[24]
total_500_final$X144x144 <- NULL
false_not_existing = c()
#Check for sizes that are less than half divided in existing and not
for(i in 24:715){
image_size<- round(table(total_500_final[,i]))
if ((image_size[[2]]<204)==TRUE){
false_not_existing <- union(false_not_existing, c(i))
}}
########################
#Now we will take the sizes that exist in less than half the instances and check graphically the deviations between the 408 sites
par(mfrow=c(3,3))
for(i in 1:416){
a = false_not_existing[i]
plot(total_500_final[,a],total_500_final$Revenues)
image_size<- round(table(total_500_final[,a]))
barplot(image_size,xlab=names(total_500_final)[a],ylab = "Has or not the size", col = "dark green")}
true_existing = c()
#Check for sizes that are more than half divided in existing and not
for(i in 24:715){
image_size<- round(table(total_500_final[,i]))
if ((image_size[[2]]>204)==TRUE){
true_existing <- union(true_existing, c(i))
}}
#Now we will take the sizes that exist in more than half the instances and check graphically the deviations between the 408 sites
par(mfrow=c(3,3))
for(i in 1:276){
a = true_existing[i]
image_size<- round(table(total_500_final[,a]))
plot(total_500_final[,a],total_500_final$Revenues)
barplot(image_size,xlab=names(total_500_final)[a],ylab = "Has or not the size", col = "dark green")}
#By checking the above plots we can see that the 24 first sizes do appear to have some differentiation regarding the revenues. While most sites do have those sizes when it comes to the high revienues they do not have them
par(mfrow=c(3,3))
keep = c()
for(i in 1:24){
a = true_existing[i]
keep = union (keep, c(a))}
keep
#As we can see they are the variables from 24 to 47 and these are the only sizes we are going to keep for the further analysis
total_500_final <- total_500_final[,-c(48:715)]
#Also we remove the other Fortune 500 variables since they will interfer in the outcome of the model and we keep only the variable we want to examine the Revenues
total_500_final$Market_Value <- NULL
total_500_final$Assets <- NULL
total_500_final$Ranking <- NULL
total_500_final$Total_SH_Equity <- NULL
total_500_final$The_page_opened <- NULL
summary(total_500_final)
names(total_500_final)
total_500_final$X15x12<- gsub("1","0", total_500_final$X15x12)
total_500_final$X15x12 <- gsub("2", "1", total_500_final$X15x12 )
total_500_final$X60x60<- gsub("1","0", total_500_final$X60x60)
total_500_final$X60x60 <- gsub("2", "1", total_500_final$X60x60 )
total_500_final$X15x75<- gsub("1","0", total_500_final$X15x75)
total_500_final$X15x75 <- gsub("2", "1", total_500_final$X15x75 )
total_500_final$X28x221<- gsub("1","0", total_500_final$X28x221)
total_500_final$X28x221 <- gsub("2", "1", total_500_final$X28x221 )
total_500_final$X41x192 <- gsub("1","0", total_500_final$X41x192 )
total_500_final$X41x192 <- gsub("2", "1", total_500_final$X41x192 )
total_500_final$X300x993 <- gsub("1","0", total_500_final$X300x993 )
total_500_final$X300x993 <- gsub("2", "1", total_500_final$X300x993 )
total_500_final$X160x233 <- gsub("1","0", total_500_final$X160x233 )
total_500_final$X160x233 <- gsub("2", "1", total_500_final$X160x233 )
total_500_final$X29x29 <- gsub("1","0", total_500_final$X29x29 )
total_500_final$X29x29 <- gsub("2", "1", total_500_final$X29x29 )
total_500_final$X300pxx1500px <- gsub("1","0", total_500_final$X300pxx1500px )
total_500_final$X300pxx1500px <- gsub("2", "1", total_500_final$X300pxx1500px )
total_500_final$X200pxx200px<- gsub("1","0", total_500_final$X200pxx200px )
total_500_final$X200pxx200px <- gsub("2", "1", total_500_final$X200pxx200px )
total_500_final$X292pxx292px <- gsub("1","0", total_500_final$X292pxx292px )
total_500_final$X292pxx292px <- gsub("2", "1", total_500_final$X292pxx292px )
total_500_final$X400x300 <- gsub("1","0", total_500_final$X400x300 )
total_500_final$X400x300 <- gsub("2", "1", total_500_final$X400x300 )
total_500_final$X115x223 <- gsub("1","0", total_500_final$X115x223 )
total_500_final$X115x223 <- gsub("2", "1", total_500_final$X115x223 )
total_500_final$X1279pxx984px <- gsub("1","0", total_500_final$X1279pxx984px )
total_500_final$X1279pxx984px<- gsub("2", "1", total_500_final$X1279pxx984px )
total_500_final$X8x15 <- gsub("1","0", total_500_final$X8x15 )
total_500_final$X8x15 <- gsub("2", "1", total_500_final$X8x15 )
total_500_final$X44x556 <- gsub("1","0", total_500_final$X44x556 )
total_500_final$X44x556 <- gsub("2", "1", total_500_final$X44x556 )
total_500_final$X1x1 <- gsub("1","0", total_500_final$X1x1 )
total_500_final$X1x1 <- gsub("2", "1", total_500_final$X1x1 )
total_500_final$autox100. <- gsub("1","0", total_500_final$autox100. )
total_500_final$autox100. <- gsub("2", "1", total_500_final$autox100. )
colnames(total_500_final)[24] <- "X100x100"
total_500_final$X800x1200 <- gsub("1","0", total_500_final$X800x1200 )
total_500_final$X800x1200 <- gsub("2", "1", total_500_final$X800x1200 )
total_500_final$X24pxx133px <- gsub("1","0", total_500_final$X24pxx133px )
total_500_final$X24pxx133px <- gsub("2", "1", total_500_final$X24pxx133px )
total_500_final$X21pxx173px <- gsub("1","0", total_500_final$X21pxx173px )
total_500_final$X21pxx173px <- gsub("2", "1", total_500_final$X21pxx173px )
total_500_final$X46x214 <- gsub("1","0", total_500_final$X46x214)
total_500_final$X46x214 <- gsub("2", "1", total_500_final$X46x214 )
total_500_final$X49x49 <- gsub("1","0", total_500_final$X49x49)
total_500_final$X49x49 <- gsub("2", "1", total_500_final$X49x49 )
total_500_final$X50x45 <- gsub("1","0", total_500_final$X50x45)
total_500_final$X50x45 <- gsub("2", "1", total_500_final$X50x45 )
for(i in 19:42){
total_500_final[,i] <- as.numeric(total_500_final[,i])}
#We split the set to training and test set
library(caret)
set.seed(20)
sampling_vector <- createDataPartition(total_500_final$Revenues, p = 0.70, list = FALSE)
total_500_final_train <- total_500_final[sampling_vector,]
total_500_final_test <- total_500_final[-sampling_vector,]
#We will try to create a regression model to see which of the variables of the websites play the most important part regarding the Ranking of the company.
#We create the empty lm model
model_null = lm(Revenues~1,data=total_500_final_train)
summary(model_null)
#####################################################################################################
#LASSO and Logistic Regression models
library(glmnet)
#We create a full model for the variable Ranking
full <- lm(Revenues~.,data=total_500_final_train)
summary(full)
x <- model.matrix(full) [,-1]
dim(x)
lasso <- glmnet (x, total_500_final_train$Revenues)
par(mfrow=c(1,1),no.readonly = TRUE)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final_train$Revenues)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#We see the coefficients for lamda min
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
#since the sum is NA that means we have to substract some variables
# in order to find which variables to substract we run the coefficients and we see which of them has NA as result
coef(full)
#Now we create a new model with only the variables with coef different from NA
full_2 <- lm(Revenues~. - total.images - total.links - X1x1 - X21pxx173px - X49x49 - X200pxx200px - X1279pxx984px - X300pxx1500px - X160x233 -  X300x993 - X41x192 - X28x221 - X60x60,data=total_500_final_train)
summary(full_2)
x <- model.matrix(full_2) [,-c(18,22,28,26,34,32,33,42,37,38,39,40,52)]
dim(x)
lasso <- glmnet (x, total_500_final_train$Revenues)
plot(lasso, xvar='lambda', label=T)
lassob <- cv.glmnet(x,total_500_final_train$Revenues)
lassob$lambda.min
lassob$lambda.1se
plot(lassob)
#coefiecinets for lammda min
blasso <- coef(lassob, s="lambda.min")
blasso
dim(blasso)
zblasso <- blasso[-1] * apply(x,2,sd)
zbolt <- coef (full_2) [-1] * apply (x,2,sd)
azbolt <- abs(zbolt)
sum(azbolt)
s <- sum(abs(zblasso))/sum(abs(azbolt))
s
full_3 <- lm(Revenues~1 +number_of_errors +facebook +pinterest +youtube+ Flesh_Mesaure +Sentences +X8x15  +X44x556 +X800x1200 +X24pxx133px +X46x214 +X50x45 +X292pxx292px +X115x223 +X15x12  +.bmp +.jpg ,data=total_500_final_train)
summary(full_3)
ad_r_sq_f3 <- summary(full_3)$adj.r.squared
aic_f3 <- AIC(full_3)
plot(full_3,which=1:3)
##############################################
blassob <- coef(lassob, s="lambda.1se")
blassob
zblassob <- blassob[-1] * apply(x,2,sd)
zboltb <- coef (full_2) [-1] * apply (x,2,sd)
s <- sum(abs(zblassob))/sum(abs(zboltb))
s
#The model based on the lasso method by taking the lambda.1se is the null model only with the intercept
full_4 <- lm(Revenues~1 +X8x15  +X44x556 +X800x1200 +X24pxx133px +X46x214 +X50x45 +X292pxx292px +X115x223 +X15x12 ,data=total_500_final_train)
summary(full_4)
ad_r_sq_f4 <- summary(full_4)$adj.r.squared
aic_f4 <- AIC(full_4)
plot(full_4,which=1:3)
###############################################
#We use the "both" method to compare the full_3 model with the null model to see how many variables are indeed important
model_a <- step(model_null, scope = list(lower = model_null, upper=full_2), direction = "both")
summary(model_a)
ad_r_sq_ma <- summary(model_a)$adj.r.squared
aic_ma <- AIC(model_a)
plot(model_a,which=1:3)
################
#We compare the Adjusted R squares of the models and also the AIC of the models we created to find the best one
ad_r_sq_f3
ad_r_sq_f4
ad_r_sq_ma #BEST
#The best Adkusted R square is the one in model a (the closer to 1 the better)
aic_f3
aic_f4
aic_ma #Best
#The best AIC and the best Adjusted R square is for model ma
#######################################################################################################
par(mfrow=c(2,2))
Actual_Revenues<- total_500_final_test$Revenues
plot (Actual_Revenues, col = "blue")
###########################################
predictions_ma <- predict(model_a,total_500_final_test)
plot (predictions_ma, col = "Red",main = "Model a")
#####################################
predictions_full3 <- predict(full_3,total_500_final_test)
plot (predictions_full3, col = "Red",main = "Full_3 model")
#####################################
predictions_full4 <- predict(full_4,total_500_final_test)
plot (predictions_full4, col = "Red",main = "Full_4 model")
#####################################
#From the plots above we can see that the actual Revenues have a more smooth way of leveling up except from the Revenues of the #1 ranking company that are extremely high in relationship with the other sites.
#The prediction model that is more smooth is the model a which has as we said before the best Adjusted R Square and the best AIC price
names(total_500_final_train)
par(mfrow=c(1,1))
total_500_final_reg <- total_500_final_train[,c(1,41,21,30,43,20,10,53,27,45,3)]
cor(total_500_final_reg)
corrplot(cor(total_500_final_reg),method="number")
#We can see here that the variable x8x15 has a very high correlation with the variable x44x556 and also the variable X15x12 has also a very high correlation with the variable x400x300.
#So we can try creating a new model excluding the 2 variables that are correlated from each pair to see if there will be any improvement in the model
full_5 <- lm(Revenues~1 +X44x556 +X400x300 + .bmp + youtube +loading.time + X46x214 + .gif + number_of_errors ,data=total_500_final_train)
summary(full_5)
adj_r_square_full5 <- summary(full_5)$adj.r.squared
aic_full5 <- AIC(full_5)
#We create the 2 basic plots so as to be able to explain the regression model
plot(full_5,which=1:3)
ad_r_sq_ma
adj_r_square_full5
aic_ma
aic_full5
#The adjusted R square and the aic are a little worse than before
#######################################################################################################
##################################################################################################
#Clustering
#Kmeans clustering
#Based on those results we will try to cluster the companies based on the results of the regression
set.seed(220)
clusters <- hclust(dist(total_500_final_reg[, 1]))
plot(clusters)
fortuneCluster <- kmeans(total_500_final_reg[, 1], 2, iter.max = 500,nstart = 1)
cluster <- table(fortuneCluster$cluster)
fortuneCluster$cluster <- as.factor(fortuneCluster$cluster)
ggplot(total_500_final_reg, aes(Revenues, loading.time, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, youtube, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, .gif, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, .bmp, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X46x214, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X15x12, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X44x556, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X400x300, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X8x15, color = fortuneCluster$cluster)) + geom_point(size=3)
#From the clustering we can see that the variables do indeed devide the most high revenues from the smallest ones
summary(model_a)
#We can see from the model that the basic variable that effect a companys ranking
#is whether or not it has an image in size X15x12
#We will try to make a model that we will not take into consideration this variable at all just in order to see how it will explain the revenues
full_6 <- lm(Revenues~1 +X44x556 +X400x300 + .bmp + X8x15+ youtube +loading.time + X46x214 + .gif + number_of_errors ,data=total_500_final_train)
summary(full_6)
adj_r_square_full6 <- summary(full_6)$adj.r.squared
aic_full6 <- AIC(full_6)
#We create the 2 basic plots so as to be able to explain the regression model
plot(full_6,which=1:3)
predictions_ma <- predict(model_a,total_500_final_test)
Actual_Revenues<- total_500_final_test$Revenues
par(mfrow=c(2,2))
plot (Actual_Revenues, col = "blue")
plot (predictions_ma, col = "Red",main = "Model A")
#####################################
predictions_full_6 <- predict(full_6,total_500_final_test)
plot (predictions_full_6, col = "Red",main = "Full_6 model")
#######################################################
predictions_full_5 <- predict(full_5,total_500_final_test)
plot (predictions_full_5, col = "Red",main = "Full_5 model")
adj_r_square_full5
aic_full5
adj_r_square_full6
aic_full6
#We can see that here the prediction of the new model is not as good as the previous one so now that we have checked this option as well we can conclude that the most important factors are the ones of model_a
summary(model_a)
#So we can try creating a new model includind only the 400x300 image size
full_5 <- lm(Revenues~1 +X400x300 + .bmp + youtube +loading.time + .gif + number_of_errors ,data=total_500_final_train)
summary(full_5)
adj_r_square_full5 <- summary(full_5)$adj.r.squared
aic_full5 <- AIC(full_5)
#We create the 2 basic plots so as to be able to explain the regression model
plot(full_5,which=1:3)
ad_r_sq_ma
adj_r_square_full5
aic_ma
aic_full5
#The adjusted R square and the aic are a little worse than before
#So we can try creating a new model includind only the 400x300 image size
full_5 <- lm(Revenues~1 +X46x214 + .bmp + youtube +loading.time + .gif + number_of_errors ,data=total_500_final_train)
summary(full_5)
adj_r_square_full5 <- summary(full_5)$adj.r.squared
aic_full5 <- AIC(full_5)
#We create the 2 basic plots so as to be able to explain the regression model
plot(full_5,which=1:3)
ad_r_sq_ma
adj_r_square_full5
aic_ma
aic_full5
#The adjusted R square and the aic are a little worse than before
#So we can try creating a new model includind only the 400x300 image size
full_5 <- lm(Revenues~1 +X400x300 + .bmp + youtube +loading.time + .gif + number_of_errors ,data=total_500_final_train)
summary(full_5)
adj_r_square_full5 <- summary(full_5)$adj.r.squared
aic_full5 <- AIC(full_5)
ad_r_sq_ma
adj_r_square_full5
aic_ma
aic_full5
#The adjusted R square and the aic are a little worse than before
#######################################################################################################
##################################################################################################
#Clustering
#Kmeans clustering
#Based on those results we will try to cluster the companies based on the results of the regression
set.seed(220)
clusters <- hclust(dist(total_500_final_reg[, 1]))
plot(clusters)
fortuneCluster <- kmeans(total_500_final_reg[, 1], 2, iter.max = 500,nstart = 1)
cluster <- table(fortuneCluster$cluster)
fortuneCluster$cluster <- as.factor(fortuneCluster$cluster)
ggplot(total_500_final_reg, aes(Revenues, loading.time, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, youtube, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, .gif, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, .bmp, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X46x214, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X15x12, color = fortuneCluster$cluster)) + geom_point(size=3)
ggplot(total_500_final_reg, aes(Revenues, X44x556, color = fortuneCluster$cluster)) + geom_point(size=3)
full_6 <- lm(Revenues~1 +X15x12 + .bmp + youtube +loading.time + .gif + number_of_errors ,data=total_500_final_train)
summary(full_6)
adj_r_square_full6 <- summary(full_6)$adj.r.squared
aic_full6 <- AIC(full_6)
#We create the 2 basic plots so as to be able to explain the regression model
plot(full_6,which=1:3)
predictions_ma <- predict(model_a,total_500_final_test)
Actual_Revenues<- total_500_final_test$Revenues
par(mfrow=c(2,2))
plot (Actual_Revenues, col = "blue")
plot (predictions_ma, col = "Red",main = "Model A")
#####################################
predictions_full_6 <- predict(full_6,total_500_final_test)
plot (predictions_full_6, col = "Red",main = "Full_6 model")
#######################################################
predictions_full_5 <- predict(full_5,total_500_final_test)
plot (predictions_full_5, col = "Red",main = "Full_5 model")
adj_r_square_full5
aic_full5
adj_r_square_full6
aic_full6
adj_r_square_full5
aic_full5
adj_r_square_full6
aic_full6
names(total_500_final_reg)
par(mfrow=c(1,1))
total_500_final_reg_2 <- total_500_final_reg[,c(1,2,5,7,8,10,11)]
cor(total_500_final_reg_2)
corrplot(cor(total_500_final_reg_2),method="number")
#Now we create a new model with only the variables with coef different from NA
full_2 <- lm(Revenues~. - total.images - total.links - X1x1 - X21pxx173px - X49x49 - X200pxx200px - X1279pxx984px - X300pxx1500px - X160x233 -  X300x993 - X41x192 - X28x221 - X60x60,data=total_500_final_train)
summary(full_2)
aic_f <- AIC(full_2)
aic_f
x <- model.matrix(full_2) [,-c(18,22,28,26,34,32,33,42,37,38,39,40,52)]
dim(x)
name(x)
x <- model.matrix(full_2) [,-c(18,22,28,26,34,32,33,42,37,38,39,40,52)]
dim(x)
(x)
lasso <- glmnet (x, total_500_final_train$Revenues)
x <- model.matrix(full_2) [,-c(18,22,28,26,34,32,33,42,37,38,39,40,52)]
dim(x)
str(x)
lasso <- glmnet (x, total_500_final_train$Revenues)
x <- model.matrix(full_2) [,-c(18,22,28,26,34,32,33,42,37,38,39,40,52)]
dim(x)
plot(x)
lasso <- glmnet (x, total_500_final_train$Revenues)
#####################################################################################################
#LASSO and Logistic Regression models
library(glmnet)
#We create a full model for the variable Ranking
full <- lm(Revenues~.,data=total_500_final_train)
summary(full)
